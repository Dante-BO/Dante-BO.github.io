{"./":{"url":"./","title":"å†™åœ¨å‰é¢","keywords":"","body":"å†™åœ¨å‰é¢ å¤§å®¶å¥½å•Šï¼Œæˆ‘æ˜¯DanteSUï¼Œä¸€ä¸ªæ¢¦æƒ³æ˜¯æˆä¸ºè®¡ç®—æœºç§‘å­¦å®¶çš„åˆå­¦è€… æœ¬ç½‘ç«™ä¸»è¦æ˜¯ç”¨æ¥è®°å½•æˆ‘çš„ä¸€äº›å­¦ä¹ ç»å†å’Œè¯•é”™ç»éªŒï¼Œå½“ç„¶è¿˜æœ‰ä¸€äº›æœ‰ç”¨çš„é“¾æ¥ã€‚ emmm å¤§æ¦‚å°±æ˜¯è¿™æ ·å§ï¼Œæœ‰é—®é¢˜æ¬¢è¿éšæ—¶é€šè¿‡ Github ä¸æˆ‘è”ç³»ã€‚ Testéƒ¨åˆ† è§£é‡Šï¼šåœ¨å†™ç¬”è®°çš„æ—¶å€™é‡åˆ°çš„å¾ˆå¤šbugä¼šåœ¨è¿™é‡Œåšæµ‹è¯•ï¼Œè¯·å‹¿ç›¸ä¿¡ä»¥ä¸‹å­—ç¬¦ã€‚ã€‚ã€‚ one linethe other line one linethe other line DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:51:40 "},"Links/":{"url":"Links/","title":"å¸¸ç”¨é“¾æ¥","keywords":"","body":"å¸¸ç”¨é“¾æ¥ Main Stream çŸ¥ä¹ https://www.zhihu.com/ Bilibili https://www.bilibili.com/ ML Baidu AI Paddle https://aistudio.baidu.com/aistudio/index åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  https://zh-v2.d2l.ai/index.html paperwithcode https://paperswithcode.com/ People çˆ±å¯å¯çˆ±ç”Ÿæ´»çš„çŸ¥ä¹ https://www.zhihu.com/people/fly51fly å°å¤§æå®æ¯… https://speech.ee.ntu.edu.tw/~hylee/index.php https://www.youtube.com/watch?v=rTqmWlnwz_0 è‹å‰‘æ—çš„åšå®¢ https://kexue.fm/ è±†çº¦ç¿° https://www.jianshu.com/u/8b23f6864f5d EIC17 KexinTANG https://github.com/Kexin-Tang Entertainment ä½ç«¯å½±è§† https://ddrk.me/ ç¾å‰§7 https://www.meiju7.cc/ Tools è¿œæ™¯è®ºå› https://bbs.pcbeta.com/ paperyyæŸ¥é‡ https://www.paperyy.cn/ è¶…æ˜Ÿå¤§é›…æŸ¥é‡ http://user.dayainfo.com/show/login v2ray https://github.com/freefq/tutorials https://github.com/wrfree/free JupyterLabï¼Œæå…¶å¼ºå¤§çš„ä¸‹ä¸€ä»£notebookï¼ https://zhuanlan.zhihu.com/p/87403131 English Duolinguo English Test https://englishtest.duolingo.cn/home ç™»ç™»å¤šé‚»å›½ https://det.91ddedu.com/#/ Speak&Improve https://speakandimprove.com/ Write&Improve https://writeandimprove.com/ æ‹›è˜ IBM https://www.ibm.com/cn-zh/employment/internship/ ä¸€äº›é“¾æ¥ åç§° ç½‘å€ æ–°åŠ å¡å·¥ä½œæŒ‡å— https://www.965work.in/archives/work-guide-for-singapore/ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:40:49 "},"OpCode/":{"url":"OpCode/","title":"æ“ä½œç ","keywords":"","body":"å¿«é€Ÿæ“ä½œç  Terminal Anaconda Python Lib Gitbook Markdown Others ä½ å¥½å•Šï¼Œè¿™é‡Œå¤§æ¦‚æ˜¯è®°å½•ä¸€äº›æˆ‘å¹³æ—¶å¸¸ç”¨çš„ä¸€äº›å¿«é€Ÿæ“ä½œç ï¼ŒåŒ…æ‹¬æœåŠ¡å™¨ç»ˆç«¯ã€condaå’Œä¸€äº›pythonçš„åº“çš„ç­‰ç­‰ã€‚ã€‚ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 21:12:14 "},"OpCode/1.html":{"url":"OpCode/1.html","title":"Terminal","keywords":"","body":"Terminal Author = DanteSU æ¸…å±å¹• Windows $ cls Linux/Mac $ clear æŸ¥çœ‹ æŸ¥çœ‹CUDAç‰ˆæœ¬ $ nvcc -V $ nvcc --version æŸ¥çœ‹Nvidiaæ˜¾å¡çŠ¶æ€ $ nvidia-smi æŸ¥çœ‹æ˜¾å¡è®¾å¤‡å’Œæ˜¾å¡çš„é©±åŠ¨ $ ubuntu-drivers devices æŸ¥çœ‹æ˜¯å¦å®‰è£…æ˜¾å¡é©±åŠ¨ $ glxinfo | grep rendering æŸ¥çœ‹cpuä¿¡æ¯ $ cat /proc/cpuinfo æŸ¥çœ‹æ‰€æœ‰ä¿¡æ¯ $ cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c æŸ¥çœ‹cpuå‹å· $ cat /proc/cpuinfo | grep physical | uniq -c æŸ¥çœ‹ç‰©ç†æ ¸å¿ƒä¸ªæ•° $ getconf LONG_BIT æŸ¥çœ‹æœåŠ¡å™¨è¿è¡Œåœ¨64bitè¿˜æ˜¯32bit æŸ¥çœ‹å†…å­˜ä¿¡æ¯ $ cat /proc/meminfo æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ $ free -h æŸ¥çœ‹å¤§æ¦‚ä¿¡æ¯ $ top åŠ¨æ€æŸ¥çœ‹å†…å­˜ä½¿ç”¨å˜åŒ– æŸ¥çœ‹æ“ä½œç³»ç»Ÿå†…æ ¸ä¿¡æ¯ $ uname -a æŸ¥çœ‹ç½‘å¡ä¿¡æ¯ $ dmesg | grep -i eth ç¦»çº¿åå°ç¨‹åº screen å‘½ä»¤ $ apt install screen $ screen -S w1 æ–°å»ºä¸€ä¸ªw1å·¥ä½œçª—å£ $ screen -ls æŸ¥çœ‹å½“å‰æ‰€æœ‰çš„è¿è¡Œçª—å£ $ screen -d w1 å°†w1çª—å£ç¦»çº¿ $ screen -r w1 æ¥å…¥çª—å£w1 $ ctrl+A+D é€€å‡ºå½“å‰çª—å£ï¼Œå›åˆ°ä¸»ç•Œé¢ $ screen -X -S w1 quit åˆ é™¤w1è¿™ä¸ªçª—å£ $ screen kill +ç¼–å·/åç§° åˆ é™¤çª—å£ tumx å‘½ä»¤ https://zhuanlan.zhihu.com/p/98384704 ä¸‹è½½ wget $ wget [option] [url] åŸºæœ¬æ“ä½œæ„æˆ $ wget url æ ¹æ®æ–‡ä»¶åœ°å€ä¸‹è½½ $ wget -O new_name url ä½¿ç”¨å…¶å®ƒåç§°ä¿å­˜æ–‡ä»¶ $ wget -P new_path url æ›´æ”¹æ–‡ä»¶ä¿å­˜ä½ç½® $ wget -c url ä¸­æ–­åçš„ç»§ç»­ä¸‹è½½ $ wget -t 40 url å¢åŠ å°è¯•æ¬¡æ•°ï¼ˆé»˜è®¤20æ¬¡ï¼‰ $ wget --ftp-user= --ftp-password= url ä»FTPåŠ å¯†æœåŠ¡å™¨ä¸‹è½½å†…å®¹ $ wget -U 'xxx' url æ¨¡æ‹Ÿæµè§ˆå™¨ä¸‹è½½ æ¯”å¦‚ xxx æ˜¯ Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.43 Safari/537.36 $ wget -b url åå°ä¸‹è½½ $ tail -f wget-log æŸ¥çœ‹åå°ä¸‹è½½æ—¥å¿— $ vim downloads.txt ä¸‹è½½å¤šä¸ªæ–‡ä»¶ $ wget -i downloads.txt curl For mac or windows $ curl -o name url æ ¹æ®æ–‡ä»¶åœ°å€ä¸‹è½½ $ curl -C - -o name url æ–­ç‚¹ç»­ä¼  $ curl --retry 3 -o name url è°ƒæ•´å°è¯•æ¬¡æ•° zip $ unzip [-cflptuvz][-agCjLMnoqsVX][-P ][.zipæ–‡ä»¶][æ–‡ä»¶][-d ][-x ] æˆ– unzip [-Z] -c å°†è§£å‹ç¼©çš„ç»“æœæ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œå¹¶å¯¹å­—ç¬¦åšé€‚å½“çš„è½¬æ¢ã€‚ -f æ›´æ–°ç°æœ‰çš„æ–‡ä»¶ã€‚ -l æ˜¾ç¤ºå‹ç¼©æ–‡ä»¶å†…æ‰€åŒ…å«çš„æ–‡ä»¶ã€‚ -p ä¸-cå‚æ•°ç±»ä¼¼ï¼Œä¼šå°†è§£å‹ç¼©çš„ç»“æœæ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œä½†ä¸ä¼šæ‰§è¡Œä»»ä½•çš„è½¬æ¢ã€‚ -t æ£€æŸ¥å‹ç¼©æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚ -u ä¸-få‚æ•°ç±»ä¼¼ï¼Œä½†æ˜¯é™¤äº†æ›´æ–°ç°æœ‰çš„æ–‡ä»¶å¤–ï¼Œä¹Ÿä¼šå°†å‹ç¼©æ–‡ä»¶ä¸­çš„å…¶ä»–æ–‡ä»¶è§£å‹ç¼©åˆ°ç›®å½•ä¸­ã€‚ -v æ‰§è¡Œæ—¶æ˜¾ç¤ºè¯¦ç»†çš„ä¿¡æ¯ã€‚ -z ä»…æ˜¾ç¤ºå‹ç¼©æ–‡ä»¶çš„å¤‡æ³¨æ–‡å­—ã€‚ -a å¯¹æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå¿…è¦çš„å­—ç¬¦è½¬æ¢ã€‚ -b ä¸è¦å¯¹æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå­—ç¬¦è½¬æ¢ã€‚ -C å‹ç¼©æ–‡ä»¶ä¸­çš„æ–‡ä»¶åç§°åŒºåˆ†å¤§å°å†™ã€‚ -j ä¸å¤„ç†å‹ç¼©æ–‡ä»¶ä¸­åŸæœ‰çš„ç›®å½•è·¯å¾„ã€‚ -L å°†å‹ç¼©æ–‡ä»¶ä¸­çš„å…¨éƒ¨æ–‡ä»¶åæ”¹ä¸ºå°å†™ã€‚ -M å°†è¾“å‡ºç»“æœé€åˆ°moreç¨‹åºå¤„ç†ã€‚ -n è§£å‹ç¼©æ—¶ä¸è¦è¦†ç›–åŸæœ‰çš„æ–‡ä»¶ã€‚ -o ä¸å¿…å…ˆè¯¢é—®ç”¨æˆ·ï¼Œunzipæ‰§è¡Œåè¦†ç›–åŸæœ‰æ–‡ä»¶ã€‚ -P ä½¿ç”¨zipçš„å¯†ç é€‰é¡¹ã€‚ -q æ‰§è¡Œæ—¶ä¸æ˜¾ç¤ºä»»ä½•ä¿¡æ¯ã€‚ -s å°†æ–‡ä»¶åä¸­çš„ç©ºç™½å­—ç¬¦è½¬æ¢ä¸ºåº•çº¿å­—ç¬¦ã€‚ -V ä¿ç•™VMSçš„æ–‡ä»¶ç‰ˆæœ¬ä¿¡æ¯ã€‚ -X è§£å‹ç¼©æ—¶åŒæ—¶å›å­˜æ–‡ä»¶åŸæ¥çš„UID/GIDã€‚ [.zipæ–‡ä»¶] æŒ‡å®š.zipå‹ç¼©æ–‡ä»¶ã€‚ [æ–‡ä»¶] æŒ‡å®šè¦å¤„ç†.zipå‹ç¼©æ–‡ä»¶ä¸­çš„å“ªäº›æ–‡ä»¶ã€‚ -d æŒ‡å®šæ–‡ä»¶è§£å‹ç¼©åæ‰€è¦å­˜å‚¨çš„ç›®å½•ã€‚ -x æŒ‡å®šä¸è¦å¤„ç†.zipå‹ç¼©æ–‡ä»¶ä¸­çš„å“ªäº›æ–‡ä»¶ã€‚ -Z unzip -Zç­‰äºæ‰§è¡ŒzipinfoæŒ‡ä»¤ã€‚ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:56:23 "},"OpCode/2.html":{"url":"OpCode/2.html","title":"Anaconda","keywords":"","body":"Anaconda Author = DanteSU Condaä½¿ç”¨ æŸ¥çœ‹å®‰è£…çš„è½¯ä»¶åŒ… conda list æŸ¥çœ‹è™šæ‹Ÿç¯å¢ƒ conda env list conda info -e æ£€æŸ¥æ›´æ–°condaç‰ˆæœ¬ conda update conda å®‰è£…ä¸å¸è½½åŒ… conda install package_name=version_in_need conda uninstall package_name åˆ›å»ºä¸åˆ é™¤è™šæ‹Ÿç¯å¢ƒ conda create -n env_name (package_name=version_in_need) python=3.7 conda remove -n env_name --all å…‹éš†ç¯å¢ƒ conda create -n new_env --clone old_env æ¸…ç†è™šæ‹Ÿç¯å¢ƒçš„åƒåœ¾ conda clean --all åˆ é™¤åŒ… conda remove --name env_name package_name æ¿€æ´»ä¸é€€å‡ºè™šæ‹Ÿç¯å¢ƒ Linux: source activate env_name source deactivate env_name Windows: conda activate conda deactivate env_name pipä½¿ç”¨ æŸ¥çœ‹å®‰è£…åŒ…ä¿¡æ¯ï¼ˆè·¯å¾„ã€ä¾èµ–ï¼‰ pip show package_name ä¸€é”®å®‰è£…éœ€è¦çš„åŒ… requirements.txt ç”Ÿæˆ pip freeze >requirements.txt å®‰è£… pip install -r requirements.txt Condaç‰ˆæœ¬ conda install --yes --file requirements.txt environment.yaml activate env_name conda env export > environment.yaml conda env create -f environment.yaml DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 21:35:15 "},"OpCode/3.html":{"url":"OpCode/3.html","title":"Python Lib","keywords":"","body":"Python Lib Author = DanteSU PyTorch å®‰è£…ç¤ºä¾‹ For CUDA 11.3 å®˜æ–¹æº conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c conda-forge æ¸…åæº åœ°å€ https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ å®‰è£… conda install cudatoolkit=11.3 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ conda install pytorch torchvision torchaudio -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ æ³¨æ„äº‹é¡¹ å®‰è£…pytorchçš„æ—¶å€™ï¼Œåœ¨æ£€æŸ¥å®‰è£…å†…å®¹é‚£ä¸€é¡¹ï¼Œä¸è¦ç€æ€¥è¾“å…¥ yesï¼Œå…ˆæ£€æŸ¥ä¸€ä¸‹æ˜¯å¦æ˜¯ GPU ç‰ˆæœ¬çš„pytorchå†å®‰è£…ï¼Œå¦‚æœä¸æ˜¯ï¼Œå¯ä»¥ç­‰ä¸€ä¼šå†åšå°è¯•æˆ–è€…é‡æ–°è¿›å…¥éœ€è¦é…ç½®çš„ç¯0:ã€‚1â€œ2å¢ƒ æ£€éªŒå®‰è£…æˆåŠŸ $ python import torch torch.cuda.is_available() torch.cuda.get_device_name() torch.__version__ torch.cuda.device_count() SkLearn condaç¯å¢ƒ $ conda install scikit-learn pipç¯å¢ƒ $ pip3 install scikit-learn cv2 $ pip install opencv-python icrawler https://pypi.org/project/icrawler/0.2.2/ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 09:52:07 "},"OpCode/4.html":{"url":"OpCode/4.html","title":"Gitbook","keywords":"","body":"Gitbook Author = DanteSU å®‰è£… Nodejs å› ä¸ºGitbookä¾èµ–Nodejsï¼Œæ‰€ä»¥é¦–å…ˆè¦å®‰è£…Nodejsï¼Œè€Œä¸”å› ä¸ºgitbookåæ¥å¾ˆä¹…æœªæ›´æ–°ï¼Œæ‰€ä»¥å¯¹æ–°ç‰ˆçš„nodejså…¼å®¹æ€§ä¸å¥½ï¼Œå®¹æ˜“å‡ºbugï¼Œå»ºè®®æœ€å¤šä½¿ç”¨åˆ°ç¬¬10ç‰ˆçš„nodejs Mac ä» https://nodejs.org/en/ ä¸‹è½½å¹¶å®‰è£… Nodejs ï¼Œå®‰è£…å®Œåå¯é€šè¿‡ç»ˆç«¯å‘½ä»¤ node -v æ£€éªŒæ˜¯å¦å®‰è£…æˆåŠŸã€‚ åé¢å¯èƒ½æŠ¥é”™ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥é€šè¿‡ brew å‘½ä»¤ä¸‹è½½ä½ç‰ˆæœ¬çš„ nodejsï¼š $ brew install node@10 $ echo 'export PATH=\"/usr/local/opt/node@10/bin:$PATH\"' >> ~/.zshrc $ source ~/.zshrc $ # æŸ¥çœ‹ç‰ˆæœ¬åŠæ˜¯å¦å®‰è£…æˆåŠŸ $ node -v $ npm -v Linux Under building... Windows Under building... å®‰è£…Gitbook $ npm install gitbook-cli -g # æŸ¥çœ‹ç‰ˆæœ¬å· $ gitbook -V åŸºæœ¬ä½¿ç”¨ åˆ›å»ºæ–°çš„book $ gitbook init ç”Ÿæˆ $ gitbook build è‹¥åªæ‰§è¡Œgitbook buildï¼Œä¼šç”Ÿæˆ_bookç›®å½•ï¼Œä½†ä¸èƒ½é¢„è§ˆã€‚ åœ¨è¿™ä¸ªç›®å½•ä¸­ï¼Œå¯¹äºæ¯ä¸€ä¸ª markdown æ–‡ä»¶éƒ½ç”Ÿæˆäº†ä¸€ä¸ªç›¸åº”çš„ html æ–‡ä»¶ï¼ŒåŒæ—¶åœ¨ _book/gitbook æ–‡ä»¶å¤¹ä¸­å­˜æ”¾äº†ä¸€äº›ä¸»é¢˜ã€å­—ä½“ã€æ ·å¼ä¸å›¾åƒç­‰æ–‡ä»¶ é¢„è§ˆ $ gitbook serve ./{book_name} æœ€åä¸€ä¸ªå‚æ•°æŒ‡å®šè¾“å‡ºé™æ€ç½‘ç«™å†…å®¹çš„ç›®å½•ï¼Œå¯çœç•¥ï¼Œé»˜è®¤ä¼šåœ¨å½“å‰ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªå­ç›®å½•_book (base) dantesu@DanteSudeMacBook-Pro gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 14 explicitly listed info: loading plugin \"splitter\"... OK info: loading plugin \"expandable-chapters-small\"... OK info: loading plugin \"anchors\"... OK info: loading plugin \"github\"... OK info: loading plugin \"github-buttons\"... OK info: loading plugin \"sharing-plus\"... OK info: loading plugin \"anchor-navigation-ex\"... OK info: loading plugin \"favicon\"... OK info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 10 pages info: found 2 asset files info: >> generation finished with success in 1.1s ! Starting server ... Serving book on http://localhost:4000 æ ·å¼ $ gitbook install æ›´æ–°æ ·å¼ä¸­çš„æ’ä»¶åéœ€è¦ä½¿ç”¨æ­¤å‘½ä»¤æ¥å®‰è£…æ–°çš„æ’ä»¶ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼Œæ¯”å¦‚ï¼š (base) dantesu@DanteSudeMBP gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 16 explicitly listed Error: Couldn't locate plugins \"page-footer-ex\", Run 'gitbook install' to install plugins from registry. æ ·å¼ä¾‹å­ ä»¥ä¸‹æ˜¯æˆ‘æš‚æ—¶åœ¨ä½¿ç”¨çš„æ ·å¼ { \"title\": \"DanteSU's House\", \"author\": \"DanteSU\", \"description\": \"All I know is here\", \"language\": \"zh-hans\", \"gitbook\": \"3.2.3\", \"styles\": { \"website\": \"./styles/website.css\" }, \"structure\": { \"readme\": \"README.md\" }, \"links\": { \"sidebar\": { \"ä½†ä¸ä¸–ç•Œï¼ˆåœ¨å»ºï¼‰\": \"https://dante-su.github.io/\" } }, \"plugins\": [ \"-sharing\", \"splitter\", \"expandable-chapters-small\", \"anchors\", \"github\", \"github-buttons\", \"sharing-plus\", \"anchor-navigation-ex\", \"favicon\" ], \"pluginsConfig\": { \"github\": { \"url\": \"https://github.com/Dante-Su\" }, \"sharing\": { \"douban\": false, \"facebook\": false, \"google\": false, \"hatenaBookmark\": false, \"instapaper\": false, \"line\": false, \"linkedin\": false, \"messenger\": false, \"pocket\": false, \"qq\": false, \"qzone\": false, \"stumbleupon\": false, \"twitter\": false, \"viber\": false, \"vk\": false, \"weibo\": false, \"whatsapp\": false, \"all\": [ \"google\", \"facebook\", \"weibo\", \"twitter\", \"qq\", \"qzone\", \"linkedin\", \"pocket\" ] }, \"anchor-navigation-ex\": { \"showLevel\": false }, \"favicon\":{ \"shortcut\": \"./source/images/favicon.jpg\", \"bookmark\": \"./source/images/favicon.jpg\", \"appleTouch\": \"./source/images/apple-touch-icon.jpg\", \"appleTouchMore\": { \"120x120\": \"./source/images/apple-touch-icon.jpg\", \"180x180\": \"./source/images/apple-touch-icon.jpg\" } } } } æ ·å¼ç½‘ç«™ https://www.npmjs.com/search?q=gitbook-plugin-theme&ranking=quality éƒ¨ç½²åˆ°Github åˆ›å»ºæ–°çš„book ç›¸å…³é“¾æ¥ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:35:09 "},"OpCode/5.html":{"url":"OpCode/5.html","title":"Markdown","keywords":"","body":"Markdown Author = DanteSU é“¾æ¥ é¡µå†…é“¾æ¥ åˆ©ç”¨htmlæ ‡ç­¾å®ç° å®šä¹‰ä¸€ä¸ªé”š(id)ï¼š è·³è½¬åˆ°çš„åœ°æ–¹ è·³è½¬é“¾æ¥çš„ä½ç½®ï¼š [ç‚¹å‡»è·³è½¬](#jump) èµ„æºé“¾æ¥ è¶…é“¾æ¥ è¡¨æ ¼ markdownæ–¹æ³• ä¸€èˆ¬æƒ…å†µ | è¡¨å¤´1 | è¡¨å¤´2 | è¡¨å¤´3 | | :- | :-: | -: | | ä¿¡æ¯1 | ä¿¡æ¯2 | ä¿¡æ¯3 | æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 è¡¨å¤´3 ä¿¡æ¯11111111 ä¿¡æ¯22222222 ä¿¡æ¯33333333 æ ¼å†…æ¢è¡Œ | è¡¨å¤´1 | è¡¨å¤´2 | | :-: | :-: | | ä¿¡æ¯1 | ä¿¡æ¯2ä¿¡æ¯3 | æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 ä¿¡æ¯1 ä¿¡æ¯2ä¿¡æ¯3 htmlæ–¹æ³• ä¸€èˆ¬æƒ…å†µ è¡¨å¤´1 è¡¨å¤´2 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2-1 å•å…ƒæ ¼ä¿¡æ¯2-2 æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2-1 å•å…ƒæ ¼ä¿¡æ¯2-2 æ›´æ”¹å¯¹é½æ–¹å¼ è¡¨å¤´1 è¡¨å¤´2 è¡¨å¤´3 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2 å•å…ƒæ ¼ä¿¡æ¯3 æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 è¡¨å¤´3 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2 å•å…ƒæ ¼ä¿¡æ¯3 è¡¨å¤´ æˆ‘æ˜¯è¡¨å¤´ æ•ˆæœï¼š æˆ‘æ˜¯è¡¨å¤´ ä¸€æ ¼å¤šè¡Œ è¡¨å¤´1 è¡¨å¤´2 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2-1 å•å…ƒæ ¼ä¿¡æ¯2-2 æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2-1 å•å…ƒæ ¼ä¿¡æ¯2-2 ä¸€æ ¼å¤šåˆ— è¡¨å¤´1 è¡¨å¤´2 è¡¨å¤´3 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2 æ•ˆæœï¼š è¡¨å¤´1 è¡¨å¤´2 è¡¨å¤´3 å•å…ƒæ ¼ä¿¡æ¯1 å•å…ƒæ ¼ä¿¡æ¯2 æ•°å­¦å…¬å¼ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:51:20 "},"OpCode/6.html":{"url":"OpCode/6.html","title":"Others","keywords":"","body":"Others Author = DanteSU Colabé˜²æ–­ https://colab.research.google.com/github/iErics/gd-utils/blob/master/Colab_gd_utils.ipynb function ConnectButton(){ console.log(\"Connect pushed\"); document.querySelector(\"#connect\").click() } setInterval(ConnectButton,60000); pythonæ–‡ä»¶ä¸­å¤šè¡Œå¹³ç§» å·¦ç§» é€‰ä¸­+æŒ‰ä¸‹Tab å³ç§» é€‰ä¸­+æŒ‰ä¸‹ctrl+[ Macæ˜¯æŒ‰ä¸‹Command+[ clearæ¸…å±å¹•å‡ºç°é—®é¢˜ é—®é¢˜æè¿° $ clear terminals database is inaccessible è§£å†³æ–¹æ³• $ export TERMINFO=/usr/share/terminfo æœ€å¥½æ˜¯å°†ä¸Šé¢é‚£æ¡ export å‘½ä»¤æ·»åŠ åˆ° .bashrc ä¸­ã€‚ Under building... DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 11:43:37 "},"Mix/":{"url":"Mix/","title":"æ‚è®°","keywords":"","body":"æ‚è®° ç¬”è®° bugç»éªŒé›† bugè§£å†³é“¾æ¥ å²—ä½èµ„æº åŠæ—¶ä»£ç  å›¾åƒç¼©æ”¾ å›¾åƒä¿®æ”¹æ ¼å¼ PyTorch DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 11:29:21 "},"Mix/1.html":{"url":"Mix/1.html","title":"ç¬”è®°","keywords":"","body":"ç¬”è®° Author = DanteSU è®¡ç®—æœºè§†è§‰ åŒ»å­¦å›¾åƒå¤„ç† 1 From çŸ¥ä¹ åˆ’é‡ç‚¹! ! ! å…¶å®åŒ»å­¦é¢†åŸŸçš„é¡¶ä¼šå’Œé¡¶åˆŠç›¸å¯¹æ¥è¯´å¥½ä¸­ä¸€ç‚¹!åªè¦å¤§å®¶å¤šä»CVPR/ICCV/ECCV.ä¸Šçœ‹ä¸€äº›ç›¸å…³è®ºæ–‡ï¼Œä»é‡Œé¢è·Ÿè¸ªä¸€äº›æœ€æ–°æŠ€æœ¯(åˆ›æ–°ç‚¹)ï¼Œå†æŠŠè¿™äº›æ–°æŠ€æœ¯(åˆ›æ–°ç‚¹)åº”ç”¨åˆ°åŒ»å­¦å›¾åƒé¢†åŸŸçš„æŸäº›ä»»åŠ¡,æ‰“è´¥è¯¥ä»»åŠ¡ä¸‹ç°æœ‰çš„SOTAç®—æ³•å¹¶è§£å†³ç›¸å…³çš„é—®é¢˜å³å¯ã€‚0K~ï¼Œæ­å–œä½ å¯ä»¥å¼€å§‹å†™è®ºæ–‡äº†!è‡³äºä¸­ä¸ä¸­è¿˜è¦çœ‹ä½ å†™çš„æ€ä¹ˆæ ·ï¼Œæ¯•ç«Ÿé¡¶ä¼šé¡¶åˆŠçš„æŠ•ç¨¿è´¨é‡å¯ä¸å…è®¸é”™è¯¯è¯­æ³•ä¸€å¤§å †ï¼Œ å›¾è¡¨ä¸è§„èŒƒï¼Œä»¥åŠæ–‡ç« é€»è¾‘ä¸é€šç­‰! English TOEFL Duolinguo English Test (DET) Supervisors with high quality publications in HK 1 From çŸ¥ä¹ ä½œè€…ï¼šlenn é“¾æ¥ï¼šhttps://www.zhihu.com/question/332075078/answer/738266074 CUHK: IE/EE: Multimedia Laboratory å…¨éƒ¨faculty (http://mmlab.ie.cuhk.edu.hk/) CSE: Prof. Jiaya Jia (http://jiaya.me/) Dr. Qi Dou (http://www.cse.cuhk.edu.hk/~qdou/) HKUST: CSE: Prof. Dit-Yan Yeung (https://sites.google.com/view/dyyeung) Prof. James Kwok (https://www.cse.ust.hk/~jamesk/) Chi Keung Tang (http://www.cs.ust.hk/~cktang/bio-sketch-review.htm) Prof. Long Quan (https://www.cse.ust.hk/~quan/) Prof. Pedro V. Sander (https://www.cse.ust.hk/~psander/) Dr. Qifeng Chen (https://cqf.io/) Dr. Dan Xu (Dan Xu - Homepage) ECE: Dr. Shaojie Shen (https://www.ece.ust.hk/eeshaojie) HKU: CS: Prof. Yizhou Yu (https://i.cs.hku.hk/~yzyu/) Dr. Ping Luo (http://luoping.me/) EE: Dr. Xiaojuan Qi (Xiaojuan Qi) CityU: CS: Prof. Chong-Wah Ngo (http://vireo.cs.cityu.edu.hk/index.html) Dr. Antoni Bert Chan (http://visal.cs.cityu.edu.hk/) Prof. Rynson Lau (http://www.cs.cityu.edu.hk/~rynson/) Dr. Kede Ma (Kede Ma, home page) Dr. Jing Liao (https://liaojing.github.io/html/) SCM: Prof. Hongbo Fu (http://sweb.cityu.edu.hk/hongbofu/) PolyU: COMP: Prof. Lei Zhang (https://www4.comp.polyu.edu.hk/~cslzhang/) Dr. Bo Yang (The Hong Kong Polytechnic University) HKBU: CS: Prof. Yiu Ming Cheung (https://www.comp.hkbu.edu.hk/~ymc/) è¿›ç¨‹ä¸çº¿ç¨‹ From çŸ¥ä¹ ç±»ä¼¼â€è¿›ç¨‹æ˜¯èµ„æºåˆ†é…çš„æœ€å°å•ä½ï¼Œçº¿ç¨‹æ˜¯CPUè°ƒåº¦çš„æœ€å°å•ä½â€œè¿™æ ·çš„å›ç­”æ„Ÿè§‰å¤ªæŠ½è±¡ï¼Œéƒ½ä¸å¤ªå®¹æ˜“è®©äººç†è§£ã€‚ åšä¸ªç®€å•çš„æ¯”å–»ï¼šè¿›ç¨‹=ç«è½¦ï¼Œçº¿ç¨‹=è½¦å¢ çº¿ç¨‹åœ¨è¿›ç¨‹ä¸‹è¡Œè¿›ï¼ˆå•çº¯çš„è½¦å¢æ— æ³•è¿è¡Œï¼‰ ä¸€ä¸ªè¿›ç¨‹å¯ä»¥åŒ…å«å¤šä¸ªçº¿ç¨‹ï¼ˆä¸€è¾†ç«è½¦å¯ä»¥æœ‰å¤šä¸ªè½¦å¢ï¼‰ ä¸åŒè¿›ç¨‹é—´æ•°æ®å¾ˆéš¾å…±äº«ï¼ˆä¸€è¾†ç«è½¦ä¸Šçš„ä¹˜å®¢å¾ˆéš¾æ¢åˆ°å¦å¤–ä¸€è¾†ç«è½¦ï¼Œæ¯”å¦‚ç«™ç‚¹æ¢ä¹˜ï¼‰ åŒä¸€è¿›ç¨‹ä¸‹ä¸åŒçº¿ç¨‹é—´æ•°æ®å¾ˆæ˜“å…±äº«ï¼ˆAè½¦å¢æ¢åˆ°Bè½¦å¢å¾ˆå®¹æ˜“ï¼‰ è¿›ç¨‹è¦æ¯”çº¿ç¨‹æ¶ˆè€—æ›´å¤šçš„è®¡ç®—æœºèµ„æºï¼ˆé‡‡ç”¨å¤šåˆ—ç«è½¦ç›¸æ¯”å¤šä¸ªè½¦å¢æ›´è€—èµ„æºï¼‰ è¿›ç¨‹é—´ä¸ä¼šç›¸äº’å½±å“ï¼Œä¸€ä¸ªçº¿ç¨‹æŒ‚æ‰å°†å¯¼è‡´æ•´ä¸ªè¿›ç¨‹æŒ‚æ‰ï¼ˆä¸€åˆ—ç«è½¦ä¸ä¼šå½±å“åˆ°å¦å¤–ä¸€åˆ—ç«è½¦ï¼Œä½†æ˜¯å¦‚æœä¸€åˆ—ç«è½¦ä¸Šä¸­é—´çš„ä¸€èŠ‚è½¦å¢ç€ç«äº†ï¼Œå°†å½±å“åˆ°æ‰€æœ‰è½¦å¢ï¼‰ è¿›ç¨‹å¯ä»¥æ‹“å±•åˆ°å¤šæœºï¼Œè¿›ç¨‹æœ€å¤šé€‚åˆå¤šæ ¸ï¼ˆä¸åŒç«è½¦å¯ä»¥å¼€åœ¨å¤šä¸ªè½¨é“ä¸Šï¼ŒåŒä¸€ç«è½¦çš„è½¦å¢ä¸èƒ½åœ¨è¡Œè¿›çš„ä¸åŒçš„è½¨é“ä¸Šï¼‰ è¿›ç¨‹ä½¿ç”¨çš„å†…å­˜åœ°å€å¯ä»¥ä¸Šé”ï¼Œå³ä¸€ä¸ªçº¿ç¨‹ä½¿ç”¨æŸäº›å…±äº«å†…å­˜æ—¶ï¼Œå…¶ä»–çº¿ç¨‹å¿…é¡»ç­‰å®ƒç»“æŸï¼Œæ‰èƒ½ä½¿ç”¨è¿™ä¸€å—å†…å­˜ã€‚ï¼ˆæ¯”å¦‚ç«è½¦ä¸Šçš„æ´—æ‰‹é—´ï¼‰ï¼\"äº’æ–¥é”\" è¿›ç¨‹ä½¿ç”¨çš„å†…å­˜åœ°å€å¯ä»¥é™å®šä½¿ç”¨é‡ï¼ˆæ¯”å¦‚ç«è½¦ä¸Šçš„é¤å…ï¼Œæœ€å¤šåªå…è®¸å¤šå°‘äººè¿›å…¥ï¼Œå¦‚æœæ»¡äº†éœ€è¦åœ¨é—¨å£ç­‰ï¼Œç­‰æœ‰äººå‡ºæ¥äº†æ‰èƒ½è¿›å»ï¼‰ï¼â€œä¿¡å·é‡â€ æ•£è®° 1 ç®€åŒ–ç‰ˆAttentionçŸ©é˜µè·Ÿæ ‡å‡†çš„Scaled-Dot Self Attentionç±»ä¼¼ï¼Œè¿™é‡Œçš„æ³¨æ„åŠ›çŸ©é˜µè¿˜æ˜¯Q,Kçš„å†…ç§¯å¹¶é™¤ä»¥ç»´åº¦çš„å¹³æ–¹æ ¹è€Œæ¥ï¼Œå¤æ‚åº¦è¿˜æ˜¯ğ’ª(n2)çš„ï¼Œä¸åŒçš„æ˜¯è¿™é‡Œç®€åŒ–äº†Q,Kçš„æ¥æºå˜æ¢ï¼Œå¹¶ä¸”æ¿€æ´»å‡½æ•°æ¢ç”¨äº†relu2ã€‚å¤§å®¶å¯èƒ½å¯¹è¿™ä¸ªæ¿€æ´»å‡½æ•°æ¯”è¾ƒé™Œç”Ÿï¼Œäº‹å®ä¸Šè¿™æ˜¯ä½œè€…å›¢é˜Ÿåœ¨ä»–ä»¬ä¹‹å‰çš„è®ºæ–‡ã€ŠPrimer: Searching for Efficient Transformers for Language Modelingã€‹ç”¨NASçš„æ–¹å¼æœå‡ºæ¥çš„ã€‚æœ€åçš„1/næ˜¯ç®€å•çš„å½’ä¸€åŒ–å› å­ï¼Œç”¨ä»¥æ¶ˆé™¤é•¿åº¦çš„å½±å“ã€‚è¿™ä¸ªè®¾è®¡çš„æˆåŠŸä¹Ÿè¡¨æ˜ï¼Œæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„softmaxä¸æ˜¯å¿…é¡»çš„ï¼Œå¯ä»¥æ¢æˆå¸¸è§„çš„æ¿€æ´»å‡½æ•°åŠ ç®€å•çš„å½’ä¸€åŒ–ã€‚ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:40:34 "},"Mix/2.html":{"url":"Mix/2.html","title":"bugç»éªŒé›†","keywords":"","body":"bugç»éªŒé›† Author = DanteSU linuxæœåŠ¡å™¨æœ¬åœ°å¼€å¯visdom éœ€è¦ç”¨pytorchçš„visdomåœ¨æœåŠ¡å™¨ä¸Šè·‘ç¨‹åºï¼Œå¹¶æŠŠå›¾ç‰‡æ˜¾ç¤ºå‡ºæ¥ï¼Œä½†æ˜¯æœåŠ¡å™¨ä¸Šæ‰“ä¸å¼€ç½‘é¡µï¼Œå¦‚ä½•å°†visdom.serverè½¬åˆ°æœ¬åœ°ã€‚ä»¥ä¸‹æ“ä½œ 1.åœ¨æœåŠ¡å™¨ä¸Šä½¿ç”¨ $ tmux new -s session-name å¼€å¯ä¸€ä¸ªæ–°çš„åå°è¿›ç¨‹ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨å‰å°å¼€å¯visdom.serverï¼Œåªä¸è¿‡å°±æ²¡åŠæ³•è¿›è¡Œå…¶ä»–å·¥ä½œã€‚ 2.å¼€å¯visdomæ‰€åœ¨condaè™šæ‹Ÿç¯å¢ƒï¼Œè¾“å…¥ $ python -m visdom.server å¼€å¯visdomæœåŠ¡å™¨ 3.åœ¨æœ¬åœ°ï¼Œæ³¨æ„æ˜¯æœ¬åœ°ç”µè„‘ï¼Œè€ŒéæœåŠ¡å™¨å‘½ä»¤è¡Œï¼Œæ‰“å¼€cmdï¼Œè¾“å…¥ $ ssh -L 8097:127.0.0.1:8097 username@xx.xx.xx.xx ï¼ˆusernameå’Œxx.xx.xx.xxåˆ†åˆ«æ˜¯ä½ æœåŠ¡å™¨çš„ç”¨æˆ·åå’ŒIPåœ°å€ï¼‰ 4.ä½ ä¼šå‘ç°æœ¬åœ°cmdå‘½ä»¤è¡Œè¿æ¥ä¸Šäº†æœåŠ¡å™¨ï¼Œç„¶åä½ å°±å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€127.0.0.1:8097 å‘ç°è¿æ¥ä¸Šäº† 5.å¦‚æœæƒ³ç»ˆæ­¢æœåŠ¡å™¨å’Œæœ¬åœ°çš„è¿æ¥ï¼Œå¯ä»¥æ€æ­»è¿›ç¨‹å³å¯ $ tmux kill-session -t session-name DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 23:01:41 "},"Mix/3.html":{"url":"Mix/3.html","title":"bugè§£å†³é“¾æ¥","keywords":"","body":"bugè§£å†³é“¾æ¥ Searcher = DanteSU Mirror åç§° ç½‘å€ æ¸…åæº https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ DP åç§° ç½‘å€ pytorch åŠ è½½å¤§æ•°æ®é›† å†…å­˜ä¸å¤Ÿ çš„å¤„ç†æ–¹å¼ https://blog.csdn.net/cjs8348797/article/details/115708811https://www.cnblogs.com/aminor/p/14336767.htmlhttps://www.zhihu.com/question/386743819/answer/1989311050https://www.cnblogs.com/xiaosongshine/p/10750908.html AdaptivePoolingä¸Max/AvgPoolingç›¸äº’è½¬æ¢ https://www.cnblogs.com/xiaosongshine/p/10750908.html Pythonä¸­ç”Ÿæˆå¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ https://blog.csdn.net/kane7csdn/article/details/83756583 Pytorch å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå¥—è·¯ https://blog.csdn.net/weixin_45468845/article/details/122971739https://zhuanlan.zhihu.com/p/464796719https://blog.csdn.net/FUTEROX/article/details/122724634 pytorchä¸­æ ¹æ®ç¥ç»ç½‘ç»œç»“æ„ç¡®å®šè¾“å…¥å›¾ç‰‡å°ºå¯¸/æ ¹æ®å›¾ç‰‡å°ºå¯¸ä¿®æ”¹ç¥ç»ç½‘ç»œç»“æ„ https://blog.csdn.net/weixin_43423455/article/details/99096580 torch.nn.AdaptiveAvgPool1d(N)å‡½æ•°è§£è¯» https://blog.csdn.net/qq_40178291/article/details/102699493 torch.view()è¯¦è§£åŠ-1å‚æ•°æ˜¯ä»€ä¹ˆæ„æ€ https://www.cnblogs.com/MartinLwx/p/10543604.html Pytorchå¸¸ç”¨çš„äº¤å‰ç†µæŸå¤±å‡½æ•°CrossEntropyLoss()è¯¦è§£ https://zhuanlan.zhihu.com/p/98785902 PyTorch å¤šåˆ†ç±»æŸå¤±å‡½æ•° https://blog.csdn.net/jacke121/article/details/104665912/ pytorchçš„å„ç§loss https://blog.csdn.net/qq_22764813/article/details/104867431 PyTorch Bertæ–‡æœ¬åˆ†ç±» https://blog.csdn.net/weixin_44912902/article/details/123886825 äºŒåˆ†ç±»é—®é¢˜ï¼šåŸºäºBERTçš„æ–‡æœ¬åˆ†ç±»å®è·µï¼é™„å®Œæ•´ä»£ç  https://blog.csdn.net/Datawhale/article/details/104871803?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-104871803-blog-123886825.pc_relevant_default&utm_relevant_index=6 BERT-ä½¿ç”¨tfç”Ÿæˆpytorch_model.bin https://www.freesion.com/article/9725381185/ PyTorchä¹‹nn.ReLUä¸F.ReLUçš„åŒºåˆ« https://blog.csdn.net/u011501388/article/details/86602275 Pytorchå…¥é—¨æ•™ç¨‹ï¼ˆåï¼‰ï¼šResNetå›¾ç‰‡åˆ†ç±»å®æˆ˜ https://blog.csdn.net/weixin_43472830/article/details/95871258?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-95871258-blog-107028785.pc_relevant_default&utm_relevant_index=5 pytorchç‰ˆyolov3è®­ç»ƒè‡ªå·±æ•°æ®é›† https://www.cnblogs.com/pprp/p/10863496.htmlhttps://github.com/BobLiu20/YOLOv3_PyTorchhttps://github.com/cxjaicj/keras-yolo3https://github.com/pprp/yolov3.keras ImportError:æ— æ³•ä»â€œtensorflowâ€å¯¼å…¥åç§°â€œSessionâ€ https://www.cnpython.com/qa/1297701 Adamä¼˜åŒ–ç®—æ³•è¯¦ç»†è§£æ https://blog.csdn.net/luoxuexiong/article/details/90412213https://www.cnblogs.com/wuchengze/p/13610500.html ç†è§£è¯­è¨€çš„ Transformer æ¨¡å‹ https://tensorflow.google.cn/tutorials/text/transformer papers åç§° ç½‘å€ Vision Transformer å¿…è¯»ç³»åˆ—ä¹‹å›¾åƒåˆ†ç±»ç»¼è¿°(ä¸€)ï¼šæ¦‚è¿° https://zhuanlan.zhihu.com/p/459828118 é¢å‘å¤šåœºæ™¯ä½èµ„æºåŠ å¯†æµé‡åˆ†ç±»çš„åŠ å¯†æµé‡é¢„è®­ç»ƒæŠ€æœ¯ https://zhuanlan.zhihu.com/p/483285843 è·¨æ¨¡æ€æ£€ç´¢ Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval https://zhuanlan.zhihu.com/p/398898919 è·¨æ¨¡æ€æ£€ç´¢è®ºæ–‡è§£è¯» Similarity Reasoning and Filtration for Image-Text Matching https://zhuanlan.zhihu.com/p/394203914 è®ºæ–‡ç¬”è®° FPN â€”â€” ç‰¹å¾é‡‘å­—å¡” https://zhuanlan.zhihu.com/p/92005927 ä¸­å›½åŒ»å­¦å½±åƒ AI çš„ 20 å¹´ã€Œå¤§å˜å±€ã€ä¸‡å­—é•¿æ–‡ https://baijiahao.baidu.com/s?id=1722558686425634791&wfr=spider&for=pc Others åç§° ç½‘å€ è§£å†³ Failed to connect to github.com port 443:connection timed out https://blog.csdn.net/Hodors/article/details/103226958 pythonå·¥å…·-å°†è§†é¢‘æŒ‰å¸§æˆªå–å›¾ç‰‡ï¼ˆé™„ä»£ç ï¼‰ https://blog.csdn.net/qq_36190978/article/details/85284484 pythonä¸­sortedæ˜¯ä»€ä¹ˆ https://m.php.cn/article/423733.html Python3åˆ›å»ºç›®å½•mkdir https://blog.csdn.net/weixin_51697369/article/details/119864944 python enumerateç”¨æ³•æ€»ç»“ https://blog.csdn.net/churximi/article/details/51648388 pythonçš„æ–‡ä»¶æ“ä½œ https://blog.csdn.net/zhandar44/article/details/95995091 è¯è¢‹æ¨¡å‹ https://github.com/gurkandemir/Bag-of-Visual-Wordshttps://github.com/cleanlii/bow-image-retrieval Standford cv reports 2017 http://cs231n.stanford.edu/reports/2017/pdfs/ æœºå™¨å­¦ä¹ æ€§èƒ½åº¦é‡æŒ‡æ ‡precisionã€recallã€PRæ›²çº¿ã€F1ã€ROCã€AUCã€IOUã€mAPï¼‰ https://blog.csdn.net/xhj_enen/article/details/88639920 Transformer æ¨¡å‹è¯¦è§£ https://baijiahao.baidu.com/s?id=1651219987457222196&wfr=spider&for=pc A Step by Step Backpropagation Example https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ Math for Computer Graphics https://faculty.cc.gatech.edu/~turk/math_gr_new.html ç”¨Pythonè¯»å–CSVæ–‡ä»¶çš„5ç§æ–¹å¼ https://blog.csdn.net/qq_40907977/article/details/108054088 Shellè„šæœ¬ç¼–å†™ https://blog.csdn.net/weixin_35784267/article/details/116582780 markdownè¡¨æ ¼ https://www.runoob.com/markdown/md-table.html DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 23:01:44 "},"Mix/4.html":{"url":"Mix/4.html","title":"å²—ä½èµ„æº","keywords":"","body":"å²—ä½èµ„æº NOTICE: åœ¨æ¯ä¸€ä¸ªåˆ†éš”æ ä¹‹é—´ï¼ŒæŒ‰ç…§æ—¶é—´çš„é¡ºåºï¼Œæœ€æ–°çš„æ¶ˆæ¯éƒ½åœ¨æœ€ä¸Šæ–¹æ˜“äºå¯»æ‰¾ Job Intern åä¸ºäº‘ Release Time: 5/31 2022 åä¸ºäº‘AIç®—æ³•å®ä¹ ç”Ÿ ï¼ˆå†…æ¨ã€å’¨è¯¢å¯åŠ å¾®ä¿¡ï¼šzhixing1055321398ï¼‰ å·¥ä½œå†…å®¹ï¼š è´Ÿè´£åä¸ºäº‘è¯­è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰é¢†åŸŸçš„ç®—æ³•åŠå¹³å°ç ”å‘ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ™ºèƒ½é—®ç­”ã€çŸ¥è¯†å›¾è°±ã€é¢„è®­ç»ƒå¤§æ¨¡å‹ã€è¯­éŸ³åˆæˆã€æ•°å­—äººæ„å»ºã€å¤šæ¨¡æ€é¢„è®­ç»ƒç­‰é¢†åŸŸç›¸å…³æ¨¡å‹çš„æ„å»ºã€ä¼˜åŒ–ã€è®ºæ–‡å‘è¡¨å’Œç®—æ³•è½åœ°ç­‰å·¥ä½œã€‚ æŠ€èƒ½è¦æ±‚ï¼š æ‰å®çš„ç®—æ³•å’Œç¼–ç¨‹åŸºç¡€ï¼Œç†Ÿæ‚‰æœºå™¨å­¦ä¹ åŸºæœ¬ç†è®ºï¼› å…·æœ‰è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€è¯­éŸ³æˆ–è®¡ç®—æœºè§†è§‰ç›¸å…³çŸ¥è¯†å’ŒæŠ€èƒ½ï¼Œè‡³å°‘åœ¨å…¶ä¸­ä¸€ä¸ªå­é¢†åŸŸæœ‰è¾ƒæ·±çš„ç†è§£å’Œç»éªŒï¼Œåœ¨é«˜æ°´å¹³å›½é™…ä¼šè®®æœŸåˆŠå‘è¡¨è¿‡è®ºæ–‡è€…ä¼˜å…ˆï¼› ç†Ÿç»ƒæŒæ¡è‡³å°‘ä¸€ç§ç¼–ç¨‹è¯­è¨€ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºJavaï¼ŒPython)ï¼Œç†Ÿæ‚‰Tensorflowã€Pytorchç­‰å¼€å‘æ¡†æ¶è€…ä¼˜å…ˆã€‚ å·¥ä½œåœ°ç‚¹ï¼šæ­å·ï¼Œæ·±åœ³ï¼Œè¥¿å®‰ï¼ŒåŒ—äº¬ æ´›å‡¯ç§‘æŠ€ Release Time: 5/28 2022 æˆ‘ä»¬å°±æ˜¯æ´›å‡¯ç§‘æŠ€ï¼ˆRockey Techï¼‰ï¼Œä¸€å®¶ä¸“æ³¨æµ·å¤–ç¤¾äº¤çš„ç‹¬è§’å…½ä¼ä¸šğŸš€ ã€é«˜è–ªäº§å“/è¿è¥å®ä¹ å²—ï¼Œæ—¥è–ª200èµ·ã€‘ã€å®£è®²é€iphone13ã€switchçš„å…¬å¸ã€‘ å²—ä½æ‹›æ»¡å³æ­¢ï¼Œbaseï¼šåŒ—äº¬ï¼›æ‹›å‹ŸèŒƒå›´ï¼š23-25å±Šæ¯•ä¸šç”Ÿï¼›ã€å†…æ¨ç ã€‘CDEJ7V1 ç½‘ç”³é“¾æ¥ï¼šhttps://rockey.jobs.feishu.cn/index/m/?spread=MKX77B9 éƒ¨é—¨æ€¥æ‹›å²—ä½å¾…é‡æ›´å¥½ï¼Œä¼˜å…ˆç­›é€‰ï¼Œå…ç¬”è¯•ï¼ŒåŠ©ä½ æ›´å¿«æ‹¿offerâ—ï¸ ğŸ†˜ æ¸¸æˆç¤¾åŒºäº§å“è¿è¥å®ä¹ ç”Ÿï¼ˆ200~300å…ƒ/å¤©ï¼‰ è´Ÿè´£å¹³å°æ¸¸æˆåº“çš„æ›´æ–°å’Œç»´æŠ¤, æ–°æ¸¸æ¨èï¼› è´Ÿè´£ç¤¾åŒºç”¨æˆ·è¿è¥, ç»´æŒç”¨æˆ·æ´»è·ƒåŠå›æµ; è´Ÿè´£ç¤¾åŒºå†…å®¹è¿è¥, ç¡®ä¿äº§èƒ½ä¸å†…å®¹è´¨é‡ç¬¦åˆéœ€æ±‚ï¼› èƒ½å¤Ÿç‹¬ç«‹è¿›è¡Œæ•°æ®åˆ†æã€‚ ğŸ†˜ å†…å®¹å¢é•¿è¿è¥å®ä¹ ç”Ÿ(seoæ–¹å‘) ï¼ˆ300~400å…ƒ/å¤©ï¼‰ è´Ÿè´£é¡¹ç›®SEOæµ·å¤–å¢é•¿ä¸šåŠ¡; SEOæµé‡ç›‘æ§ä¸æ•°æ®åˆ†æï¼Œé€šè¿‡æ•°æ®å˜åŒ–è°ƒæ•´ä¼˜åŒ–ç­–ç•¥ï¼Œé£é™©é¢„è­¦ï¼› æ‰§è¡Œæµ·å¤–ç½‘ç«™å†…å®¹ä¼˜åŒ–ï¼Œé€šè¿‡å†…å®¹è´¨é‡æé«˜SEOæ’åï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼› ç®¡ç†æœç´¢å¼•æ“ç›¸å…³å¹¿å‘Šè´¦æˆ·ï¼Œé€šè¿‡è´¦æˆ·è¡¨ç°è°ƒæ•´è´¦æˆ·æŠ•æ”¾æ–¹å‘ã€‚ ğŸ†˜ æ¸¸æˆç¼–è¾‘å®ä¹ ç”Ÿï¼ˆ200~300å…ƒ/å¤©ï¼‰ äº†è§£æ¸¸æˆç©å®¶çš„ä¸åŒé£æ ¼ã€å–œçˆ±çš„æ¸¸æˆç±»å‹,å¯Œæœ‰åŒç†å¿ƒï¼› å¯¹æ¸¸æˆæ„Ÿå…´è¶£ï¼Œæœªæ¥è‡´åŠ›äºä»äº‹æ¸¸æˆè¡Œä¸šçš„åŒå­¦ï¼› è´Ÿè´£å…¬å¸å¹³å°çš„æ¸¸æˆæ¨èå’Œæµ‹è¯„ã€‚ ğŸ†˜ æ¸¸æˆç¤¾åŒºäº§å“ç»ç†å®ä¹ ç”Ÿ ï¼ˆ300~400å…ƒ/å¤©ï¼‰ è´Ÿè´£æ¸¸æˆç¤¾åŒºäº§å“åŠŸèƒ½ç­–åˆ’å’Œè¿­ä»£ï¼Œæé«˜ç•™å­˜å’Œç”¨æˆ·æ´»è·ƒåº¦ï¼› åŸºäºæ•°æ®åˆ†æç”¨æˆ·ç‰¹å¾ï¼ŒæŒ–æ˜ç”¨æˆ·éœ€æ±‚ï¼Œè®¾è®¡æœ‰æ•ˆçš„äº§å“æ–¹æ¡ˆï¼Œå¯¹è½¬åŒ–ã€ç•™å­˜ã€å¬å›ç­‰å„ç¯èŠ‚æŒ‡æ ‡è´Ÿè´£; é…åˆè¿è¥åŠä¸šåŠ¡éœ€æ±‚ï¼Œè´Ÿè´£å¹³å°èµ„æºåˆ†é…ç­–ç•¥ä¼˜åŒ–ï¼Œæå‡èµ„æºåˆ†å‘æ•ˆç‡ã€‚ ğŸ†˜ å†…å®¹è¿è¥å®ä¹ ç”Ÿï¼ˆ300~400å…ƒ/å¤©ï¼‰ è´Ÿè´£è´´çº¸äº§å“å†…å®¹è¿è¥ï¼ŒåŒ…æ‹¬æ—¥å¸¸å†…å®¹æ›´æ–°ã€ä¼˜åŒ–ã€å“ç±»æµ‹è¯•; å…³æ³¨ç”¨æˆ·åé¦ˆï¼Œé’ˆå¯¹ç”¨æˆ·åé¦ˆæå‡ºå¯ä¼˜åŒ–çš„äº§å“å»ºè®®ï¼› é…åˆå®Œæˆäº§å“æŠ•æ”¾ï¼Œé’ˆå¯¹æŠ•æ”¾åœ°åŒºè¿›è¡Œç´ æä¼˜åŒ–ã€‚ å¹¿è”è¾¾ Release Time: 5/21 2022 å¹¿è”è¾¾ç§‹æ‹›æå‰æ‰¹&æš‘æœŸå®ä¹ å†…æ¨ ğŸŒŸæœ¬æ¬¡æå‰æ‰¹ä¸å½±å“ç§‹æ‹›æ­£å¼æŠ•é€’ï¼›æ— è¿çº¦é‡‘ï¼Œåˆ«äººè¿˜åœ¨æ‰¾å®ä¹ ï¼Œä½ å´å·²ç»æ‹¿äº†ä¿åº•offerï¼› ğŸŒŸåŒä¼‘åˆ¶ï¼Œå…¬ç§¯é‡‘æ»¡é¢ç¼´çº³ Base: å…¨å›½å¤šåœ°å¯é€‰ âœ”ï¸æå‰æ‰¹å²—ä½ï¼šC++å¼€å‘å·¥ç¨‹å¸ˆã€Javaå¼€å‘å·¥ç¨‹å¸ˆã€å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆã€å›¾å½¢å¼€å‘å·¥ç¨‹å¸ˆã€ å›¾å½¢ ç®—æ³•å¼€å‘å·¥ç¨‹å¸ˆã€äººå·¥æ™ºèƒ½å·¥ç¨‹å¸ˆã€ æµ‹è¯•å¼€å‘å·¥ç¨‹å¸ˆã€äº§å“ç»ç† âœ”ï¸æš‘æœŸå®ä¹ å²—ä½ï¼šé”€å”®å·¥ç¨‹å¸ˆã€æœåŠ¡å·¥ç¨‹å¸ˆã€å®æ–½å·¥ç¨‹ ç½‘ç”³é“¾æ¥ğŸ‘‡ https://app.mokahr.com/m/campus_apply/glodon/1750?recommendCode=DSnskg8B#/jobs å†…æ¨ç ğŸ‘‰DSnskg8B [çˆ±å¿ƒ]å¹¿è”è¾¾2023å±Šæ ¡å›­æ‹›è˜æ¥å•¦ï¼[çˆ±å¿ƒ] [åº†ç¥]å¹¿è”è¾¾ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸æˆç«‹äº1998 å¹´ï¼Œé•¿æœŸç«‹è¶³å»ºç­‘äº§ä¸šï¼Œå›´ç»•å»ºè®¾å·¥ç¨‹é¡¹ç›®çš„å…¨ç”Ÿå‘½å‘¨æœŸï¼Œæ˜¯æä¾›ä»¥å»ºè®¾å·¥ç¨‹é¢†åŸŸä¸“ä¸šåº”ç”¨ä¸ºæ ¸å¿ƒåŸºç¡€æ”¯æ’‘ï¼Œä»¥äº§ä¸šå¤§æ•°æ®ã€äº§ä¸šæ–°é‡‘èä¸ºå¢å€¼æœåŠ¡çš„æ•°å­—å»ºç­‘å¹³å°æœåŠ¡å•†ã€‚å¹¿è”è¾¾ç»è¿‡ 20 ä½™å¹´çš„å‘å±•ï¼Œåœ¨å…¨çƒå»ºç«‹ 80 ä½™å®¶åˆ†å­å…¬å¸ï¼Œæ‹¥æœ‰å‘˜å·¥8000ä½™äººï¼Œæ¶µç›–å…¨äº§ä¸šé“¾åŒ…å«è®¾è®¡ã€é€ ä»·ã€æ–½å·¥ã€è¿ç»´ã€ä¾›é‡‡ã€å›­åŒºï¼Œä»¥åŠé‡‘èã€æ•™è‚²ã€æŠ•èµ„å¹¶è´­ç­‰ä¸šåŠ¡ï¼Œä¸º30ä½™ä¸‡ä¼ä¸šç”¨æˆ·ï¼Œç™¾ä¸‡ä¸“ä¸šå·¥ç¨‹æŠ€æœ¯å’Œç®¡ç†äººå‘˜ï¼Œæä¾›è¿‘ç™¾æ¬¾ä¸“ä¸šåº”ç”¨äº§å“åŠæœåŠ¡ã€‚ [åº†ç¥]é¢å‘2023å¹´åº”å±Šç”Ÿï¼Œæœ¬ç§‘åŠä»¥ä¸Šå­¦å†ï¼Œç¡•å£«ã€åšå£« ä¼˜å…ˆï¼›è®¡ç®—æœºã€æ•°å­¦ã€æœºæ¢°ã€åœŸæœ¨ã€å»ºç­‘ã€GISã€ä»¿çœŸã€äººå·¥æ™ºèƒ½/è‡ªåŠ¨åŒ–ã€è½¯ä»¶å·¥ç¨‹ç­‰ç†å·¥ç§‘ç›¸å…³ä¸“ä¸šä¼˜å…ˆï¼Œå…¶ä»–ä¸“ä¸šä¸é™ï¼› [åº†ç¥]å·¥ä½œåœ°ï¼šTOTç ”å‘åºåˆ—bsaeåŒ—äº¬ã€ä¸Šæµ·ã€è¥¿å®‰ã€å¹¿å·ï¼ŒEOEé”€æœåºåˆ—baseå…¨å›½ï¼ˆå…·ä½“å²—ä½å·¥ä½œåŸå¸‚å¯åœ¨ æŠ•é€’æ—¶æŸ¥çœ‹ï¼‰ [åº†ç¥]å²—ä½è–ªé…¬ï¼šTOTç ”å‘å²—ä½30W+ï¼ŒEOEé”€æœå²—ä½15W+ ç¨³å®šèˆ’é€‚çš„åŠå…¬ç¯å¢ƒï¼Œä¸Šå¸‚å…¬å¸å¤§å¹³å°ï¼Œç¦åˆ©å¾…é‡å¥½ï¼Œæ¨ªå‘çºµå‘å¤šç§å‘å±•é€šé“ï¼› ä¸ƒé™©ä¸€é‡‘ï¼ˆåŒ…æ‹¬å•†ä¸šæ„å¤–é™©+è¡¥å……åŒ»ç–—ï¼‰ï¼ŒåŒä¼‘ï¼Œæ³•å®šèŠ‚å‡æ—¥åŠå¸¦è–ªå¹´å‡ï¼› èŠ‚æ—¥ç¦åˆ©ï¼ˆæ³•å®šèŠ‚å‡æ—¥åŠå¦‡å¥³èŠ‚ã€äº”å››é’å¹´èŠ‚ã€æ¯äº²èŠ‚ã€å„¿ç«¥èŠ‚ã€åœ£è¯èŠ‚ç­‰ï¼‰ç”Ÿæ—¥ç¤¼å“æƒŠå–œï¼Œæœˆåº¦å’Œå­£åº¦å¥–é‡‘ï¼› åˆé¤è¡¥åŠ©ã€äº¤é€šå’Œé€šä¿¡è¡¥åŠ©ï¼Œé«˜æ¸©è¡¥è´´ã€å¹´ç»ˆå¥–ç­‰ï¼› æ¯å¹´å®šæœŸå…è´¹ä½“æ£€ï¼Œä¿è¯å‘˜å·¥èº«ä½“å¥åº·ï¼› å¹´åº¦å›½å†…ã€å¤–æ—…æ¸¸å›¢å»ºã€‚ [åº†ç¥]åŠ å…¥æˆ‘ä»¬ï¼š ã€å†…æ¨ç ã€‘DSnskg8B PC ç«¯ç½‘ç”³é€šé“ï¼šhttp://campus.glodon.com ç§»åŠ¨ç«¯ç½‘ç”³é€šé“ï¼šå…³æ³¨â€œå¹¿è”è¾¾æ‹›è˜â€å…¬ä¼—å· é›†å›¢å®˜ç½‘ï¼šwww.glodon.com è”ç³»ç”µè¯ï¼š18071552535ï¼ˆé»„ï¼‰ï¼Œ15007120648ï¼ˆæœ±ï¼‰ï¼ˆå¾®ä¿¡åŒå·ï¼‰ æ€»éƒ¨åœ°å€ï¼šä¸­å›½-åŒ—äº¬-æµ·æ·€åŒºè¥¿åŒ—æ—ºä¸œè·¯10å·é™¢ä¸œåŒº13å·æ¥¼å¹¿è”è¾¾ä¿¡æ¯å¤§å¦ æ¹–åŒ—åˆ†å…¬å¸åœ°å€ï¼šæ­¦æ±‰å¸‚æ­¦æ˜ŒåŒºå¾ä¸œå¤§è¡—ç¾¤æ˜ŸåŸK3-2åº§20æ¥¼ å›¾æ£®æœªæ¥ Release Time: 5/08 2022 ã€é«˜è–ªå¤–ä¼å†…æ¨ï¼Œå›¾æ£®æœªæ¥ã€‘ã€åº”å±Š/å®ä¹ ã€‘ ğŸŒŸè§£å†³åŒ—äº¬ã€ä¸Šæµ·æˆ·å£/ä¸ƒé™©ä¸€é‡‘/åŒä¼‘/å…¬ç§¯é‡‘ç¼´çº³12%/å®ä¹ æä¾›å…è´¹ä½æˆ¿/å®ä¹ æœˆè–ª8kèµ·/ç®—æ³•å²—8å¡2080Tiæ ‡é…â€¦ ğŸ”¥æ— äººé©¾é©¶é¢†åŸŸå…¨çƒé¦–å®¶ä¸Šå¸‚å…¬å¸ï¼Œé¢å‘å…¨çƒæä¾›å¯å¤§è§„æ¨¡å•†ä¸šåŒ–è¿è¥çš„æ— äººé©¾é©¶å¡è½¦æŠ€æœ¯ï¼Œå¹¶å¯åŠ¨å…¨çƒé¦–ä¸ªæ— äººé©¾é©¶è´§è¿ç½‘ç»œã€‚ ç½‘ç”³é“¾æ¥ğŸ‘‡ https://app.mokahr.com/m/campus_apply/tusenweilai/35932?recommendCode=DSK8Wgdv#/jobs å†…æ¨ç ğŸ‘‰DSK8Wgdv å·¥ä½œåœ°ç‚¹ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å›½å¤– é’è—¤äº‘ Release Time: 4/26 2022 é’è—¤äº‘å®‰å…¨-ä¿¡æ¯å®‰å…¨å®ä¹ ç”Ÿæ‹›è˜ï¼ˆ6æœˆåˆ°å²—å³å¯ï¼‰ ã€å·¥ä½œåœ°ç‚¹ã€‘ åŒ—äº¬å¸‚æµ·æ·€åŒºåˆ›ä¸šè·¯8å·ç¾¤è‹±ç§‘æŠ€å›­ ã€å·¥ä½œèŒè´£ã€‘ pythonä¸shellæ¶æ„è„šæœ¬æ£€æµ‹å¼•æ“çš„å¼€å‘ï¼› æ¶æ„è„šæœ¬æ£€æµ‹å¼•æ“çš„æµ‹è¯•ï¼› æœé›†æ¶æ„è„šæœ¬ä»¥åŠä¸šç•Œçš„æ£€æµ‹æ–¹å¼ï¼› ã€ä»»èŒèµ„æ ¼ã€‘ æœ¬ç§‘æˆ–ä»¥ä¸Šå­¦å†ï¼› ç†Ÿæ‚‰pythonã€shellå’Œcè¯­è¨€ï¼Œä½¿ç”¨pythonæˆ–cåšè¿‡å®é™…é¡¹ç›®ï¼› äº†è§£ç¼–è¯‘åŸç†ï¼Œç†Ÿæ‚‰è„šæœ¬è¯­è¨€å†…éƒ¨æ‰§è¡Œè¿‡ç¨‹ï¼› å¯¹ç½‘ç»œå®‰å…¨çŸ¥è¯†æœ‰ä¸€å®šäº†è§£ï¼Œç†Ÿæ‚‰å¸¸è§çš„è„šæœ¬åˆ©ç”¨æ¼æ´ï¼› ã€å·¥ä½œæ—¶é•¿ã€‘ 9ï¼š30â€”19ï¼š00 ã€ç¦åˆ©å¾…é‡ã€‘ å®ä¹ è¡¥è´´180-200/å¤©ï¼Œæœ‰é¤è¡¥ã€æˆ¿è¡¥ã€ç”µè„‘è¡¥è´´ï¼Œå¯å¼€å…·å®ä¹ è¯æ˜ï¼Œå›¢é˜Ÿæ°›å›´nice ã€ç”³è¯·æ–¹å¼ã€‘ å°†ç®€å†å‘é€è‡³ hanyl1104@163.comï¼Œç®€å†åŠé‚®ä»¶å‘½åæ ¼å¼ä¸ºã€å§“å+å­¦æ ¡+ä¸“ä¸šã€‘ æœ‰é—®é¢˜åŠ wx 13641251014 OPPO Release Time: 4/14 2022 OPPO22å±Šæ˜¥æ‹›ï½œ23å±Šæš‘æœŸå®ä¹ ç”Ÿç«çƒ­å¼€å¯ï¼æŠ•é€’ä½¿ç”¨å†…æ¨ç ä¼˜å…ˆç­›é€‰! å†…æ¨ç ï¼šXYDS42780811 ç½‘ç”³ç½‘å€ï¼šhttps://careers.oppo.com/campus è½¯ä»¶ç±»ã€ç¡¬ä»¶ç±»ã€AI/ç®—æ³•ç±»ã€äº§å“ç±»ã€å·¥ç¨‹æŠ€æœ¯ç±»ã€é‡‡è´­ç±»ã€å“ç‰Œç­–åˆ’ç±»ã€é”€å”®æœåŠ¡ç±»ã€ç»¼åˆèŒèƒ½ç±» æ€»æœ‰ä¸€æ¬¾é€‚åˆä½  OPPOå·¥ä½œç¯å¢ƒVRä¸Šçº¿ï¼Œæ¬¢è¿æ²‰æµ¸ä½“éªŒï¼šhttps://720yun.com/t/38vkz9fwgpl#scene_id=78676648 2022å±Šæ˜¥æ‹›ç¼ºå£è¾ƒå¤šå²—ä½(ä¾æ¬¡æ’åº)ï¼šç³»ç»Ÿå·¥ç¨‹å¸ˆï¼Œå®‰å“åº”ç”¨å·¥ç¨‹å¸ˆï¼Œé©±åŠ¨å·¥ç¨‹å¸ˆï¼Œæ— çº¿é€šä¿¡åè®®å·¥ç¨‹å¸ˆï¼ŒLinuxç³»ç»Ÿå·¥ç¨‹å¸ˆï¼Œå¤šåª’ä½“å¼€å‘å·¥ç¨‹å¸ˆï¼Œè®¡ç®—æœºè§†è§‰ç®—æ³•å¼€å‘å·¥ç¨‹å¸ˆ å®ä¹ ç”Ÿå²—ä½ç¼ºå£ï¼š éæŠ€æœ¯ç±»ç¼ºå£è¾ƒå¤šçš„å²—ä½ï¼šè´¢åŠ¡ç®¡ç†ä¸“å‘˜ï¼Œå…³åŠ¡ç®¡ç†ä¸“å‘˜ æŠ€æœ¯ç±»ç¼ºå£è¾ƒå¤šçš„å²—ä½ï¼šè®¡ç®—æœºè§†è§‰ç®—æ³•ï¼Œå½±åƒç®—æ³•ï¼Œlinuxç³»ç»Ÿï¼Œå®‰å“åº”ç”¨(ç¼ºå£æœ€å¤§)ï¼Œå¤šåª’ä½“å¼€å‘ï¼Œå¤šåª’ä½“ç³»ç»Ÿï¼Œé©±åŠ¨ï¼Œç³»ç»Ÿå·¥ç¨‹å¸ˆ(ç¼ºå£æ¬¡å¤š)ï¼Œè½¯ä»¶æµ‹è¯•å¼€å‘(ç¼ºå£ç¬¬ä¸‰å¤š) å†…æ¨ç XYDS42780811 OPPOåç§‘å®˜æ–¹æ ¡æ‹›ç¾¤ 913802534 ç™¾åº¦ Release Time: 4/13 2022 ç™¾åº¦23å±Šå®ä¹ å†…æ¨ ï¼Œå³å°†æˆªæ­¢ ğŸŒŸ 600+OFFER å‘æ”¾ã€å¤šç§å²—ä½é€‰æ‹©ï¼Œå®ä¹ è½¬æ­£ç‡è¶…è¿‡70% ğŸŒŸ å†…æ¨ç®€å†å…ç­›é€‰ ï¼Œç›´è¾¾ç¬”è¯• åœ°ç‚¹ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³ã€å¤§è¿ ç½‘ç”³ğŸ‘‰ https://talent.baidu.com/ å†…æ¨ç ğŸ‘‰ISKWSB ãŠ™ï¸ç§‹æ‹›æå‰æ‰¹7æœˆå¼€å¯ï¼Œå†…æ¨å…ç¬”è¯•ï¼Œ ç›´é€šé¢è¯•ï½æ²¡åŠæ³•å®ä¹ çš„åŒå­¦ï¼Œè®°å¾—æ”¶è—å†…æ¨ç ï¼Œç§‹æ‹›æå‰æ‰¹åŠ©ä½ æ›´å¿«æ‹¿ offerâ— æ·±ä¿¡æœ Release Time: 4/10 2022 æ·±ä¿¡æœå®ä¹ ç”Ÿæ‹›è˜ å²—ä½ï¼šå¼€å‘ç±»ã€å¸‚åœºç±»ã€å®‰å…¨ç±»ã€ç®—æ³•ç±»ã€äº§å“è§„åˆ’ç±»ç­‰å…­â¼¤ç±»å²—ä½ åœ°ç‚¹ï¼šæ·±åœ³ã€â»“æ²™ã€åŒ—äº¬ã€å—äº¬ ç¦åˆ©ï¼šåŒ…ä½å®¿ã€åŒ…ä¸‰é¤ã€åŒ…å¾€è¿”è½¦ç¥¨ã€æœˆè–ª4000èµ·ï¼Œæ›´å¤šç¦åˆ©ç­‰ä½ è§£é” æŠ•é€’é€šé“ï¼š pcç«¯ï¼šhttps://app.mokahr.com/campus_apply/sangfor/6146#/home â¼¿æœºç«¯ï¼šå…³æ³¨ã€æ·±ä¿¡æœæ‹›è˜ã€‘-ã€æ ¡å›­æ‹›è˜ã€‘-ã€å®ä¹ æ‹›è˜ã€‘ ä¿¡æœåœˆï¼ˆä¸ºäº†æ›´å¥½çš„é€šè¿‡é¢è¯•ï¼Œå»ºè®®å¤§å®¶å…³æ³¨ä¿¡æœåœˆå„¿è¿›è¡Œå­¦ä¹ ï¼‰ï¼š äººç¾¤ï¼š å¯¹ç®€å†å¦‚ä½•ä¹¦å†™ã€é¢è¯•å¦‚ä½•å‡†å¤‡æœ‰ç›¸å…³ç–‘æƒ‘çš„ å·²ç»æ˜ç¡®äº†è‡ªå·±çš„æ±‚èŒæ–¹å‘ï¼Œæƒ³è¦æå‡èƒ½åŠ›çš„ æƒ³è¦å’Œæ›´å¤šå¿—åŒé“åˆçš„äººä¸€èµ·äº¤æµæ±‚èŒæƒ³æ³•çš„ ä¸ç¡®å®šè‡ªå·±æœªæ¥èŒä¸šå‘å±•æ–¹å‘è¯¥å¦‚ä½•åšæŠ‰æ‹©çš„ å†…å®¹ï¼šä½“ç³»åŒ–çš„å¸‚åœºè¯¾ç¨‹ã€hr æ¨¡æ‹Ÿé¢è¯•ã€ç ”å‘æ ¡æ‹›çœŸé¢˜ã€å­¦é•¿å­¦å§çˆ†æ–™ç­‰ ç¦åˆ©ï¼šå…è´¹çš„ç®€å†æ¨¡æ¿ï¼Œä¸“ä¸šåŒ–çš„hrè¾…å¯¼ï¼Œæµ·é‡çš„è¡Œä¸šçŸ¥è¯†ç­‰ å¦‚ä½•å…³æ³¨ï¼š æ‰«ç æˆ–ç›´æ¥å¾®ä¿¡å…¬ä¼—å·æœç´¢ã€ä¿¡æœåœˆâ¼‰ã€‘è¿›è¡Œå…³æ³¨ æ›´å¤šè¯¦æƒ…ï¼šhttps://mp.weixin.qq.com/s/RIRirwgM72dqCeBgloNlLg åŒ—äº¬æ³°é“¼æŠ•èµ„ Release Time: 4/2 2022 æ˜¥å­£æ ¡æ‹›/å®ä¹  é‡åŒ–ç ”ç©¶å‘˜/äº¤æ˜“å‘˜/å¸‚åœº/æ•°æ®å¼€å‘...å¤šå²—ä½æ‹›å‹Ÿä¸­ğŸ“® æ—¶é—´ï¼šå®ä¹ å²—ä½éœ€å®ä¹ æ»¡4ä¸ªæœˆåŠä»¥ä¸Šï¼Œæ ¡æ‹›å²—éœ€æ¯•ä¸šå‰å®ä¹ [å¤ªé˜³] å·¥ä½œåœ°ç‚¹ï¼šåŒ—äº¬è¥¿åŸåŒºè¥¿ç¯å¹¿åœº å·¥ä½œå†…å®¹: æ¶‰åŠé‡åŒ–æŠ•ç ”ã€äºŒçº§å¸‚åœºäº¤æ˜“ã€é‡‘èæœºæ„å¯¹æ¥åˆä½œã€äº¤æ˜“ç³»ç»Ÿå¼€å‘ç­‰å¤šç§æ–¹å‘ å¸Œæœ›ä½ : 2022å±Šæˆ–2023å±Šå›½å†…å¤–åº”å±Šæ¯•ä¸šç”Ÿ æœ‰æ•°å­¦ã€è®¡ç®—æœºã€é‡‘èç­‰ç›¸å…³ä¸“ä¸šèƒŒæ™¯ï¼Œä¸“ä¸šåŸºç¡€æ‰å®ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè¡¨è¾¾æ¸…æ¥š æœ‰é‡åŒ–æŠ•èµ„æˆ–äº’è”ç½‘ç®—æ³•/å¼€å‘ç›¸å…³å®ä¹ ç»éªŒçš„åŒå­¦ä¼˜å…ˆ è–ªé…¬ç¦åˆ©ï¼š ç ”ç©¶å®ä¹ ç”ŸRMB 400~600/å¤©ï¼Œ ç ”å‘å®ä¹ ç”ŸRMB 300/å¤©ï¼Œæ ¡æ‹›è–ªèµ„å•ç‹¬æ²Ÿé€šï¼Œwlbæ‹’ç»996 è¡¨ç°ä¼˜ç§€çš„å®ä¹ ç”Ÿå°†è¢«æ¨èå‚ä¸ä¹‹åçš„é¡¹ç›®ï¼Œå¹¶å¯è·å¾—è½¬æ­£æœºä¼š å…¬å¸æ­£å¼å®ä¹ ç”Ÿï¼Œå¯å¼€å®ä¹ è¯æ˜ å†…æ¨ç ï¼šDS5bJZPu è…¾è®¯ Release Time: 2/18 2022 ğŸ”¥ è…¾è®¯2022å®ä¹ ç”Ÿæ‹›è˜å³å°†å¯åŠ¨ï¼ æ¬¢è¿å¤§å®¶æœç´¢/æ‰«ç åŠ å…¥ã€è…¾è®¯åä¸­åŒº23å±Šå®˜æ–¹å®ä¹ äº¤æµç¾¤ã€‘ ç¾¤å†…å°†ä¼šæä¾›ï¼š è…¾è®¯å®˜æ–¹æ‹›è˜ä¿¡æ¯ è§£ç­”å…³äºå®ä¹ çš„å„ç§ç–‘é—® çº¿ä¸Šçº¿ä¸‹æ´»åŠ¨é¢„å‘Š âœ¨ æŠ€æœ¯ç±»QQç¾¤ç¾¤å·ï¼š701302439 âœ¨ éæŠ€æœ¯ç±»QQç¾¤ç¾¤å·ï¼š760545855 Research Intern Dr. Yang YOU in NUS Release Time: 4/20 2022 æ–°åŠ å¡å›½ç«‹å¤§å­¦(NUS) AIé«˜æ€§èƒ½è®¡ç®—å®éªŒå®¤å®ä¹ ç”Ÿæ‹›å‹Ÿï¼Œå¯¼å¸ˆä¸ºå°¤æ´‹è€å¸ˆï¼Œå°¤è€å¸ˆåšå£«æ¯•ä¸šäºåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ï¼Œå°¤è€å¸ˆä¸ªäººä¸»é¡µï¼šhttps://www.comp.nus.edu.sg/~youy/ï¼Œå®éªŒå®¤ä¸»é¡µï¼šhttps://ai.comp.nus.edu.sg/ æœ¬æ¬¡CVPR 2022å®éªŒå®¤æŠ•ç¨¿5ç¯‡è®ºæ–‡å…¨éƒ¨è¢«æ¥æ”¶ï¼š https://www.zhihu.com/question/502566228/answer/2379895566ã€‚ å°¤è€å¸ˆæ˜¯NUSçš„æ ¡é•¿é’å¹´æ•™æˆï¼Œå®éªŒå®¤æ°›å›´å¼€æ”¾ï¼ŒåŠ å…¥çš„è¯æœ‰å‘è¿‡é¡¶ä¼šçš„å­¦é•¿äº²è‡ªæŒ‡å¯¼ï¼Œå¯ä¾›é€‰æ‹©çš„æ–¹å‘åŒ…æ‹¬è‡ªç›‘ç£ã€æ•°æ®é›†æ²»ç†ã€è‡ªåŠ¨é©¾é©¶ã€å›¾åƒæ£€ç´¢ã€åº¦é‡å­¦ä¹ ç­‰ï¼Œå®ä¹ ç»“æŸåå¯ä»¥æä¾›åœ¨NUSçš„ç§‘ç ”ç»å†è¯æ˜ã€‚åœ¨å›½å†…çš„åŒå­¦å¯ä»¥æ¨èåˆ°é˜¿é‡Œã€å­—èŠ‚ã€ç¾å›¢ã€åä¸ºç­‰å…¬å¸çº¯ç§‘ç ”å®ä¹ ï¼Œæœ‰æ¡ä»¶çš„åŒå­¦ä¹Ÿå¯ä»¥ç”³è¯·ç»è´¹åˆ°æ–°åŠ å¡äº¤æµã€‚æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‘é‚®ä»¶åˆ°kai.wang@comp.nus.edu.sg VSRP of KAUST Release Time: é•¿æœŸæœ‰æ•ˆ é˜¿åœæœæ‹‰å›½ç‹ç§‘æŠ€å¤§å­¦çš„ VSRP(Visiting Student Research Program) é¡¹ç›®ï¼Œå…¨çƒç›¸å…³ç ”ç©¶é¢†åŸŸæœ¬ç§‘ç”Ÿã€ç¡•å£«ç”Ÿã€åšå£«ç”Ÿå‡å¯ç”³è¯·ï¼Œæ¯æœˆå·¥èµ„ 1000 USDï¼ŒåŠå…¬æä¾› Macï¼Œå¯ä»¥è§£å†³å‡ºè¡Œé—®é¢˜ï¼Œçº¿ä¸‹å‚åŠ éœ€è¦ä¸¤é’ˆå¾—åˆ°è®¤è¯çš„ç–«è‹—æ¥ç§è¯æ˜ï¼Œåœ¨COVID-19å¸­å·å…¨çƒæœŸé—´å¯ä»¥ç”³è¯·Remoteã€‚ å…·ä½“é¡¹ç›®ä¸ç›‘ç£è€…è¯¦è§ç½‘å€ï¼šhttps://vsrp.kaust.edu.sa PhD Position Dr.Lu Cheng in UIC Release Time: 5/5 2022 åç§‘å­¦å§ã€æ‹›ç”Ÿã€‘ä¼Šåˆ©è¯ºä¼ŠèŠåŠ å“¥åˆ†æ ¡ï¼ˆUICï¼‰- è®¡ç®—æœºç³» - åšå£«/ç¡•å£«/å®ä¹ ç”Ÿ - è´Ÿè´£ä»»äººå·¥æ™ºèƒ½/æ•°æ®æŒ–æ˜/å› æœæœºå™¨å­¦ä¹ /ç¤¾äº¤åª’ä½“æŒ–æ˜ (2022ç§‹ï¼Œ2023æ˜¥/ç§‹) https://www.1point3acres.com/bbs/thread-892043-1-1.html ä¼Šåˆ©è¯ºä¼Šå¤§å­¦èŠåŠ å“¥åˆ†æ ¡ï¼ˆthe University of Illinois at Chicago ç®€ç§° UICï¼‰ç”±åŸä¼Šåˆ©è¯ºä¼Šå¤§å­¦åŒ»å­¦ä¸­å¿ƒä¸ä½äºèŠåŠ å“¥çš„åˆ†æ ¡äº1982å¹´åˆå¹¶è€Œæˆæ˜¯ç¾å›½å›½å®¶èµ„åŠ©çš„å…¬ç«‹ç ”ç©¶å‹å¤§å­¦ä»¥åŠä¼Šåˆ©è¯ºä¼Šå¤§å­¦ç³»ç»Ÿçš„ç¬¬äºŒä¸ªæˆå‘˜å®åŠ›ä»…æ¬¡äºä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡ï¼›åŒæ—¶è¯¥æ ¡ä¹Ÿæ˜¯ç”±å¡å†…åŸºåŸºé‡‘ä¼šè¯„é€‰çš„88æ‰€ç ”ç©¶å‹ä¸€ç±»ç¾å›½å¤§å­¦ä»¥åŠå…¨ç¾æœ€å¤§çš„10æ‰€å¤§å­¦ä¹‹ä¸€ä½œä¸ºä¼Šåˆ©è¯ºä¼Šå¤§å­¦ç³»ç»Ÿä¸‰æ‰€åˆ†æ ¡ä¹‹ä¸€UICä½äºç¾å›½ä¼Šåˆ©è¯ºä¼Šå·èŠåŠ å“¥å¸‚ä¸­å¿ƒæ˜¯ä¸€æ‰€è‘—åçš„å…¬ç«‹ç ”ç©¶å‹å¤§å­¦åŒæ—¶ä¹Ÿæ˜¯èŠåŠ å“¥åœ°åŒºè§„æ¨¡æœ€å¤§ã€ç»¼åˆå®åŠ›æœ€å¼ºçš„å…¬ç«‹å¤§å­¦å­¦æ ¡å…±åˆ†ä¸ºä¸œã€è¥¿ã€å—ä¸‰ä¸ªæ ¡åŒºè®¡ç®—æœºç³»ä½äºä¸œæ ¡åŒºä¹Ÿæ˜¯æœ€å®‰å…¨çš„æ ¡åŒºUICè®¡ç®—æœºç³»2022å¹´USNewså…¨ç¾æ’å60èŠåŠ å“¥å…·æœ‰ä¼˜è¶Šçš„æµ·æ»¨åœ°ç†ç¯å¢ƒä»¥åŠè®¸å¤šé«˜æ¡£é¤é¥®åœºæ‰€èŠåŠ å“¥å¸‚ä¸­å¿ƒæ˜¯èŠåŠ å“¥æœ€é‡è¦çš„åŒºåŸŸä¹Ÿæ˜¯è¯¥åŸå¸‚èšé›†é‡‘èã€æ–‡åŒ–ã€æ”¿åºœå’Œå•†ä¸šæœºæ„çš„ä¸­å¿ƒ UICè®¡ç®—æœºç³»æ˜¯ä¸€ä¸ªä»¥ç ”ç©¶ä¸ºä¸»çš„é™¢ç³»ç›®å‰æ‹›æ”¶å¤šååšå£«ç”Ÿæ‰€æœ‰å½•å–åšå£«å‡æœ‰å¥–å­¦é‡‘ï¼ˆTA/RAï¼‰æ”¯æŒåœ¨PhDå‰ä¸¤å¹´æ‰€æœ‰å­¦ç”Ÿéƒ½æœ‰TAæœºä¼šä¸éœ€è¦å¯¼å¸ˆfundingæ”¯æŒå¯ä»¥è‡ªç”±é€‰æ‹©å¯¼å¸ˆUICè®¡ç®—æœºç³»åœ¨æ•°æ®æŒ–æ˜å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸéƒ½æœ‰éå¸¸å¥½çš„æˆå°±å…³äºæˆ‘ä¸ªäººä¿¡æ¯å°±ç”¨è‹±æ–‡äº† Fully funded PhD positions are available in Dr.LuCheng's lab (http://wwwpublicasuedu/~lcheng35/) in the Department of Computer Science at the University of Illinois at Chicago. The main research direction will be socially responsible AI (fairness, interpretability/explainability,privacy,robustness,domain generalization) causal machine learning and social media mining. Highly motivated master's students/undergraduate/interns are also very welcome to work with me. Dr.Lu Cheng received her Ph.D. degree in Computer Science at Arizona State University(ASU) in 2022 advised by Dr.Huan Liu, M.Eng. degree in Industrial Engineering at Rensselaer Polytechnique Institute(RPI) and B.Eng. degree in Industrial Engineering at Huazhong University of Science & Technology(HUST). Her research interests are broadly in data mining and machine learning, with aparticular focus on socially responsible AI, social computing, causal machine learning and AI for social good. Lu is the web chair of WSDM'22 and a senior program committee member of AAAI'22. She was the recipient of the 2021 ASU Engineering Dean's Dissertation Award, 2020 ASU Graduate Outstanding Research Award, 2021 and 2022 ASU CIDSE Doctoral Fellowship, 2022 SDM Best Poster Award, 2019 ASU Grace Hopper Celebration Scholarship, IBM Ph.D. Social Good Fellowship, Visa Research Scholarship and various Student Travel Awards and Scholarships. More information can be found at http://wwwpublicasuedu/lcheng35/ Requirement: A bachelor's degree in Computer Science Computer Engineering Electrical Engineering or related fields Experience in at least one major programming language Capabilities and willingness to learn new programming languages Enthusiasm for doing research Students who are interested in joining my lab as PhD students in Fall 2022 need to be US-based(Not applied to other semesters) Application Process: Please send your CV and transcript to luchengrecuit@gmailcom ç”±äºæœ€è¿‘deadlineæ¯”è¾ƒå¤š å›å¤é‚®ä»¶å¯èƒ½æ¯”è¾ƒæ…¢ æœ›è§è°…ï¼ Dr. Kai ZHAO in UAB Release Time: 4/13 2022 å‘ä¸ªæ‹›ç”Ÿä¿¡æ¯ï¼Œè¿˜è¯·å¤§å®¶å¤šå¤šæ”¯æŒ[æœºæ™º] é˜¿æ‹‰å·´é©¬å¤§å­¦ä¼¯æ˜ç¿°åˆ†æ ¡(The University of Alabama at Birmingham) åŠ©ç†æ•™æˆèµµæº ( https://cs.ucr.edu/~kzhao016/ ) æ‹›æ”¶2022ç§‹å­£æˆ–2023æ˜¥å­£å…¥å­¦çš„è®¡ç®—æœºåšå£«ç”Ÿ3~4åã€‚æ•™æˆæœ¬äººæœ¬ç§‘æ¯•ä¸šäºåŒ—äº¬å¤§å­¦è®¡ç®—æœºç³»ï¼Œåšå£«æ¯•ä¸šäºåŠ å·å¤§å­¦æ²³æ»¨åˆ†æ ¡è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹ç³»ã€‚ç ”ç©¶æ–¹å‘è¦†ç›–é«˜æ€§èƒ½è®¡ç®—ï¼Œå¹¶è¡Œåˆ†å¸ƒå¼è®¡ç®—ï¼Œå¤§æ•°æ®çš„ç®¡ç†å’Œåˆ†æï¼Œé«˜èƒ½æ•ˆæ·±åº¦å­¦ä¹ ç­‰ã€‚èµµæºæ•™æˆåœ¨æ•°æ®åº“å’Œé«˜æ€§èƒ½è®¡ç®—ä¸¤ä¸ªé¢†åŸŸçš„é¡¶çº§ä¼šè®®(ICDE, HPDC, SC, ICS)å‘è¡¨è®ºæ–‡åä½™ç¯‡ï¼Œæ‰€å‚ä¸ç ”å‘çš„æ•°æ®å‹ç¼©æ¡†æ¶SZè·å¾—äº†2021å¹´çš„ç¾å›½R&D100åˆ›æ–°å¥–(2021 R&D 100 Awards)ã€‚ å­¦ç”Ÿèµ„åŠ©å’Œå‘å±•ï¼šæ‰€æœ‰å½•å–å­¦ç”Ÿå‡æä¾›å…¨é¢å¥–å­¦é‡‘(åŒ…æ‹¬ç”Ÿæ´»è´¹ï¼Œå­¦è´¹ï¼Œå’Œå¥åº·ä¿é™©)å¹¶æä¾›å®éªŒè®¾å¤‡(æœ€æ–°Macæˆ–Linuxç”µè„‘)ã€‚èµµæºæ•™æˆå’Œç¾å›½é˜¿è´¡å›½å®¶å®éªŒå®¤(Argonne National Laboratory)ä¿æŒç€é•¿æœŸåˆä½œï¼Œå­¦ç”Ÿè¡¨ç°ä¼˜å¼‚å¯åœ¨æš‘å‡å‰å¾€å›½å®¶å®éªŒå®¤è·Ÿéšå„ä¸ªé¢†åŸŸçš„èµ„æ·±ç§‘å­¦å®¶å®ä¹ ã€‚ å¤§å­¦ç®€ä»‹ï¼šé˜¿æ‹‰å·´é©¬å¤§å­¦ä¼¯æ˜ç¿°åˆ†æ ¡(ç®€ç§°UAB)ï¼Œæ˜¯ä¸€æ‰€ç¾å›½è‘—åçš„å…¬ç«‹ç ”ç©¶å‹å¤§å­¦ï¼Œæ‹¥æœ‰æé«˜çš„å…¨çƒæ’å(US News ç¬¬147ï¼ŒTHE ç¬¬169)ã€‚UABåŒ»å­¦ç³»ç»Ÿæ˜¯ç¾å›½æœ€å¤§çš„åŒ»å­¦ä¸­å¿ƒä¹‹ä¸€ï¼Œä¸ºå­¦ç”Ÿæä¾›æ— å¿§çš„å¥åº·ä¿éšœã€‚UABè®¡ç®—æœºç§‘å­¦ç³»ç ”ç©¶é¢†åŸŸè¦†ç›–é«˜æ€§èƒ½è®¡ç®—ï¼Œå¹¶è¡Œå’Œåˆ†å¸ƒå¼è®¡ç®—ï¼Œæ•°æ®æŒ–æ˜ï¼ŒåŒ»ç–—æ•°æ®åˆ†æï¼Œæœºå™¨å­¦ä¹ ï¼Œç³»ç»Ÿå’Œç½‘ç»œå®‰å…¨ï¼ŒåŒºå—é“¾ï¼Œäº‘è®¡ç®—ï¼Œç¼–ç¨‹è¯­è¨€ç­‰ã€‚è®¡ç®—æœºç§‘å­¦ç³»äº2019å¹´æ¬å…¥å…¨æ–°çš„åŠå…¬æ¥¼ï¼Œæ‹¥æœ‰é¢†å…ˆçš„ç¡¬ä»¶è®¾æ–½(ä¾‹å¦‚å…¨M1çš„Macæ•™å®¤)ã€‚UABåŸéƒŠ(Vestavia Hillsç­‰åœ°)è·ç¦»å­¦æ ¡10åˆ†é’Ÿè½¦ç¨‹ï¼Œæ²»å®‰è¿œå¥½äºç¾å›½ç»å¤§å¤šæ•°åœ°åŒºï¼Œå¹¶æ‹¥æœ‰å®Œå–„çš„å•†ä¸š(Costco, é™ˆå®¶å›­ Hometown Supermarket, Trader Joe'sç­‰)ï¼Œååˆ†é€‚åˆäºšè£”ç”Ÿæ´»ã€‚UABäº¤é€šä¾¿åˆ©ï¼Œè·ç¦»ä¼¯æ˜ç¿°æœºåœº10åˆ†é’Ÿï¼Œè·ç¦»äºšç‰¹å…°å¤§ï¼Œçº³ä»€ç»´å°”ï¼Œå’Œå­Ÿè²æ–¯è½¦ç¨‹2-3å°æ—¶ï¼Œè·ç¦»å¢¨è¥¿å“¥æ¹¾æœ€ä½³ç™½æ²™æ»© Destin å’Œå¤§é›¾å±±å›½å®¶å…¬å›­è½¦ç¨‹4å°æ—¶ï¼Œå‘¨æœ«ä¼‘é—²é‡‡è´­å¨±ä¹éƒ½ç›¸å¯¹ä¾¿æ·ã€‚ å­¦ç”Ÿè¦æ±‚ï¼šæœ¬ç§‘å°±è¯»ä»»ä½•ä¸“ä¸šçš„å­¦ç”Ÿå‡å¯ç”³è¯·ï¼Œä¸è¦æ±‚æœ‰ç§‘ç ”ç»å†ã€‚è¦æ±‚å­¦ç”Ÿè‡ªå­¦èƒ½åŠ›å¼ºï¼Œé€»è¾‘æ€ç»´ä¸¥å¯†ï¼Œæœ‰æ’å¿ƒå’Œæ¯…åŠ›ï¼Œå¹¶å¯¹æ”»è¯»åšå£«å­¦ä½æœ‰å¼ºçƒˆå…´è¶£ã€‚ ç”³è¯·æ–¹å¼ï¼šè¯·å°†ç®€å†ï¼ŒTOEFLæˆç»©ï¼Œè¯¾ç¨‹æˆç»©å•ï¼ŒåŠä¸ªäººä¸“é•¿ç­‰å‘é€åˆ°kzhao@uab.eduã€‚ Dr. Peng GAO in Virginia Tech Release Time: 3/7 2022 18å±Šç‹xxï¼šå’Œé«˜æ•™æˆåšäº†å…­ä¸ªæœˆinternï¼Œæœ‰äº†ä¸¤ç¯‡å¾ˆå¥½çš„äº§å‡ºï¼Œç”³è¯·å­£é«˜æ•™æˆç»™äº†æˆ‘å·¨å¤§çš„æ”¯æŒå’Œå¸®åŠ©ï¼Œå’Œæˆ‘å•ç‹¬èŠäº†å‡ ä¸ªå°æ—¶åˆ†äº«ä»–è¯»åšçš„ç»éªŒå»ºè®®ã€‚æœ€åå› ä¸ºä¸ªäººåŸå› é€‰äº†åœ°ç†ä½ç½®åœ¨åŠ å·çš„å­¦æ ¡ï¼Œæ²¡æœ‰ç»§ç»­ç•™ç»„è¯»PhDã€‚éå¸¸æ¨èé«˜æ•™æˆçš„å›¢é˜Ÿï¼Œæ•™æˆéå¸¸niceå’Œfriendlyï¼Œç§‘ç ”è´¨é‡å¾ˆé«˜ï¼Œå·¥ä¸šç•Œå­¦æœ¯ç•Œconnectionéƒ½éå¸¸å¼ºã€‚æ¨èç»™åœ¨æ‰¾æš‘ç ”å’Œ22Fall/23Spring/23Fall PhDæœºä¼šçš„æœ‹å‹ä»¬ https://people.cs.vt.edu/penggao/ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 21:37:20 "},"CodeForUse/":{"url":"CodeForUse/","title":"åŠæ—¶ä»£ç ","keywords":"","body":"å›¾åƒå¤„ç† å›¾åƒç¼©æ”¾ å›¾åƒä¿®æ”¹æ ¼å¼ PyTorch DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 21:14:58 "},"CodeForUse/1.html":{"url":"CodeForUse/1.html","title":"å›¾åƒç¼©æ”¾","keywords":"","body":"å›¾åƒç¼©æ”¾ Author = DanteSU import cv2 import os import glob def img_resize(): # iterations path = input(r\"Input the path of image to be processed(eg: D:\\picture\\1.jpg):\") print('Path of image here is : ',path) path_rewrite = input(r\"Input the path of restoring the image(eg: D:\\picture):\") for i in glob.glob(path): print('I here is : ', i) im1 = cv2.imread(i) # print('The original image data are: ', im1) im2 = cv2.resize(im1,(256,256)) # (256,256)æ˜¯ç¼©æ”¾åçš„åƒç´ æ•° # print('The resized image data are: ', im2) cv2.imwrite(os.path.join(path_rewrite,'resized_' + os.path.basename(i)),im2) if __name__ == '__main__': img_resize() DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:56:21 "},"CodeForUse/2.html":{"url":"CodeForUse/2.html","title":"å›¾åƒä¿®æ”¹æ ¼å¼","keywords":"","body":"å›¾åƒä¿®æ”¹æ ¼å¼ Author = DanteSU ä¸€èˆ¬æƒ…å†µ import cv2 import os import glob def change_img_format(): # iterations path = input(r\"Input the path of image to be processed(eg: D:\\picture\\1.jpg):\") print('Path of image here is : ',path) path_rewrite = input(r\"Input the path of restoring the image(eg: D:\\picture):\") img_format = input(r\"Input the format you want(eg: jpg):\") for i in glob.glob(path): print('I here is : ', i) im = cv2.imread(i) new_path = os.path.join(path_rewrite,'new_name'+'.'+img_format) cv2.imwrite(new_path,im) if __name__ == '__main__': change_img_format() é’ˆå¯¹ ico ï¼ˆå›¾æ ‡ï¼‰æ–‡ä»¶ ''' å¸¸ç”¨å›¾æ ‡å¤§å°ï¼š [ (256, 256), (128, 128), (64, 64), (48, 48), (32, 32), (24, 24), (16, 16) ] ''' from PIL import Image def make_ico_file(src_image_file, dist_ico_file, size): size = [int(size), int(size)] image = Image.open(src_image_file) image_cropped = image.crop((0, 0, 256, 256)) image_cropped.save(dist_ico_file, sizes=size) if __name__ == '__main__': make_ico_file(input(r\"Input the path of the image(eg: D:\\picture\\1.jpg):\"), input(r'Input the name of icon(eg: favicon):'), input(r'Input the same of icon(eg: 256):')) DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 21:17:11 "},"CodeForUse/3.html":{"url":"CodeForUse/3.html","title":"PyTorch","keywords":"","body":"PyTorch Author = DanteSU æ ·ä¾‹ train.py import time import click from datetime import datetime import torch # from torch import nn from torch.utils.data import DataLoader # from torch.utils.tensorboard import SummaryWriter # from sklearn.metrics import confusion_matrix from utils.loss import * from utils.model import * from utils.loader import * from utils.others import * def train(gpu_set, epoch, learning_rate, data_path, batch_size, loss, weight_decay='0.00001', model_name = 'dp_cnn', time_now = 'fake time'): # Load train and val data print('Loading data...') trainset, valset = load_train_data(data_path) # Get and print useful settings print('Getting settings...') train_data_size,val_data_size,n_classes,input_lenghth = get_setting(trainset, valset) # Using DataLoader to load data print('Setting dataloader...') train_dataloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True ) val_dataloader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=True ) # Set pytorch device print('Setting device...') device = get_device_name(gpu_set) # Create the model print('Creating model network...') model = model_set(model_name,n_classes, batch_size,input_lenghth).to(device) # Creat loss function print('Creating loss function...') loss_fn = loss_set(loss,device) # create optimizer print('Creating optimizer...') # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False) # set some sets total_train_step = 0 # record training's number # total_val_step = 0 # record validating's number # use tensorboard # writer = SummaryWriter(\"logs_train\") for i in range(epoch): epoch_start_time = iters_time = time.time() # timer for entire epoch # iters_time = time.time() print(\"------The {}th epoch starts------\".format(i+1)) # train starts training(train_dataloader,device,model,loss_fn,optimizer,batch_size,total_train_step,iters_time) validating(val_dataloader,val_data_size,device,model,loss_fn,time_now) save_checkpoints(time_now,model,model_name,i) print('The time consumption of this code is : {} s'.format(time.time() - epoch_start_time)) # writer.close() @click.command() @click.option('-g', '--gpu_set', type=str, default='-1', help='gpu_set: e.g. 0 0,1,2, 0,2. use -1 for CPU') @click.option('-dp', '--data_path', type=str, default='data', help='path of input data') @click.option('-e', '--epoch', type=int, default=10, help='epoch') @click.option('-bs', '--batch_size', type=int, default=1, help='batch size') @click.option('-lr', '--learning_rate', type=float, default=1e-3, help='batch size') @click.option('-l', '--loss', type=str, default='ce', help='loss function') @click.option('-wd', '--weight_decay', type=float, default=1e-5, help='weight decay') @click.option('-m', '--model_name', type=str, default='lstm', help='eg. lstm') def main(gpu_set, data_path, epoch, batch_size,learning_rate, loss, weight_decay,model_name): total_time = time.time() time_now = datetime.now() record_parameter(gpu_set, epoch = epoch, learning_rate = learning_rate, data_path=data_path, batch_size = batch_size, loss = loss, weight_decay = weight_decay, model_name = model_name, time_now = time_now) train(gpu_set, epoch = epoch, learning_rate = learning_rate, data_path=data_path, batch_size = batch_size, loss = loss, weight_decay = weight_decay, model_name = model_name, time_now = time_now) run_time = time.time() - total_time record_run_time(run_time) if __name__ == '__main__': main() utils loader.py import torch from torch.utils.data import Dataset import numpy as np import time def load_train_data(data_path): print('preparing trainset...') trainset_time = time.time() trainset = TrainDataset(data_path=data_path) print('trainset time consumption is :', time.time()-trainset_time) print('preparing valset...') valset_time = time.time() valset = ValDataset(data_path=data_path) print('trainset time consumption is :', time.time()-valset_time) return trainset, valset class TrainDataset(Dataset): \"\"\" ä¸‹è½½æ•°æ®ã€åˆå§‹åŒ–æ•°æ®ï¼Œéƒ½å¯ä»¥åœ¨è¿™é‡Œå®Œæˆ \"\"\" def __init__(self, data_path): self.X_train = self.npy_loader(data_path+'/x_train.npy') self.y_train_onehot = self.npy_loader(data_path+'/y_train_onehot.npy') def __getitem__(self, index): return self.X_train[index].unsqueeze(0), self.y_train_onehot[index] # .unsqueeze(0) def __len__(self): return len(self.X_train) def npy_loader(self,path): return torch.from_numpy(np.load(path)) class ValDataset(Dataset): \"\"\" ä¸‹è½½æ•°æ®ã€åˆå§‹åŒ–æ•°æ®ï¼Œéƒ½å¯ä»¥åœ¨è¿™é‡Œå®Œæˆ \"\"\" def __init__(self, data_path): self.X_val = self.npy_loader(data_path+'/x_val.npy') self.y_val_onehot = self.npy_loader(data_path+'/y_val_onehot.npy') def __getitem__(self, index): return self.X_val[index].unsqueeze(0), self.y_val_onehot[index] # .unsqueeze(0) def __len__(self): return len(self.X_val) def npy_loader(self,path): return torch.from_numpy(np.load(path)) class TestDataset(Dataset): \"\"\" ä¸‹è½½æ•°æ®ã€åˆå§‹åŒ–æ•°æ®ï¼Œéƒ½å¯ä»¥åœ¨è¿™é‡Œå®Œæˆ \"\"\" def __init__(self, data_path): self.X_test = self.npy_loader(data_path+'/x_test.npy') self.y_test_onehot = self.npy_loader(data_path+'/y_test_onehot.npy') def __getitem__(self, index): return self.X_test[index].unsqueeze(0), self.y_test_onehot[index] # .unsqueeze(0) def __len__(self): return len(self.X_test) def npy_loader(self,path): return torch.from_numpy(np.load(path)) loss.py import sys import torch from torch import nn import torch.nn.functional as F from torch.autograd import Variable def loss_set(loss, device): if loss =='ce': return nn.CrossEntropyLoss() if loss == 'bce': return nn.BCELoss() if loss =='mlsm': return nn.MultiLabelSoftMarginLoss() if loss =='mlcce': return multilabel_categorical_crossentropy if loss =='fl1': return WeightedFocalLoss() if loss =='fl2': return focalBceLoss if loss == 'fl3': return focal_loss() if loss == 'fl4': return FocalLoss() else: print('loss name error!!!') return sys.exit(0) class WeightedFocalLoss(nn.Module): \"Non weighted version of Focal Loss\" def __init__(self, alpha=.25, gamma=2, device = 'cuda:2'): super(WeightedFocalLoss, self).__init__() self.alpha = torch.tensor([alpha, 1-alpha]).to(device) self.gamma = gamma def forward(self, inputs, targets): BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none') targets = targets.type(torch.long) at = self.alpha.gather(0, targets.data.view(-1)) pt = torch.exp(-BCE_loss) F_loss = at*(1-pt)**self.gamma * BCE_loss return F_loss.mean() class GHM_Loss(nn.Module): def __init__(self, bins, alpha): super(GHM_Loss, self).__init__() self._bins = bins self._alpha = alpha self._last_bin_count = None def _g2bin(self, g): return torch.floor(g * (self._bins - 0.0001)).long() def _custom_loss(self, x, target, weight): raise NotImplementedError def _custom_loss_grad(self, x, target): raise NotImplementedError def forward(self, x, target): g = torch.abs(self._custom_loss_grad(x, target)) bin_idx = self._g2bin(g) bin_count = torch.zeros((self._bins)) for i in range(self._bins): bin_count[i] = (bin_idx == i).sum().item() N = x.size(0) nonempty_bins = (bin_count > 0).sum().item() gd = bin_count * nonempty_bins gd = torch.clamp(gd, min=0.0001) beta = N / gd return self._custom_loss(x, target, beta[bin_idx]) class GHMC_Loss(GHM_Loss): def __init__(self, bins, alpha,device='cuda:2'): super(GHMC_Loss, self).__init__(bins, alpha) self.device = device def _custom_loss(self, x, target, weight): return torch.sum((torch.nn.NLLLoss(reduce=False)(torch.log(x),target)).mul(weight.to(self.device).detach()))/torch.sum(weight.to(self.device).detach()) def _custom_loss_grad(self, x, target): x=x.to(self.device).detach() target=target.to(self.device) return torch.tensor([x[i,target[i]] for i in range(target.shape[0])])-target class focal_loss(nn.Module): def __init__(self, alpha=0.25, gamma=2, num_classes = '11', size_average=True): \"\"\" focal_lossæŸå¤±å‡½æ•°, -Î±(1-yi)**Î³ *ce_loss(xi,yi) æ­¥éª¤è¯¦ç»†çš„å®ç°äº† focal_lossæŸå¤±å‡½æ•°. :param alpha: é˜¿å°”æ³•Î±,ç±»åˆ«æƒé‡. å½“Î±æ˜¯åˆ—è¡¨æ—¶,ä¸ºå„ç±»åˆ«æƒé‡,å½“Î±ä¸ºå¸¸æ•°æ—¶,ç±»åˆ«æƒé‡ä¸º[Î±, 1-Î±, 1-Î±, ....],å¸¸ç”¨äº ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸­æŠ‘åˆ¶èƒŒæ™¯ç±» , retainnetä¸­è®¾ç½®ä¸º0.25 :param gamma: ä¼½é©¬Î³,éš¾æ˜“æ ·æœ¬è°ƒèŠ‚å‚æ•°. retainnetä¸­è®¾ç½®ä¸º2 :param num_classes: ç±»åˆ«æ•°é‡ :param size_average: æŸå¤±è®¡ç®—æ–¹å¼,é»˜è®¤å–å‡å€¼ \"\"\" super(focal_loss,self).__init__() self.size_average = size_average if isinstance(alpha,list): assert len(alpha)==num_classes # Î±å¯ä»¥ä»¥listæ–¹å¼è¾“å…¥,size:[num_classes] ç”¨äºå¯¹ä¸åŒç±»åˆ«ç²¾ç»†åœ°èµ‹äºˆæƒé‡ print(\" --- Focal_loss alpha = {}, å°†å¯¹æ¯ä¸€ç±»æƒé‡è¿›è¡Œç²¾ç»†åŒ–èµ‹å€¼ --- \".format(alpha)) self.alpha = torch.Tensor(alpha) else: assert alpha2: input = input.view(input.size(0),input.size(1),-1) # N,C,H,W => N,C,H*W input = input.transpose(1,2) # N,C,H*W => N,H*W,C input = input.contiguous().view(-1,input.size(2)) # N,H*W,C => N*H*W,C target = target.view(-1,1) logpt = F.log_softmax(input) logpt = logpt.gather(1,target) logpt = logpt.view(-1) pt = Variable(logpt.data.exp()) if self.alpha is not None: if self.alpha.type()!=input.data.type(): self.alpha = self.alpha.type_as(input.data) at = self.alpha.gather(0,target.data.view(-1)) logpt = logpt * Variable(at) loss = -1 * (1-pt)**self.gamma * logpt if self.size_average: return loss.mean() else: return loss.sum() def focalBceLoss(pred,mask,device='cuda:3'): # pred[pred1]=1 # BCE_loss = F.binary_cross_entropy_with_logits(pred, mask) BCE_loss = multilabel_categorical_crossentropy(pred, mask) alpha = 0.25 alpha = torch.tensor([alpha, 1 - alpha]).to(device) gamma = 2 targets = BCE_loss.type(torch.long) at = alpha.gather(0, targets.data.view(-1)) pt = torch.exp(-BCE_loss) F_loss = at * (1 - pt) ** gamma * BCE_loss smooth = 1e-5 pred = torch.sigmoid(pred) num = mask.size(0) pred = pred.view(num, -1) #view()çš„ä½œç”¨ç›¸å½“äºnumpyä¸­çš„reshapeï¼Œé‡æ–°å®šä¹‰çŸ©é˜µçš„å½¢çŠ¶ã€‚ #print(mask.shape) mask = mask.contiguous().view(num, -1) intersection = (pred * mask) # dice = (2. * intersection.sum(1) + smooth) / (pred.sum(1) + mask.sum(1) + smooth) # dice = 1 - dice.sum() / num # print(type(dice)) # # å› ä¸ºè¿”å›1ç»´tensorï¼Œä½ å¯ä»¥æƒ³è±¡æˆåªå«æœ‰1ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œè¦ä½¿ç”¨[0]ç´¢å¼•æ‰è¿”å›ä¸€ä¸ªfloatæ•° # print(type(dice.item())) # print(type(F_loss.item())) # # print(dice) #print(type(F_loss.item())) return 0.5 * F_loss.item() + BCE_loss def multilabel_categorical_crossentropy(y_pred,y_true): y_pred = (1 - 2 * y_true) * y_pred y_pred_neg = y_pred - y_true * 1e12 y_pred_pos = y_pred - (1 - y_true) * 1e12 zeros = torch.zeros_like(y_pred[..., :1]) y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1) y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1) neg_loss = torch.logsumexp(y_pred_neg, dim=-1) pos_loss = torch.logsumexp(y_pred_pos, dim=-1) return neg_loss + pos_loss model.py import sys import math import torch from torch import nn, Tensor def model_set(model_name,n_classes, batch_size,input_lenghth): if model_name == 'resnet': return ResNet18(n_classes) if model_name == 'lstm': return LSTM(input_lenghth, n_classes) else: print('model name error!!!') return sys.exit(0) # model 1 class ResNet(nn.Module): def __init__(self, ch_in, ch_out): super(ResNet, self).__init__() self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(ch_out) self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(ch_out) self.relu = nn.ReLU(inplace=True) self.extra = nn.Sequential() # å¦‚æœè¾“å…¥ã€è¾“å‡ºç»´åº¦ä¸åŒï¼Œéœ€è½¬åŒ–åæ‰èƒ½ç›¸åŠ  if ch_out != ch_in: self.extra = nn.Sequential( nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1), nn.BatchNorm2d(ch_out) ) def forward(self, x): out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.extra(x) + out return out class ResNet18(nn.Module): def __init__(self,n_classes): super(ResNet18, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64) ) self.relu = nn.ReLU(inplace=True) # 4 block [b, 64, h, w] => [b, 1024, h, w] self.blk1 = ResNet(64, 128) self.blk2 = ResNet(128, 256) self.blk3 = ResNet(256, 512) self.blk4 = ResNet(512, 1024) # æ³¨æ„æœ€åå…¨è¿æ¥å±‚ç»´åº¦ï¼Œè¿›å»ä¹‹å‰éœ€è¦å…ˆæ‰“å¹³ self.outlayer = nn.Linear(1024*30*50, n_classes) def forward(self, x): x = x.view(len(x),30,-1) x = x.unsqueeze(1) x = self.conv1(x) x = self.relu(x) x = self.blk1(x) x = self.blk2(x) x = self.blk3(x) x = self.blk4(x) x = x.view(x.size(0), -1) # å…ˆæ‰“å¹³ï¼Œå†è¿›å…¨è¿æ¥ x = self.outlayer(x) return x # model 2 class LSTM(nn.Module): def __init__(self,INPUT_SIZE,n_classes): super(LSTM, self).__init__() self.rnn = nn.LSTM( # if use nn.RNN(), it hardly learns input_size=INPUT_SIZE, hidden_size=64, # rnn hidden unit num_layers=1, # number of rnn layer batch_first=True, # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size) ) self.out = nn.Linear(64, n_classes) def forward(self, x): # x shape (batch, time_step, input_size) # r_out shape (batch, time_step, output_size) # h_n shape (n_layers, batch, hidden_size) # h_c shape (n_layers, batch, hidden_size) r_out, (h_n, h_c) = self.rnn(x, None) # None represents zero initial hidden state # choose r_out at the last time step out = self.out(r_out[:, -1, :]) return out other.py import torch import time from pathlib import Path def record_parameter(gpu_set, epoch, learning_rate, data_path, batch_size,loss, weight_decay, model_name, time_now): fp = open('log/log.txt','a') fp.write('-'*100 + '\\n' + 'new training starts :' + '\\n') fp.write('The time of running this code is {}:'.format(time_now) + '\\n') fp.write('The hyper parameters are as follows: \\n'+ 'using gpu ids : {} \\n'.format(gpu_set)+ 'the path of data : {} \\n'.format(data_path)+ 'epoch numbers : {} \\n'.format(epoch)+ 'batch size : {} \\n'.format(batch_size)+ 'learning rate : {} \\n'.format(learning_rate)+ 'loss function : {} \\n'.format(loss)+ 'weight decay : {} \\n'.format(weight_decay)+ 'model name : {} \\n'.format(model_name)) fp.close() def record_run_time(run_time): print('The time consumption of this code is : : {}'.format(run_time)) fp = open('log/log.txt','a') fp.write('The time consumption of this code is : {} \\n'.format(run_time)) fp.close() def get_setting(trainset, valset): # get useful settings train_data_size = len(trainset.X_train) val_data_size = len(valset.X_val) n_classes = len(trainset.y_train_onehot[0]) input_lenghth = len(trainset.X_train[0]) # print to see print(\"The length of train set is : {}\".format(train_data_size)) print(\"The length of val set is : {}\".format(val_data_size)) print(\"The number of classes is : {}\".format(n_classes)) print(\"The length of each input is : {}\".format(input_lenghth)) return train_data_size,val_data_size,n_classes,input_lenghth def get_device_name(gpu_set): if gpu_set == '-1': return torch.device('cpu') else: return torch.device('cuda:{}'.format(gpu_set)) def training(train_dataloader,device,model,loss_fn,optimizer,batch_size,total_train_step,iters_time): for data in train_dataloader: traffic, targets = data traffic = traffic.to(device) targets = targets.to(device) outputs = model(traffic) # å°†è®­ç»ƒçš„æ•°æ®æ”¾å…¥ # print(traffic.shape,outputs.shape,targets.shape) # print(outputs) # print(targets.float()) loss = loss_fn(outputs, targets.float()) # å¾—åˆ°æŸå¤±å€¼ optimizer.zero_grad() # ä¼˜åŒ–è¿‡ç¨‹ä¸­é¦–å…ˆè¦ä½¿ç”¨ä¼˜åŒ–å™¨è¿›è¡Œæ¢¯åº¦æ¸…é›¶ loss.backward() # è°ƒç”¨å¾—åˆ°çš„æŸå¤±ï¼Œåˆ©ç”¨åå‘ä¼ æ’­ï¼Œå¾—åˆ°æ¯ä¸€ä¸ªå‚æ•°èŠ‚ç‚¹çš„æ¢¯åº¦ optimizer.step() # å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ– total_train_step += batch_size # ä¸Šé¢å°±æ˜¯è¿›è¡Œäº†ä¸€æ¬¡è®­ç»ƒï¼Œè®­ç»ƒæ¬¡æ•° +1 # Print some information when the number of iterations divide by batch size equal 200 if total_train_step/batch_size % 200 == 0: print(\"Iterations: {}, time consumptions :{}, Loss: {}\".format(total_train_step, time.time() - iters_time, loss)) iters_time = time.time() # writer.add_scalar(\"train_loss\", loss.item(), total_train_step) def validating(val_dataloader,val_data_size,device,model,loss_fn,time_now): total_val_loss = 0 total_accuracy = 0 # å‡†ç¡®ç‡ with torch.no_grad(): for data in val_dataloader: traffic, targets = data traffic = traffic.to(device) targets = targets.to(device) outputs = model(traffic) loss = loss_fn(outputs, targets.float()) # è¿™é‡Œçš„ loss åªæ˜¯ä¸€éƒ¨åˆ†æ•°æ®(data) åœ¨ç½‘ç»œæ¨¡å‹ä¸Šçš„æŸå¤± total_val_loss = total_val_loss + loss # æ•´ä¸ªæµ‹è¯•é›†çš„loss accuracy = (outputs.argmax(1) == targets.argmax(1)).sum() # åˆ†ç±»æ­£ç¡®ä¸ªæ•° total_accuracy += accuracy # ç›¸åŠ  fp = open('log/log.txt','a') fp.write('acc of {} is : '.format(time_now)+str(total_accuracy / val_data_size)+'\\n') fp.close() print(\"The loss in the whole val dataset: {}\".format(total_val_loss)) print(\"The acc of the whole val dataset: {}\".format(total_accuracy / val_data_size)) # print('æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ··æ·†çŸ©é˜µ:{}'.format(confusion_matrix())) # writer.add_scalar(\"val_loss\", total_val_loss) # writer.add_scalar(\"val_accuracy\", total_accuracy / val_data_size, total_val_step) def save_checkpoints(time_now,model,model_name,i): name_time_part = str(time_now) name_time_part = name_time_part[5:10]+'|'+name_time_part[11:19] cp_path = Path('checkpoints/model_{}_{}'.format(model_name, name_time_part)) cp_path.mkdir(parents=True, exist_ok=True) torch.save(model, \"checkpoints/model_{}_{}/model_{}.pth\".format(model_name, name_time_part, i)) print(\"model has been saved.\") DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:12:08 "},"DP/":{"url":"DP/","title":"æ·±åº¦å­¦ä¹ ","keywords":"","body":"æ·±åº¦å­¦ä¹  æµé‡åˆ†ç±» Open Source Related Papers Related Links å§¿æ€è¿ç§» Info å¯¹è¯æ¨è Info è®¡ç®—æœºå›¾å½¢å­¦ Info DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:33:26 "},"DP/TrafficClassification/":{"url":"DP/TrafficClassification/","title":"æµé‡åˆ†ç±»","keywords":"","body":"Traffic Classification Open Source Related Papers Related Links Lead-in Author = DanteSU ï¼ï¼ï¼æœ¬æ–‡ç¦æ­¢åœ¨å–å¾—ä½œè€…åŒæ„ä¹‹å‰ä»¥ä»»ä½•å½¢å¼ä½¿ç”¨ï¼ï¼ï¼ Brief Intro éšç€æˆ‘å›½ç»æµçš„é«˜é€Ÿå‘å±•ï¼Œäººæ°‘ç”Ÿæ´»æ°´å¹³æ—¥ç›Šæé«˜ï¼Œå¯¹é«˜é€Ÿä¸Šç½‘çš„éœ€æ±‚ä¹ŸæŒç»­å¢åŠ ã€‚ç»å†äº†æ•°æ¬¡é€šä¿¡æŠ€æœ¯çš„æ›´æ–°è¿­ä»£ï¼Œæ—¶è‡³ä»Šæ—¥ï¼Œæ°‘ç”¨ 5G å·²ç»é€æ­¥åœ¨å…¨å›½èŒƒå›´å†…é“ºè®¾å¼€æ¥ã€‚ä¼´éšç€ç½‘ç»œæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒåŒä¸€æ—¶é—´æ®µå†…äº§ç”Ÿçš„äº’è”ç½‘æµé‡æ˜æ˜¾å¢å¤šã€‚æ ¹æ®å·¥ä¿¡éƒ¨å‘å¸ƒçš„ã€Š2021 å¹´ 1~10 æœˆé€šä¿¡ä¸šç»æµè¿è¡Œæƒ…å†µã€‹æ˜¾ç¤ºï¼Œè™½ç„¶äº’è”ç½‘æ¥å…¥æµé‡å¢é€Ÿç¨ç¨æ”¾ç¼“ï¼Œä½†åœ¨æœªæ¥è¾ƒé•¿æ—¶æœŸå¢é•¿é‡ä»å°†åŸºæœ¬ç¨³å®šï¼Œéšå®è§‚ç»æµæ³¢åŠ¨ï¼Œç–«æƒ…æŒç»­å­˜åœ¨ï¼Œæœˆç´¯è®¡æµé‡å°†æŒç»­å¢é•¿ã€‚ æµé‡çš„æŒç»­å¢åŠ ä¹Ÿä¼šå¸¦æ¥ä¸€äº›æ—¥å¸¸ç”Ÿæ´»ä¸­å‡ºç°é—®é¢˜çš„å¢åŠ ï¼Œæ¯”å¦‚äº’è”ç½‘æœåŠ¡æä¾›å•† (ISP) åŠå…¶è®¾å¤‡ä¾›åº”å•†é¢å¯¹çš„æ„ˆå‘å›°éš¾çš„ç½‘ç»œç®¡ç†é—®é¢˜ã€‚ç½‘ç»œè¿è¥å•†éœ€è¦åŠæ—¶äº†è§£ç½‘ç»œä¸­çš„å†…å®¹ï¼Œä»¥ä¾¿ä»–ä»¬èƒ½å¤Ÿå¿«é€Ÿåšå‡ºååº”ä»¥æ”¯æŒå…¶å„ç§ä¸šåŠ¡ç›®æ ‡ã€‚ä¼´éšç€æµé‡æ€»é‡çš„å¢é•¿å’Œæ–°ç±»å‹æµé‡çš„å‡ºç°ï¼Œæ›¾ç»çš„ç½‘ç»œæµé‡åˆ†ç±»ç®—æ³•éš¾æ©é¢“åŠ¿ï¼Œæˆ‘ä»¬éœ€è¦æ›´å‡†ç¡®ã€æ›´å¿«é€Ÿã€æ›´æ˜“äºå®ç°ã€å¯¹æ–°çš„æµé‡ç±»å‹ä¹Ÿèƒ½åšå‡ºå¤„ç†çš„ç½‘ç»œæµé‡åˆ†ç±»ç®—æ³•æ¥å¸®åŠ©æˆ‘ä»¬è§£å†³ç½‘ç»œæµé‡ç®¡ç†ä¸­çš„æ–°çš„é—®é¢˜ã€‚ æµé‡åˆ†ç±»é—®é¢˜å·²ç»ç ”ç©¶äº†äºŒåå¹´ï¼Œç›¸å…³ç ”ç©¶ç»“æœå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚ç›®å‰æµé‡åˆ†ç±»æŠ€æœ¯çš„ç›®çš„æ˜¯è¦æ£€æµ‹æµé‡æ¨¡å¼ï¼Œä»è€Œä¼˜å…ˆå®¢æˆ·è‡ªåŠ¨åˆ†é…ç½‘ç»œèµ„æºï¼Œæˆ–è¯†åˆ«å®¢æˆ·ä½¿ç”¨ç½‘ç»œèµ„æºæ˜¯å¦åœ¨æŸç§ç¨‹åº¦ä¸Šè¿åäº†è¿è¥å•†çš„æœåŠ¡æ¡æ¬¾ï¼Œå½“ç„¶ï¼Œè¿˜æœ‰ä¸€äº›è°ƒæ•´ç½‘ç»œæµé‡è§£åŒ…ä¸è°ƒå–çš„é¡ºåºä»¥ä¼˜åŒ–ç”¨æˆ·ä½“éªŒçš„ä½œç”¨ã€‚æœ€è¿‘ï¼Œæ”¿åºœè¿˜æ˜ç¡®äº†äº’è”ç½‘æœåŠ¡æä¾›å•†åœ¨â€œåˆæ³•æ‹¦æˆªâ€è¿æ³• IP æ•°æ®æµé‡æ–¹é¢çš„ä¹‰åŠ¡ã€‚æ­£å¦‚ç”µè¯å…¬å¸å¿…é¡»æ”¯æŒæ‹¦æˆªç”µè¯ä¸€æ ·ï¼Œäº’è”ç½‘æœåŠ¡ä¾›åº”å•†è¶Šæ¥è¶Šå—æ”¿åºœè¦æ±‚æä¾›ç‰¹å®šä¸ªäººåœ¨ç‰¹å®šæ—¶é—´ç‚¹çš„ç½‘ç»œä½¿ç”¨ä¿¡æ¯çš„è¦æ±‚ã€‚ ç›®å‰æµé‡åˆ†ç±»æœ‰åŸºäºç«¯å£çš„æ•°æ®åŒ…æ£€æµ‹ã€å¯¹æœ‰æ•ˆè½½è·çš„æ£€æµ‹ã€å¯¹åŸºäºç»Ÿè®¡å­¦çš„ç‰¹å¾æ£€æµ‹ç­‰æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•éƒ½å·²ç»åœ¨è¿‡å»å¾—åˆ°å¾ˆå¥½çš„åº”ç”¨ï¼Œä½†ç”±äºé€šä¿¡æŠ€æœ¯çš„å‘å±•ï¼Œäº’è”ç½‘æµé‡çš„å·¨å¤§å˜åŒ–ï¼Œç‰¹åˆ«æ˜¯åŠ å¯†æµé‡çš„å¢åŠ ï¼Œå®ƒä»¬çš„å‡†ç¡®æ€§å·²ç»åœ¨ä¸‹é™ã€‚éšç€æœºå™¨å­¦ä¹ æ–¹æ³•çš„æ™®åŠï¼Œç ”ç©¶äººå‘˜æœ€è¿‘ç ”ç©¶äº†è¿™äº›æ–¹æ³•ç”¨äºæµé‡åˆ†ç±»ä»»åŠ¡å¹¶è¾¾åˆ°äº†å¾ˆé«˜çš„ç²¾åº¦ï¼Œå®ç°äº†å¾ˆå¥½çš„æ•ˆæœã€‚ç›¸æ¯”äºä¼ ç»Ÿæµé‡åˆ†ç±»æŠ€æœ¯ï¼ŒåŸºäºæœºå™¨å­¦ä¹ æˆ–è€…æ·±åº¦å­¦ä¹ çš„æŠ€æœ¯å…·æœ‰æ“ä½œç®€å•ï¼Œèµ„æºæ¶ˆè€—å°‘ï¼Œå®æ—¶æ€§å¥½ç­‰ä¼˜ç‚¹ï¼Œå¯ä»¥å¹¿æ³›è¿ç”¨äºäº’è”ç½‘æœåŠ¡ä¾›åº”å•†çš„æµé‡ç®¡ç†ç³»ç»Ÿç­‰åœ°æ–¹ã€‚ä¸æ­¤åŒæ—¶ï¼Œè¿‘å‡ å¹´æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œä½¿å¾—ä¸€äº›ç®—æ³•åœ¨å¾ˆå¤šä»»åŠ¡çš„ç²¾åº¦å’Œé€Ÿåº¦ä¸Šéƒ½è¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æ°´å¹³ï¼Œè¿™ä½¿å¾—åœ¨æµé‡ç®¡ç†ç³»ç»Ÿä¸­åº”ç”¨ä¸€å¥—ç«¯åˆ°ç«¯çš„æ–¹æ¡ˆæˆä¸ºå¯èƒ½ã€‚ç”±æ­¤æˆ‘æƒ³åœ¨åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„ç½‘ç»œæµé‡åˆ†ç±»è¿™ä¸€æ–¹é¢è¿›è¡Œä¸€å®šçš„ç ”ç©¶ï¼Œå¹¶è€ƒè™‘æµé‡åˆ†ç±»åœ¨ä¸€äº›ç‰¹æ®ŠçŠ¶æ€ä¸‹å¦‚é¢å¯¹å¾ˆå¤šæœªæ›¾è§è¿‡çš„åº”ç”¨æµé‡æƒ…å†µä¸‹çš„è¡¨ç°ã€‚ Traditional Technology åŸºäºç«¯å£çš„æ–¹æ³• é€šè¿‡ç«¯å£å·è¿›è¡Œæµé‡åˆ†ç±»æ˜¯è¿™é¡¹ä»»åŠ¡æœ€å¤è€å’Œæœ€è‘—åçš„æ–¹æ³•ã€‚åŸºäºç«¯å£çš„åˆ†ç±»å™¨ä½¿ç”¨æ•°æ®åŒ…çš„ TCP/UDP æ ‡å¤´ä¸­çš„ä¿¡æ¯æ¥æå–å‡å®šä¸ç‰¹å®šåº”ç”¨ç¨‹åºç›¸å…³è”çš„ç«¯å£å·ã€‚æå–ç«¯å£å·åï¼Œä¸åˆ†é…çš„ IANA TCP/UDP ç«¯å£å·è¿›è¡Œæ¯”è¾ƒï¼Œè¿›è¡Œæµé‡åˆ†ç±»ã€‚æå–è¿‡ç¨‹ç®€å•ï¼Œç«¯å£å·ä¸å—åŠ å¯†æ–¹æ¡ˆçš„å½±å“ã€‚ç”±äºæå–è¿‡ç¨‹å¿«é€Ÿï¼Œè¿™ç§æ–¹æ³•ç»å¸¸ç”¨äºé˜²ç«å¢™å’Œè®¿é—®æ§åˆ¶åˆ—è¡¨ã€‚ä¼—æ‰€å‘¨çŸ¥ï¼ŒåŸºäºç«¯å£çš„åˆ†ç±»æ˜¯ç½‘ç»œæµé‡è¯†åˆ«æœ€ç®€å•ã€æœ€å¿«çš„æ–¹æ³•ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œç«¯å£æ··æ·†ã€ç½‘ç»œåœ°å€è½¬æ¢ã€ç«¯å£è½¬å‘ã€åè®®åµŒå…¥å’Œéšæœºç«¯å£åˆ†é…çš„æ™®éæ€§å¤§å¤§é™ä½äº†è¿™ç§æ–¹æ³•çš„å‡†ç¡®æ€§ã€‚æ ¹æ®ç›¸å…³ç ”ç©¶ï¼Œç›®å‰åªæœ‰ 30% åˆ° 70% çš„äº’è”ç½‘æµé‡å¯ä»¥ä½¿ç”¨åŸºäºç«¯å£çš„åˆ†ç±»æ–¹æ³•è¿›è¡Œåˆ†ç±»ã€‚ç”±äºè¿™äº›åŸå› ï¼Œéœ€è¦æ›´å¤æ‚çš„æµé‡åˆ†ç±»æ–¹æ³•æ¥å¯¹ç°ä»£ç½‘ç»œæµé‡è¿›è¡Œåˆ†ç±»ã€‚ æœ‰æ•ˆè½½è·æ£€æµ‹æŠ€æœ¯ è¿™äº›æŠ€æœ¯åŸºäºå¯¹æ•°æ®åŒ…åº”ç”¨å±‚æœ‰æ•ˆè½½è·ä¸­å¯ç”¨ä¿¡æ¯çš„åˆ†æã€‚å¤§å¤šæ•°æœ‰æ•ˆè´Ÿè½½æ£€æµ‹æ–¹æ³•ï¼Œä¹Ÿç§°ä¸ºæ·±åº¦æ•°æ®åŒ…æ£€æµ‹ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å¼(å¦‚æ­£åˆ™è¡¨è¾¾å¼)ä½œä¸ºæ¯ä¸ªåè®®çš„ç­¾åã€‚ç„¶åä½¿ç”¨æ´¾ç”Ÿçš„æ¨¡å¼æ¥åŒºåˆ†åè®®å½¼æ­¤ã€‚æ¯å½“å‘å¸ƒæ–°åè®®æ—¶éƒ½éœ€è¦æ›´æ–°æ¨¡å¼ï¼Œå¹¶ä¸”ç”¨æˆ·éšç§é—®é¢˜æ˜¯è¿™ç§æ–¹æ³•æœ€é‡è¦çš„ç¼ºç‚¹ä¹‹ä¸€ã€‚è™½ç„¶æœ‰äººæå‡ºäº†ä¸€ç§æ–°çš„æ·±åº¦æ•°æ®åŒ…æ£€æµ‹ç³»ç»Ÿï¼Œå¯ä»¥åœ¨ä¸è§£å¯†çš„æƒ…å†µä¸‹æ£€æŸ¥åŠ å¯†çš„æœ‰æ•ˆè´Ÿè½½ï¼Œä»è€Œè§£å†³äº†ç”¨æˆ·éšç§é—®é¢˜ï¼Œä½†å®ƒåªèƒ½å¤„ç† HTTP å®‰å…¨æµé‡ã€‚ ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ æ–¹æ³• å…¶ä¸­ä¸€äº›æ–¹æ³•ï¼Œä¸»è¦ç§°ä¸ºç»Ÿè®¡æ–¹æ³•ï¼Œæœ‰ä¸€ä¸ªæœ‰åè§çš„å‡è®¾ï¼Œå³æ¯ä¸ªåº”ç”¨ç¨‹åºçš„åŸºç¡€æµé‡å…·æœ‰ä¸€äº›å‡ ä¹ç‹¬æœ‰çš„ç»Ÿè®¡ç‰¹å¾ã€‚æ¯ç§ç»Ÿè®¡æ–¹æ³•éƒ½ä½¿ç”¨è‡ªå·±çš„å‡½æ•°å’Œç»Ÿè®¡æ•°æ®ã€‚æœ‰ä¸€ç§åŠæ³•æ˜¯åŸºäºæ•°æ®åŒ…åˆ°è¾¾æ—¶é—´å’Œå½’ä¸€åŒ– é˜ˆå€¼çš„æ¦‚ç‡å¯†åº¦å‡½æ•°çš„åè®®æŒ‡çº¹ã€‚ä»–ä»¬å¯¹ HTTPã€POP3 å’Œ SMTP ç­‰ä¸€ç»„åè®®çš„å‡†ç¡®ç‡é«˜è¾¾ 91%ã€‚åœ¨ç±»ä¼¼çš„å·¥ä½œä¸­ï¼Œè¿˜æœ‰äººè€ƒè™‘äº†æ•°æ®åŒ…å¤§å°çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚ä»–ä»¬çš„æ–¹æ¡ˆèƒ½å¤Ÿè¯†åˆ«æ›´å¹¿æ³›çš„åè®®ï¼ŒåŒ…æ‹¬æ–‡ä»¶ä¼ è¾“åè®® (FTP)ã€äº’è”ç½‘æ¶ˆæ¯è®¿é—®åè®® (IMAP)ã€SSH å’Œ TELNETï¼Œå‡†ç¡®ç‡é«˜è¾¾87%ã€‚ ç°å¦‚ä»Šï¼Œå·²ç»æœ‰äº†å¤§é‡æœºå™¨å­¦ä¹ æ–¹æ³•æ¥å¯¹æµé‡è¿›è¡Œåˆ†ç±»ã€‚æ¯”å¦‚æœ‰è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œç»è¿‡è®­ç»ƒå¯ä»¥å¯¹åŒ…æ‹¬ Kazaaã€BitTorrentã€GnuTella åœ¨å†…çš„å¤§å¤šæ•°çŸ¥å P2P åè®®è¿›è¡Œåˆ†ç±»ï¼Œå¹¶è¾¾åˆ° 99% çš„å‡†ç¡®ç‡ã€‚ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨å’Œæ ¸å¯†åº¦ä¼°è®¡å™¨å¯ä»¥åœ¨åŒä¸€ç»„åº”ç”¨ç¨‹åºä¸Šå®ç° 96% çš„å‡†ç¡®åº¦ã€‚åœ¨æµé‡åˆ†ç±»é—®é¢˜ä¸Šï¼Œäººå·¥ç¥ç»ç½‘ç»œæ–¹æ³•å¯ä»¥èƒœè¿‡æœ´ç´ è´å¶æ–¯æ–¹æ³•ã€‚åœ¨â€œISCX VPN-nonVPNâ€æµé‡æ•°æ®é›†ä¸Šå‘è¡¨çš„ä¸¤ç¯‡æœ€é‡è¦çš„è®ºæ–‡éƒ½æ˜¯åŸºäºæœºå™¨å­¦ä¹ æ–¹æ³•çš„ã€‚è¿˜æœ‰ä¸€äº›ä½¿ç”¨ä¸æ—¶é—´ç›¸å…³çš„ç‰¹å¾çš„ç ”ç©¶ï¼Œä¾‹å¦‚æµçš„æŒç»­æ—¶é—´ã€æ¯ç§’æµå­—èŠ‚æ•°ã€å‰å‘å’Œåå‘åˆ°è¾¾é—´éš”æ—¶é—´ç­‰ï¼Œä½¿ç”¨ k-æœ€è¿‘é‚»å’Œ C4.5 å†³ç­–æ ‘ç®—æ³•æ¥åˆ†ç±»ç½‘ç»œæµé‡ã€‚æœ€ç»ˆå¯ä»¥å®ç°äº†å¤§çº¦ 92% çš„å¬å›ç‡ï¼Œä½¿ç”¨ C4.5 ç®—æ³•åˆ†ç±»äº†å…­å¤§ç±»æµé‡ï¼ŒåŒ…æ‹¬ç½‘ç«™æµè§ˆã€ç”µå­é‚®ä»¶ã€èŠå¤©ã€æµåª’ä½“ã€æ–‡ä»¶ä¼ è¾“å’Œ IP è¯­éŸ³ã€‚è¿˜åœ¨é€šè¿‡ VPN éš§é“ä¼ è¾“çš„åŒä¸€æ•°æ®é›†ä¸Šä½¿ç”¨ C4.5 ç®—æ³•å®ç°äº†å¤§çº¦ 88% çš„å¬å›ç‡ã€‚è¿˜æœ‰ä¸€äº›ç ”ç©¶æ‰‹åŠ¨é€‰æ‹© 111 ä¸ªæµåŠ¨ç‰¹å¾å¹¶ä½¿ç”¨ k-æœ€è¿‘é‚»ç®—æ³•åœ¨ 14 ç±»åº”ç”¨ä¸­å®ç°äº† 94% çš„å‡†ç¡®ç‡ã€‚æ‰€æœ‰è¿™äº›æ–¹æ³•çš„ä¸»è¦ç¼ºç‚¹æ˜¯ç‰¹å¾æå–å’Œç‰¹å¾é€‰æ‹©é˜¶æ®µåŸºæœ¬ä¸Šæ˜¯åœ¨ä¸“å®¶çš„å¸®åŠ©ä¸‹å®Œæˆçš„ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•è€—æ—¶ã€æ˜‚è´µä¸”å®¹æ˜“å‡ºç°äººä¸ºé”™è¯¯ã€‚æ­¤å¤–ï¼Œå¯¹äºä½¿ç”¨ k-æœ€è¿‘é‚»åˆ†ç±»å™¨çš„æƒ…å†µï¼Œå½“ç”¨äºé¢„æµ‹æ—¶ï¼Œè¯¥ç®—æ³•çš„æ‰§è¡Œæ—¶é—´æ˜¯ä¸€ä¸ªä¸»è¦é—®é¢˜ã€‚ DeepLearning-based Technology A. å¤šå±‚æ„ŸçŸ¥æœº å¤šå±‚æ„ŸçŸ¥æœº(MLP)æ˜¯ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”±ä¸€ä¸ªè¾“å…¥å±‚ã€ä¸€ä¸ªè¾“å‡ºå±‚å’Œå‡ ä¸ªéšè—å±‚ç¥ç»å…ƒç»„æˆã€‚æ¯å±‚éƒ½æœ‰å‡ ä¸ªç¥ç»å…ƒï¼Œè¿™äº›ç¥ç»å…ƒä¸ç›¸é‚»å±‚ç´§å¯†ç›¸è¿ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚ç¥ç»å…ƒå¯¹å…¶è¾“å…¥è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¹¶é€šè¿‡éçº¿æ€§æ¿€æ´»å‡½æ•°äº§ç”Ÿè¾“å‡ºã€‚ä»ç†è®ºä¸Šè®²ï¼Œè¶³å¤Ÿå¯†é›†ä¸”è¶³å¤Ÿæ·±çš„å¤šå±‚æ„ŸçŸ¥æœºå¯ä»¥ä¼°è®¡ä»»æ„å‡½æ•°ã€‚ç„¶è€Œï¼Œç”±äºæ¨¡å‹éœ€è¦å­¦ä¹ å¤§é‡çš„å‚æ•°ï¼Œè¿™ä¸ªæ¨¡å‹é€šå¸¸éå¸¸å¤æ‚ã€ä½æ•ˆå¹¶ä¸”éš¾ä»¥é’ˆå¯¹ä»»æ„å¤æ‚é—®é¢˜è¿›è¡Œè®­ç»ƒã€‚å°½ç®¡å•ç‹¬ä½¿ç”¨æ·±åº¦å¤šå±‚æ„ŸçŸ¥æœºå·²ç»è¯æ˜æ•ˆæœå¾ˆå·®ï¼Œä½†ä½¿ç”¨å‡ å±‚å…¨è¿æ¥çš„ç¥ç»å…ƒçš„æ„ŸçŸ¥æœºä»ç„¶å¯ä»¥ä½œä¸ºå…¶ä»–æ¨¡å‹ä¸­é—´çš„ç»„æˆéƒ¨åˆ†ä½¿ç”¨ã€‚å¯¹äºç½‘ç»œæµé‡åˆ†ç±»ï¼Œå•çº¯çš„å¤šå±‚æ„ŸçŸ¥æœºç”±äºå…¶å¤æ‚æ€§å’Œå‡†ç¡®æ€§ä½è€Œå¾ˆå°‘ä½¿ç”¨ã€‚åœ¨ [1] ä¸­ï¼Œå°†è®¸å¤šæ·±åº¦å­¦ä¹ æ–¹æ³•ä¸éšæœºæ£®æ— (RF) ç®—æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œä»¥æ˜¾ç¤ºæ€§èƒ½å·®è·ã€‚ä»–ä»¬ä½¿ç”¨ 3 ä¸ªå…·æœ‰ä¸åŒæ ‡ç­¾æ•°é‡çš„ç§»åŠ¨æ•°æ®é›†ã€‚è®¸å¤šæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å…¶ä¸­ä¸¤ä¸ªæ•°æ®é›†ä¸­ä¼˜äºéšæœºæ£®æ—ç®—æ³•ã€‚ç„¶è€Œï¼Œå®éªŒè®¾ç½®å¹¶ä¸å®Œå…¨å…¬å¹³ï¼Œå› ä¸ºç”¨äº RFã€MLP å’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ–¹æ³•çš„è¾“å…¥ç‰¹å¾ä¸åŒã€‚å› æ­¤ï¼Œä¸åº”å°†å…¶ç»“æœè§†ä¸ºå¯¹ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•çš„å…¨é¢æ¯”è¾ƒã€‚ å›¾ 1 å¤šå±‚æ„ŸçŸ¥æœº B. å·ç§¯ç¥ç»ç½‘ç»œ ä¸å¤šå±‚æ„ŸçŸ¥æœºç±»ä¼¼ï¼Œå·ç§¯ç¥ç»ç½‘ç»œ (CNN) ä¹Ÿç”±å‡ ä¸ªå…·æœ‰å¯å­¦ä¹ å‚æ•°çš„å±‚ç»„æˆã€‚å¤šå±‚æ„ŸçŸ¥æœºæ— æ³•å¾ˆå¥½åœ°å¤„ç†å¯¼è‡´éšè—å±‚ä¸­æœ‰å¤§é‡å¯å­¦ä¹ å‚æ•°çš„é«˜ç»´æ•°æ®ã€‚å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¦‚å›¾ 2 æ‰€ç¤ºï¼Œé€šè¿‡ä½¿ç”¨å·ç§¯å±‚è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚åœ¨å·ç§¯å±‚ä¸­ï¼Œä½¿ç”¨äº†ä¸€ç»„å…·æœ‰å°‘é‡å¯å­¦ä¹ å‚æ•°çš„å°å†…æ ¸ã€‚åŒä¸€ç»„å†…æ ¸ç”¨äºæ•´åˆè¾“å…¥ä»¥äº§ç”Ÿä¸‹ä¸€å±‚çš„è¾“å‡ºã€‚é€šè¿‡åœ¨å±‚ä¸­ä½¿ç”¨ç›¸åŒçš„å¤šä¸ªå†…æ ¸ï¼Œå¯å­¦ä¹ å‚æ•°çš„æ•°é‡æ˜¾ç€å‡å°‘ã€‚åœ¨æ•´ä¸ªè¾“å…¥ä¸Šä½¿ç”¨è¿™äº›å†…æ ¸æœ‰åŠ©äºæ¨¡å‹æ›´è½»æ¾åœ°æ•è·ç§»ä½ä¸å˜ç‰¹å¾ã€‚ æ± åŒ–å±‚ä¹Ÿç”¨äºä¸€ä¸ªæˆ–å‡ ä¸ªå·ç§¯å±‚ä¹‹åè¿›è¡ŒäºŒæ¬¡é‡‡æ ·ã€‚æ­¤å¤–ï¼Œæœ€åçš„éšè—å±‚é€šå¸¸é‡‡ç”¨å…¨è¿æ¥å±‚ã€‚[2] ä¸­æå‡ºäº†æœ€ç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œ (CNN) æ¨¡å‹ï¼Œå®ƒåŸºæœ¬ä¸Šç”¨ä¸€ç»´å‘é‡è¡¨ç¤ºæ¯ä¸ªæµæˆ–ä¼šè¯ï¼Œæ¥è¾“å…¥åˆ°å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ä»–ä»¬çš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹æœ‰ 2 ä¸ªå·ç§¯å±‚ã€2 ä¸ªæ± åŒ–å±‚å’Œ 2 ä¸ªå…¨è¿æ¥å±‚ã€‚å®ƒä»¬å¯¹æ¯ä¸ªæ•°æ®åŒ…ä¸­çš„å­—èŠ‚è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¹¶ä¸”ä»…ä½¿ç”¨å‰ 784 ä¸ªå­—èŠ‚ã€‚ä»–ä»¬åœ¨ 12 ä¸ªç±»åˆ«çš„åŠ å¯†åº”ç”¨ç¨‹åºæ•°æ®é›†ä¸Šè¯„ä¼°ä»–ä»¬çš„æ¨¡å‹ï¼Œå¹¶è¡¨ç°å‡ºæ¯”ä½¿ç”¨æ—¶é—´åºåˆ—å’Œç»Ÿè®¡ç‰¹å¾çš„ C4.5 æ–¹æ³•æœ‰æ˜¾ç€æ”¹è¿›ã€‚åœ¨ [3] ä¸­ï¼Œä½œè€…è¿˜ä½¿ç”¨å…·æœ‰ 2 ä¸ªå·ç§¯å±‚ã€2 ä¸ªæ± åŒ–å±‚å’Œ 3 ä¸ªå…¨è¿æ¥å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œæ¥æ‰§è¡Œåè®®å’Œåº”ç”¨ç¨‹åºåˆ†ç±»ä»»åŠ¡ã€‚ä»–ä»¬ä½¿ç”¨å†ç°å†…æ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ (RKHS) åµŒå…¥å¹¶å°†æ—©æœŸæ—¶é—´åºåˆ—æ•°æ®è½¬æ¢ä¸ºäºŒç»´å›¾åƒã€‚ä»–ä»¬çš„å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨åè®®å’Œåº”ç”¨åˆ†ç±»ä»»åŠ¡ä¸­ä¼˜äºç»å…¸çš„æœºå™¨å­¦ä¹ æ–¹æ³•å’Œå¤šå±‚æ„ŸçŸ¥æœºã€‚ [4] ä¸­ä½¿ç”¨åŸºäºç®€å•ä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œçš„åŠç›‘ç£æ–¹æ³•å¯¹äº”ä¸ªè°·æ­Œåº”ç”¨ç¨‹åºè¿›è¡Œåˆ†ç±»ã€‚ä»–ä»¬è®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œä»å…·æœ‰å¤§é‡æœªæ ‡è®°æ•°æ®é›†çš„å‡ ä¸ªé‡‡æ ·æ•°æ®åŒ…ä¸­é¢„æµ‹æ•´ä¸ªæµçš„ç»Ÿè®¡ç‰¹å¾ã€‚ç„¶åï¼Œä»–ä»¬å°†æƒé‡è½¬ç§»åˆ°ä¸€ä¸ªæ–°æ¨¡å‹ï¼Œå¹¶é‡æ–°è®­ç»ƒå®ƒä»¥æ‰§è¡Œåº”ç”¨åˆ†ç±»ä»»åŠ¡ï¼Œåªä½¿ç”¨å‡ ä¸ªæ ‡è®°æ ·æœ¬ã€‚ä»–ä»¬å±•ç¤ºäº†ä½¿ç”¨é‡‡æ ·æ—¶é—´åºåˆ—ç‰¹å¾è€Œä¸æ˜¯å‰ n ä¸ªæ•°æ®åŒ…çš„å¯èƒ½æ€§ï¼Œè¿™å¯¹äºé«˜å¸¦å®½æ“ä½œç½‘ç»œå¯è¡Œæ€§æ›´é«˜ [4]ã€‚ å›¾ 2 å·ç§¯ç¥ç»ç½‘ç»œ C. å¾ªç¯ç¥ç»ç½‘ç»œ å¾ªç¯ç¥ç»ç½‘ç»œ (RNN) æ˜¯åŒ…å«ç”¨äºå­˜å‚¨æ—¶é—´ä¿¡æ¯çš„å¾ªç¯çš„ç¥ç»ç½‘ç»œï¼Œå¦‚å›¾3 æ‰€ç¤ºã€‚å¾ªç¯ç¥ç»ç½‘ç»œæ˜¯ä¸“é—¨ä¸ºé¡ºåºæ•°æ®è®¾è®¡çš„ï¼Œå…¶ä¸­è¾“å‡ºå¯èƒ½ä¸ä»…å–å†³äºæœ€åä¸€ä¸ªè¾“å…¥ï¼Œè¿˜å–å†³äºä¹‹å‰çš„è¾“å…¥ã€‚å¾ªç¯ç¥ç»ç½‘ç»œå·²æˆåŠŸåº”ç”¨äºè¯­éŸ³è¯†åˆ«ã€æ—¶é—´åºåˆ—é¢„æµ‹ã€ç¿»è¯‘å’Œè¯­è¨€å»ºæ¨¡ç­‰ä¸€ç³»åˆ—ä»»åŠ¡ã€‚æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸ä½¿å¾—å­¦ä¹ é•¿æœŸçš„ä¾èµ–å…³ç³»å˜å¾—å›°éš¾(ä¾‹å¦‚ï¼Œç›¸è·å¾ˆè¿œçš„è¾“å…¥ä¹‹é—´çš„ä¾èµ–)ï¼Œæ˜¯ä¼ ç»Ÿå¾ªç¯ç¥ç»ç½‘ç»œä¸­çš„ä¸€ä¸ªå¸¸è§éšœç¢ã€‚é•¿çŸ­æœŸè®°å¿† (LSTM) é€šè¿‡æ·»åŠ ä¸€ç»„æ§åˆ¶ä½•æ—¶å­˜å‚¨æˆ–åˆ é™¤ ä¿¡æ¯çš„é—¨æ¥ç¼“è§£è¿™äº›é—®é¢˜ã€‚å¯¹äºç½‘ç»œåˆ†ç±»ä»»åŠ¡ï¼Œç ”ç©¶å‘ç°æ··åˆæ¨¡å‹ä¼˜äºçº¯é•¿çŸ­æœŸè®°å¿†æ¨¡å‹æˆ–å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ [5]ã€‚å·ç§¯ç¥ç»ç½‘ç»œå’Œå¾ªç¯ç¥ç»ç½‘ç»œéƒ½åœ¨ [6]ã€[5] ä¸­ç”¨äºä¸åŒçš„åº”ç”¨æ¥æ•æ‰æµçš„ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚é™¤äº†å¾®å°çš„å·®å¼‚ä¹‹å¤–ï¼Œä¸¤é¡¹ç ”ç©¶éƒ½å°†å‰ 6 åˆ° 30 ä¸ªæ•°æ®åŒ…çš„å†…å®¹å¸¦åˆ°å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€å¾ªç¯ç¥ç»ç½‘ç»œæˆ–é•¿çŸ­æœŸè®°å¿†æ¨¡å‹ã€‚å°½ç®¡ç¡®åˆ‡çš„è¾“å…¥ç‰¹å¾ã€ç¥ç»ç½‘ç»œæ¶æ„å’Œæ•°æ®é›†ä¸åŒï¼Œä½†å®ƒä»¬éƒ½è¾¾åˆ°äº†å¾ˆé«˜çš„ç²¾åº¦ã€‚å°½ç®¡å®ƒä»¬åœ¨åºåˆ—æ•°æ®æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†é•¿çŸ­æœŸè®°å¿†å¹¶ä¸é€‚åˆéœ€è¦æ˜¾å¼å’Œå¤–éƒ¨å­˜å‚¨å™¨çš„å¤æ‚ä»»åŠ¡ã€‚æœ€è¿‘å¼•å…¥äº†æ–°çš„æ¶æ„ï¼Œä¾‹å¦‚è®°å¿†ç½‘ç»œå’Œç¥ç»å›¾çµæœº (NTM)ï¼Œä»¥å°†æ˜¾å¼è®°å¿†åµŒå…¥åˆ°æ¶æ„ä¸­ï¼Œç§°ä¸ºè®°å¿†å¢å¼ºç¥ç»ç½‘ç»œ (MANN)ã€‚è®°å¿†å¢å¼ºç¥ç»ç½‘ç»œå·²æˆåŠŸåº”ç”¨äºè¯­è¨€å»ºæ¨¡ã€é—®ç­”å’Œä¸€æ¬¡æ€§å­¦ä¹ ã€‚ä½†å°šæœªç ”ç©¶è®°å¿†å¢å¼ºç¥ç»ç½‘ç»œåœ¨ç½‘ç»œåˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ å›¾ 3 å¾ªç¯ç¥ç»ç½‘ç»œ D. è‡ªç¼–ç å™¨ (AE) ç›¸å¯¹äºä¸Šè¿°æ¨¡å‹ï¼Œè‡ªç¼–ç å™¨ (AE) å…·æœ‰æ˜æ˜¾æ›´å°çš„éšè—å±‚çš„ç¥ç»ç½‘ç»œï¼Œç›®çš„æ˜¯åœ¨è¾“å‡ºç«¯é‡å»ºè¾“å…¥ï¼Œå¦‚å›¾ 4 æ‰€ç¤ºã€‚å†…éƒ¨çš„ç¼–ç è¡¨ç¤ºå¯ç”¨äºæ•°æ®å‹ç¼©æˆ–é™ç»´ã€‚å¤šå±‚æ„ŸçŸ¥æœºã€å·ç§¯ç¥ç»ç½‘ç»œå’Œå¾ªç¯ç¥ç»ç½‘ç»œéƒ½å¯ä»¥ç”¨ä½œè‡ªç¼–ç å™¨æ¶æ„çš„ä¸€éƒ¨åˆ†ã€‚è‡ªç¼–ç å™¨å¹¿æ³›ç”¨äºåˆå§‹åŒ–æ·±åº¦æ¶æ„çš„æƒé‡ã€‚è‡ªç¼–ç å™¨æœ‰ä¸€äº›å˜ä½“ï¼Œä¾‹å¦‚å»å™ªè‡ªç¼–ç å™¨ (DAE) é€šè¿‡è¾“å…¥å¸¦å™ªéŸ³çš„æ ·æœ¬æ¥è¾“å‡ºå®Œæ•´çš„è¾“å…¥æ ·æœ¬ï¼Œä»è€Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´ç¨³å¥çš„ç‰¹å¾ï¼Œä»¥åŠç”¨äºç”Ÿæˆçš„å˜åˆ†è‡ªç¼–ç å™¨ (VAE)å¯ä»¥äº§ç”Ÿæ¨¡æ‹Ÿç›®æ ‡åˆ†å¸ƒçš„è™šå‡æ•°æ®ã€‚æ›´å¤æ‚çš„æ¶æ„ï¼Œç§°ä¸ºå †å å¼è‡ªåŠ¨ç¼–ç å™¨ (SAE)ï¼Œå †å äº†å¤šä¸ªè‡ªç¼–ç å™¨ï¼Œå…¶ä¸­æ¯ä¸ªè‡ªç¼–ç å™¨çš„è¾“å‡ºéƒ½æ˜¯ä¸‹ä¸€ä¸ªè‡ªç¼–ç å™¨çš„è¾“å…¥ï¼Œæ•´ä¸ªæ¨¡å‹ä»¥è´ªå©ªçš„é€å±‚æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚ä¹Ÿå¯ä»¥è®­ç»ƒä¸€ä¸ªæ··åˆå­¦ä¹ æ¡†æ¶ï¼Œå®ƒå°†è‡ªç¼–ç å™¨ä¸å¤šå±‚æ„ŸçŸ¥æœºæˆ–å…¶ä»–æ¨¡å‹ç›¸ç»“åˆï¼Œä»ä¸€å¼€å§‹å°±å¸¦æœ‰æ ‡è®°æ•°æ®ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹åŒæ—¶å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºåˆ†å¸ƒã€‚è¿™ç§æ··åˆæ¨¡å‹ä½¿ç”¨å¤šç›®æ ‡æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬æ ‡å‡†è¾“å‡ºæŸå¤±ä»¥åŠé‡å»ºæŸå¤±ã€‚è‡ªç¼–ç å™¨é€šå¸¸ä½¿ç”¨æ— ç›‘ç£çš„æ–¹å¼æ¥è·å¾—è¾“å…¥æ•°æ®çš„è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºä»¥åå¯ä»¥ç”¨ä½œåˆ†ç±»å™¨çš„ä¸€éƒ¨åˆ†ã€‚ä¾‹å¦‚ï¼Œåœ¨ [7] ä¸­ï¼Œä½¿ç”¨è‡ªç¼–ç å™¨æ¥é‡æ„è¾“å…¥ã€‚ç„¶åï¼Œå°† softmax å±‚åº”ç”¨äºè‡ªç¼–ç å™¨çš„ç¼–ç å†…éƒ¨è¡¨ç¤ºï¼Œæœ€åè¾¾åˆ°äº†ä¸é”™çš„ç²¾åº¦ã€‚ä»–ä»¬ä½¿ç”¨è‡ªå·±çš„ç§æœ‰æ•°æ®é›†ï¼ŒåŒ…å« 7 ç§æµé‡ç±»å‹ã€‚æ­¤å¤–ï¼Œä»–ä»¬ä½¿ç”¨ 12 ä¸ªåŒºé—´å’Œä¸¤ä¸ªæµå‘çš„ 9 ä¸ªç»Ÿè®¡ç‰¹å¾ä½œä¸ºè¾“å…¥ã€‚åœ¨ [8] ä¸­ï¼Œä½œè€…ä½¿ç”¨æ ‡å¤´å’Œæœ‰æ•ˆè´Ÿè½½æ•°æ®åœ¨ ISCX VPN non-VPN æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œå’Œå †å å¼è‡ªç¼–ç å™¨æ¨¡å‹ã€‚ä¸¤ç§æ¨¡å‹éƒ½æ˜¾ç¤ºå‡ºå¾ˆé«˜çš„å‡†ç¡®æ€§ï¼Œä½†å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ€§èƒ½ç•¥ä¼˜äºå †å å¼è‡ªç¼–ç å™¨æ¨¡å‹ã€‚ å›¾ 4 è‡ªç¼–ç å™¨ E. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æ˜¯ä¸€ç§æ— ç›‘ç£æŠ€æœ¯ï¼Œå¯åŒæ—¶è®­ç»ƒç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹ã€‚å¦‚å›¾ 5 æ‰€ç¤ºï¼Œç”Ÿæˆå™¨æ—¨åœ¨ç”Ÿæˆç›®æ ‡åˆ†å¸ƒçš„æ•°æ®ï¼Œè€Œåˆ¤åˆ«å™¨æ¨¡å‹æ—¨åœ¨åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®ã€‚è¿™ä¸¤ç§æ¨¡å‹é€šå¸¸éƒ½æ˜¯ç¥ç»ç½‘ç»œã€‚é¦–å…ˆè®­ç»ƒç”Ÿæˆå™¨ä»¥é€šè¿‡åˆ¤åˆ«å™¨æœ€å¤§åŒ–é”™è¯¯æ¦‚ç‡ã€‚ç„¶åï¼Œå›ºå®šç”Ÿæˆå™¨å¹¶è®­ç»ƒé‰´åˆ«å™¨ä»¥æœ€å°åŒ–é”™è¯¯æ¦‚ç‡ï¼ŒåŒæ—¶è¾“å…¥çœŸå®å’Œç”Ÿæˆçš„æ•°æ®ã€‚ç»§ç»­è¯¥è¿‡ç¨‹ç›´åˆ°æ”¶æ•›ã€‚å°½ç®¡ç”Ÿæˆå¯¹æŠ—ç½‘ç»œéš¾ä»¥è®­ç»ƒå’Œæ”¶æ•›ï¼Œä½†å®ƒå·²è¢«ç”¨äºè®¸å¤šåº”ç”¨ä¸­ï¼Œä¾‹å¦‚åˆ›å»ºé€¼çœŸçš„å›¾åƒã€ä»å›¾åƒé‡å»º 3D æ¨¡å‹ã€æé«˜å›¾åƒè´¨é‡ã€ä¸ºæ•°æ®ç¨€ç¼ºçš„åº”ç”¨åˆ›å»ºåˆæˆæ•°æ®ã€‚ç”Ÿæˆæ¨¡å‹å¯ç”¨äºå¤„ç†ç½‘ç»œæµé‡åˆ†ç±»ä¸­çš„æ•°æ®é›†ä¸å¹³è¡¡é—®é¢˜ã€‚ä¸å¹³è¡¡é—®é¢˜æ˜¯æŒ‡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡å˜åŒ–å¾ˆå¤§çš„æƒ…å†µã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•é€šå¸¸éš¾ä»¥æ­£ç¡®é¢„æµ‹æ•°æ®è¾ƒå°‘çš„ç±»åˆ«ã€‚å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†æœ€å¸¸è§å’Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯å¯¹æ•°æ®è¾ƒå°‘çš„ç±»åˆ«è¿›è¡Œè¿‡é‡‡æ ·ï¼Œå¤åˆ¶äº§ç”Ÿæ›´å¤šçš„æ ·æœ¬ï¼Œæˆ–å¯¹æ•°æ®è¾ƒå¤šçš„ç±»åˆ«è¿›è¡Œæ¬ é‡‡æ ·ï¼Œä»å…¶ä¸­åˆ é™¤ä¸€äº›æ ·æœ¬ã€‚åœ¨ [9] ä¸­ï¼Œè¾…åŠ©åˆ†ç±»çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(AC- GAN)å¯ä»¥ç”Ÿæˆç”¨äºç›‘ç£ç½‘ç»œåˆ†ç±»ä»»åŠ¡çš„åˆæˆæ ·æœ¬ã€‚ AC-GAN å’Œä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„ä¸»è¦åŒºåˆ«åœ¨äº AC-GAN åŒæ—¶å°†éšæœºå™ªå£°å’Œç±»æ ‡ç­¾ä½œä¸ºè¾“å…¥ï¼Œä»è€Œç”Ÿæˆè¾“å…¥ç±»æ ‡ç­¾çš„æ ·æœ¬ã€‚ä»–ä»¬ä½¿ç”¨å…·æœ‰ä¸¤ä¸ªç±»(SSH å’Œé SSH)çš„å…¬å…±æ•°æ®é›†ã€ 22 ä¸ªç»Ÿè®¡ç‰¹å¾æ¥ä½œä¸ºè¾“å…¥ã€‚ä»–ä»¬ä»…ä½¿ç”¨æ·±åº¦æ¨¡å‹æ¥ç”Ÿæˆåˆæˆæ•°æ®ã€‚å¯¹äºåˆ†ç±»éƒ¨åˆ†ï¼Œä»–ä»¬ä½¿ç”¨ç»å…¸çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼ŒåŒ…æ‹¬æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—å’Œå†³ç­–æ ‘ã€‚ å›¾ 5 ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ F. å›¾ç¥ç»ç½‘ç»œ å›¾ç¥ç»ç½‘ç»œ(GNN)æ˜¯ä¸€ç§ç›´æ¥ä½œç”¨äºå›¾ç»“æ„ä¸Šçš„ç¥ç»ç½‘ç»œã€‚å¦‚å›¾ 6 æ‰€ç¤ºï¼Œå›¾ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªå…¸å‹åº”ç”¨æ˜¯èŠ‚ç‚¹åˆ†ç±»ï¼Œæœ¬è´¨ä¸Šï¼Œå›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¸ä¸€ä¸ªæ ‡ç­¾ç›¸å…³è”ï¼Œæˆ‘ä»¬å¸Œæœ›é¢„æµ‹æœªæ ‡è®°èŠ‚ç‚¹çš„æ ‡ç­¾ã€‚åœ¨èŠ‚ç‚¹åˆ†ç±»é—®é¢˜ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥ç”¨å…¶ç‰¹å¾è¡¨ç¤ºå¹¶ä¸”ä¸å·²æ ‡è®°çš„æ ‡ç­¾ç›¸å…³è”ã€‚ç»™å®šéƒ¨åˆ†æ ‡è®°çš„å›¾ï¼Œç›®æ ‡æ˜¯åˆ©ç”¨è¿™äº›æ ‡è®°çš„èŠ‚ç‚¹æ¥é¢„æµ‹æœªæ ‡è®°çš„èŠ‚ç‚¹æ ‡ç­¾ã€‚å®ƒé€šè¿‡å­¦ä¹ å¾—åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„é«˜ç»´å‘é‡(çŠ¶æ€)è¡¨ç¤ºï¼ŒåŒæ—¶åŒ…å«å…¶ç›¸é‚»èŠ‚ç‚¹çš„ä¿¡æ¯ã€‚Shen ç­‰äºº [10] æå‡ºäº†ä¸€ç§ç§°ä¸ºâ€œæµé‡äº¤äº’å›¾(TIG)â€çš„å›¾ç»“æ„ï¼ŒåŸºäºå›¾ç¥ç»ç½‘ç»œåˆ†ç±»å™¨ï¼Œè¯†åˆ«å»ä¸­å¿ƒåŒ–åº”ç”¨ç¨‹åº(DApp)ã€‚è¯¥æ–‡é‡‡ç”¨å›¾æ¥è¡¨å¾æµé‡äº¤äº’ç‰¹å¾ï¼Œå°†æµé‡æŒ‰æµåˆ’åˆ†ï¼Œæ¯æ¡æµåŒ…å«ä¸€ç³»åˆ—æ•°æ®åŒ…ï¼Œæ¯ä¸ªåŒ…ä»¥äº”å…ƒç»„(æº/ç›®çš„ IPï¼Œæº/ç›®çš„ç«¯å£ï¼Œåè®®)è¡¨ç¤ºã€‚ä»ç”¨æˆ·è§’åº¦çœ‹ï¼Œå°†ä¸Šè¡Œæµæ•°æ®åŒ…é•¿åº¦è®¾ä¸ºè´Ÿæ•°ï¼Œå°†ä¸‹è¡Œæµæ•°æ®åŒ…é•¿åº¦è®¾ä¸ºæ­£æ•°ã€‚ å›¾ 6 å›¾ç¥ç»ç½‘ç»œ System Design å¯¹äºç½‘ç»œæµé‡æ•°æ®åŒ…çš„åˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦è®­ç»ƒå‡ºä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„æ¨¡å‹æ¥å¤„ç†æ­¤é—®é¢˜ã€‚å› ä¸ºç°é˜¶æ®µï¼Œæ·±åº¦å­¦ä¹ å‘å±•å¦‚ç«å¦‚è¼ï¼Œæœ‰å¾ˆå¤šæ¯”è¾ƒæ–°çš„åŠæ³•åœ¨å¾ˆå¤šé—®é¢˜ä¸Šéƒ½æœ‰å¾ˆå¥½çš„æ•ˆæœï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰å–æ·±åº¦å­¦ä¹ æ–¹æ³•æ¥è§£å†³æ­¤é—®é¢˜ã€‚å¯¹äºæ·±åº¦å­¦ä¹ ä¸­çš„æ¨¡å‹è®­ç»ƒè€Œè¨€ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªæœ€é‡è¦çš„å…³é”®ï¼Œä¸€ä¸ªæ˜¯æ¨¡å‹çš„é€‰æ‹©ï¼Œå¦ä¸€ä¸ªæ˜¯æ•°æ®çš„é€‰å–ã€‚æµç¨‹è®¾è®¡å¦‚å›¾ 7 æ‰€ç¤ºã€‚é¦–å…ˆæˆ‘ä»¬å°†é€‰å–çš„æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†æ¥é€‰æ‹©åˆé€‚çš„ç‰¹å¾ï¼Œä¹‹åé€šè¿‡ç‰¹å¾é™ç»´å¾—åˆ°å¯ä»¥ç”¨æ¥è®­ç»ƒçš„æ ·æœ¬æ•°æ®ï¼Œè¾“å…¥è¿›å…¥æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼Œç»è¿‡ä¸€ç³»åˆ—å‚æ•°è°ƒæ•´ä¸è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„ä¸€ä¸ªåˆ†ç±»å™¨ã€‚å°†å¾…åˆ†ç±»æ ·æœ¬è¾“å…¥è¿›å…¥è®­ç»ƒå®Œæˆçš„åˆ†ç±»æ¨¡å‹å°±å¯ä»¥å¾—åˆ°åˆ†ç±»çš„ç»“æœäº†ã€‚ å›¾ 7 æµç¨‹å›¾ Datasets å¯¹äºç½‘ç»œæµé‡æ•°æ®ï¼Œä»¥ç›¸å…³è®ºæ–‡é‡‡ç”¨çš„å¼€æºæ•°æ®é›†(æ¯”å¦‚ ISCX-VPN2016[11], ISCX2012[12], UNSW-NB15[13][14][15][16][17])ä¸ºåŸºç¡€ï¼Œæ ¹æ®ç›´æ¥æœé›†æ³•ä¸è„šæœ¬ç”Ÿæˆæ³•ï¼Œä»¥åŠå…¶ä»–ç±»ä¼¼æ•°æ®é›†çš„æ”¶é›†åŠæ³•ï¼Œä»¥å¤šä¸ªæ•°æ®é›†ç»“åˆï¼Œäº¤å‰éªŒè¯çš„åŠæ³•(æ··åˆç”Ÿæˆæ³•)ã€‚ ç›´æ¥æœé›†æ³•: å€ŸåŠ© Wiresharkã€Tcpdumpã€Sniffer ç­‰æŠ“åŒ…å·¥å…·åœ¨çœŸå®ç¯å¢ƒä¸­æ•æ‰æ•°æ®åˆ¶ä½œæ•°æ®é›†ã€‚ è„šæœ¬ç”Ÿæˆæ³•:æ¨¡æ‹Ÿæ”»å‡»æµé‡å¸¸åˆ©ç”¨è„šæœ¬æˆ–è™šæ‹Ÿç½‘ç»œäº§ç”Ÿï¼Œå¦‚æ¨¡æ‹Ÿ APT æ”»å‡»ã€ IOT æ”»å‡»ã€å†…ç½‘æ¸—é€ç­‰æ”»å‡»æµé‡æ¥ç»„æˆæ•°æ®é›†ã€‚ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:33:05 "},"DP/TrafficClassification/1.html":{"url":"DP/TrafficClassification/1.html","title":"Open Source","keywords":"","body":"Open source Useful Models Author = DanteSU Headers import torch from torch import nn, Tensor import torch.nn.functional as F from torch.nn import TransformerEncoder, TransformerEncoderLayer Deep Packet CNN # model 1 class DeepPacketCNN(nn.Module): def __init__(self, n_classes, batch_size): super(DeepPacketCNN, self).__init__() self.batch_size = batch_size self.conv1 = nn.Conv1d(1, 200, 5, 2, 0) self.bn1 = nn.BatchNorm1d(200) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv1d(200, 100, 4, 1, 0) self.bn2 = nn.BatchNorm1d(100) self.pool = nn.AvgPool1d(2) self.dropout = nn.Dropout(p=0.25) self.fc1 = nn.Sequential(nn.Linear(100 * 372, 600), # 00 * 372 nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc2 = nn.Sequential(nn.Linear(600, 500), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc3 = nn.Sequential(nn.Linear(500, 400), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc4 = nn.Sequential(nn.Linear(400, 300), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc5 = nn.Sequential(nn.Linear(300, 200), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc6 = nn.Sequential(nn.Linear(200, 100), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc7 = nn.Sequential(nn.Linear(100, 50), nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc_out = nn.Linear(50, n_classes) self.lsm = nn.LogSoftmax(dim=0) def forward(self, x): # print('x1x1x1x1x1x1x1x1', x.shape) x = self.conv1(x) # print('x2x2x2x2x2x2x2x2', x.shape) x = self.bn1(x) # print('x3x3x3x3x3x3x3x3', x.shape) x = self.relu(x) # print('x4x4x4x4x4x4x4x4', x.shape) x = self.conv2(x) # print('x5x5x5x5x5x5x5x5', x.shape) x = self.bn2(x) # print('x6x6x6x6x6x6x6x6', x.shape) x = self.relu(x) # print('x7x7x7x7x7x7x7x7', x.shape) x = self.pool(x).view(self.batch_size,-1) # print('x8x8x8x8x8x8x8x8', x.shape) x = self.fc1(x) x = self.fc2(x) x = self.fc3(x) x = self.fc4(x) x = self.fc5(x) x = self.fc6(x) x = self.fc7(x) x = self.fc_out(x) # print('xxxxxxxxxxxxxxxxxx',x.shape) y = self.lsm(x) # print('yyyyyyyyyyyyyyyyyy',y.shape) return y SAE # model 2 class AutoEncoder(nn.Module): def __init__(self, input_size, output_size): super(AutoEncoder, self).__init__() self.forward_pass = nn.Sequential(nn.Linear(input_size, output_size), nn.Dropout(p=0.05), nn.ReLU(True) ) self.backward_pass = nn.Linear(output_size, input_size) self.criterion = nn.MSELoss() self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1) def forward(self, x): x = x.detach() y = self.forward_pass(x) if self.training: x_reconstruct = self.backward_pass(y) loss = self.criterion(x_reconstruct, x.data) self.optimizer.zero_grad() loss.backward() self.optimizer.step() return y.detach() class StackedAutoEncoder(nn.Module): def __init__(self, n_classes): super(StackedAutoEncoder, self).__init__() self.ae1 = AutoEncoder(1500, 400) self.ae2 = AutoEncoder(400, 300) self.ae3 = AutoEncoder(300, 200) self.ae4 = AutoEncoder(200, 100) self.ae5 = AutoEncoder(100, 50) self.fc_out = nn.Linear(50, n_classes) self.lsm = nn.LogSoftmax(dim=0) def forward(self, x): x = self.ae1(x) x = self.ae2(x) x = self.ae3(x) x = self.ae4(x) x = self.ae5(x) y = self.fc_out(x) y = self.lsm(y) return y # model 3 class trafficBert(nn.Module): def __init__(self,n_classes): super(trafficBert, self).__init__() self.bert = BertModel.from_pretrained('bert_pretrain') # /bert_pretrain/ for param in self.bert.parameters(): param.requires_grad = True # æ¯ä¸ªå‚æ•°éƒ½è¦ æ±‚æ¢¯åº¦ self.fc = nn.Linear(768, n_classes) # 768 -> 2 def forward(self, x): print('_'*20, x.shape) context = x[0] # è¾“å…¥çš„å¥å­ (ids, seq_len, mask) types = x[1] mask = x[2] # å¯¹paddingéƒ¨åˆ†è¿›è¡Œmaskï¼Œå’Œå¥å­ç›¸åŒsizeï¼Œpaddingéƒ¨åˆ†ç”¨0è¡¨ç¤ºï¼Œå¦‚ï¼š[1, 1, 1, 1, 0, 0] _, pooled = self.bert(context, token_type_ids=types, attention_mask=mask, output_all_encoded_layers=False) # æ§åˆ¶æ˜¯å¦è¾“å‡ºæ‰€æœ‰encoderå±‚çš„ç»“æœ out = self.fc(pooled) # å¾—åˆ°10åˆ†ç±» return out ResNet # model 4 class ResNet(nn.Module): def __init__(self, ch_in, ch_out): super(ResNet, self).__init__() self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(ch_out) self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(ch_out) self.relu = nn.ReLU(inplace=True) self.extra = nn.Sequential() # å¦‚æœè¾“å…¥ã€è¾“å‡ºç»´åº¦ä¸åŒï¼Œéœ€è½¬åŒ–åæ‰èƒ½ç›¸åŠ  if ch_out != ch_in: self.extra = nn.Sequential( nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1), nn.BatchNorm2d(ch_out) ) def forward(self, x): # print('-1'*10,x.shape) out = self.conv1(x) # print('-2'*10,out.shape) out = self.bn1(out) # print('-3'*10,out.shape) out = self.relu(out) # print('-4'*10,out.shape) out = self.conv2(out) # print('-5'*10,out.shape) out = self.bn2(out) # print('-6'*10,out.shape) out = self.extra(x) + out # print('-7'*10,out.shape) return out class ResNet18(nn.Module): def __init__(self,n_classes): super(ResNet18, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64) ) self.relu = nn.ReLU(inplace=True) # 4 block [b, 64, h, w] => [b, 1024, h, w] self.blk1 = ResNet(64, 128) self.blk2 = ResNet(128, 256) self.blk3 = ResNet(256, 512) self.blk4 = ResNet(512, 1024) # æ³¨æ„æœ€åå…¨è¿æ¥å±‚ç»´åº¦ï¼Œè¿›å»ä¹‹å‰éœ€è¦å…ˆæ‰“å¹³ self.outlayer = nn.Linear(1024*30*50, n_classes) def forward(self, x): x = x.view(len(x),30,-1) x = x.unsqueeze(1) # print('-1'*10,x.shape) x = self.conv1(x) # print('-2'*10,x.shape) x = self.relu(x) # print('-3'*10,x.shape) # x = self.blk1(x) # print('-4'*10,x.shape) x = self.blk2(x) # print('-5'*10,x.shape) x = self.blk3(x) # print('-6'*10,x.shape) x = self.blk4(x) # print('-7'*10,x.shape) # print(x.size(0)) x = x.view(x.size(0), -1) # å…ˆæ‰“å¹³ï¼Œå†è¿›å…¨è¿æ¥ # print('-8'*10,x.shape) x = self.outlayer(x) # print('-9'*10,x.shape) return x LSTM Pure LSTM # model 5 class LSTM(nn.Module): def __init__(self,INPUT_SIZE,n_classes): super(LSTM, self).__init__() self.rnn = nn.LSTM( # if use nn.RNN(), it hardly learns input_size=INPUT_SIZE, hidden_size=64, # rnn hidden unit num_layers=1, # number of rnn layer batch_first=True, # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size) ) self.out = nn.Linear(64, n_classes) def forward(self, x): # x shape (batch, time_step, input_size) # r_out shape (batch, time_step, output_size) # h_n shape (n_layers, batch, hidden_size) # h_c shape (n_layers, batch, hidden_size) r_out, (h_n, h_c) = self.rnn(x, None) # None represents zero initial hidden state # choose r_out at the last time step out = self.out(r_out[:, -1, :]) return out LSTM+FC # model 5.1 class LSTM_FC2(nn.Module): def __init__(self,INPUT_SIZE,n_classes): super(LSTM_FC2, self).__init__() self.rnn = nn.LSTM( # if use nn.RNN(), it hardly learns input_size=INPUT_SIZE, hidden_size=1024, # rnn hidden unit num_layers=1, # number of rnn layer batch_first=True, # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size) ) self.fc1 = nn.Sequential(nn.Linear(1024,256), # 00 * 372 nn.Dropout(p=0.25), nn.ReLU(True) ) self.fc2 = nn.Sequential(nn.Linear(256, 64), nn.Dropout(p=0.25), nn.ReLU(True) ) self.out = nn.Linear(64, n_classes) self.lsm = nn.LogSoftmax(dim=0) def forward(self, x): # print(x.shape) # x shape (batch, time_step, input_size) # r_out shape (batch, time_step, output_size) # h_n shape (n_layers, batch, hidden_size) # h_c shape (n_layers, batch, hidden_size) r_out, (h_n, h_c) = self.rnn(x, None) # None represents zero initial hidden state # print('r_out is : ',r_out.shape) r_out = r_out[:, -1, :] # print('r_out is : ',r_out.shape) r_out = self.fc1(r_out) r_out = self.fc2(r_out) # choose r_out at the last time step out = self.out(r_out) # print('out is : ',out.shape) return out CNN+Transformer # model 6 class ResModule(nn.Module): def __init__(self, ch_in, ch_out, kernel_size, stride): super(ResModule, self).__init__() self.conv1 = nn.Conv1d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2) self.bn1 = nn.BatchNorm1d(ch_out) self.conv2 = nn.Conv1d(ch_out, ch_out, kernel_size=kernel_size, stride=1, padding=(kernel_size-1)//2) self.bn2 = nn.BatchNorm1d(ch_out) self.relu = nn.ReLU(inplace=True) if stride == 1: self.downsample = None else: self.downsample = nn.Sequential( nn.Conv1d(ch_in, ch_out, kernel_size=1, stride=stride), nn.BatchNorm1d(ch_out)) def forward(self, x): out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: x = self.downsample(x) return self.relu(x+out) class CNN(nn.Module): def __init__(self,ch): super(CNN, self).__init__() self.conv1 = nn.Sequential( nn.Conv1d(1, ch, kernel_size=3, stride=1, padding=1), nn.BatchNorm1d(ch) ) self.relu = nn.ReLU(inplace=True) self.blk1 = ResModule(ch, ch*2, 3, 2) self.blk2 = ResModule(ch*2, ch*2, 3, 2) self.blk3 = ResModule(ch*2, ch*4, 3, 2) self.blk4 = ResModule(ch*4, ch*4, 3, 2) def forward(self, x): x = self.conv1(x) x = self.relu(x) x = self.blk1(x) x = self.blk2(x) x = self.blk3(x) x = self.blk4(x) return x class PositionalEncoding(nn.Module): def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000): super().__init__() self.dropout = nn.Dropout(p=dropout) position = torch.arange(max_len).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)) pe = torch.zeros(max_len, 1, d_model) pe[:, 0, 0::2] = torch.sin(position * div_term) pe[:, 0, 1::2] = torch.cos(position * div_term) self.register_buffer('pe', pe) def forward(self, x: Tensor) -> Tensor: \"\"\" Args: x: Tensor, shape [seq_len, batch_size, embedding_dim] \"\"\" x = x + self.pe[:x.size(0)] return self.dropout(x) class CNN_TRAN(nn.Module): def __init__(self, n_classes): super(CNN_TRAN, self).__init__() self.cnn = CNN(ch=16) emsize = 64 self.pos_encoder = PositionalEncoding(emsize, dropout=0.2) encoder_layers = TransformerEncoderLayer(d_model=emsize, nhead=4, dim_feedforward=256, dropout=0.2) self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=4) self.d_model = emsize self.decoder = nn.Sequential( nn.Linear(64*94, 512), nn.ReLU(), nn.Linear(512, 256), nn.ReLU(), nn.Linear(256, n_classes) ) # self.init_weights() def init_weights(self) -> None: pass def forward(self, src: Tensor) -> Tensor: bs,_,_ = src.shape x = self.cnn(src).permute(2,0,1) x = self.pos_encoder(x) x = self.transformer_encoder(x).permute(1,2,0) x = self.decoder(x.reshape(bs,-1)) pred = F.softmax(x,dim=1) return pred LSTNet # model 7 class LSTNet(nn.Module): def __init__(self, window=50, input_dim=1500,hidRNN=100,hidCNN=250,hidSkip=5,CNN_kernel=5,skip=5, highway_window=1500,dropout=float(0.2),output_fun='sigmoid'): super(LSTNet, self).__init__() # P1500 m 1 self.use_cuda = True self.P = window# æ—¶é—´åºåˆ—çª—å£ï¼Œè¾“å…¥ç½‘ç»œçš„æ—¶é—´æˆ³é•¿åº¦ self.m = 30; # æ—¶é—´åºåˆ—è¾“å…¥ç»´åº¦ self.hidR = hidRNN # RNNå±‚è¾“å‡ºç»´åº¦ self.hidC = hidCNN # CNNå±‚è¾“å‡ºç»´åº¦ self.hidS = hidSkip # Skip-RNNå±‚è¾“å‡ºç»´åº¦ self.Ck = CNN_kernel # CNNå±‚kernelå¤§å° self.skip = skip # å‘¨æœŸé•¿åº¦ self.pt = int((self.P - self.Ck)/self.skip) # windowåœ¨kernelä½œç”¨ä¸‹ï¼Œä»¥skipä¸ºå‘¨æœŸçš„æ•°æ®æ•°é‡ã€‚å‘¨æœŸæ•°ç›®ã€‚ #50-5/5 =9 self.hw = highway_window # highwayé€šé“çš„è¾“å‡ºèŠ‚ç‚¹æ•°ç›® self.conv1 = nn.Conv2d(1, self.hidC, kernel_size = (self.Ck, self.m)) # ç¬¬ä¸€å±‚conv2d self.GRU1 = nn.GRU(self.hidC, self.hidR) # ç¬¬ä¸€å±‚GRU self.dropout = nn.Dropout(p = dropout) if (self.skip > 0): self.GRUskip = nn.GRU(self.hidC, self.hidS) # self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, self.m) self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, 11) else: self.linear1 = nn.Linear(self.hidR, self.m) if (self.hw > 0): # self.highway = nn.Linear(self.hw, 1) # highwayåè·Ÿçº¿æ€§å±‚ self.highway = nn.Linear(self.hw, 11) self.output = None if (output_fun == 'sigmoid'): self.output = F.sigmoid if (output_fun == 'tanh'): self.output = F.tanh def forward(self, x): # print('x here is : ',x.shape)#[2, 1, 1500] batch_size = x.size(0) # print('batch_size here is : ',batch_size)#2 # è¾“å…¥ x dim = [batch_size, window_size, data_dim] # å› ä¸º CNN conv2d need [batch_size, in_channels, inputHeight, inputWidth], # æ‰€ä»¥ x è½¬å˜ä¸º c = [batch_size, 1, window_size, data_dim] c = x.view(-1, 1, self.P, self.m)#[4, 1, 1500, 1] # print('c1 here is : ',c.shape) # ç»è¿‡ conv1 åï¼Œout = [batch_size, out_channels, outHeight, outWidth], # å…¶ä¸­ outWidth = self.m å³æ—¶é—´åºåˆ—è¾“å…¥ç»´åº¦ï¼Œå³æ¯æ¬¡kernelæ»‘åŠ¨éƒ½ä¼šå°†è¾“å…¥ç»´åº¦å˜ä¸º1, # æ‰€ä»¥ outWidth=1ï¼Œéœ€è¦ squeeze ä¸º3ä¸ªç»´åº¦ [batch_size, out_channels, outHeight] c = F.relu(self.conv1(c))#2, 250, 46, 1] # print('c2 here is : ',c.shape) c = self.dropout(c) # print('c3 here is : ',c.shape) c = torch.squeeze(c, 3); # batch_size, out_channels, outHeight] # print('c4 here is : ',c.shape) # RNN # GRU input shape: [seq_len, batch_size, input_size]ï¼Œéœ€è¦ç”± c å…ˆ reshape r = c.permute(2, 0, 1).contiguous() # print('r here is : ',r.shape) _, r = self.GRU1(r) r = self.dropout(torch.squeeze(r,0)) # [batch_size, hiddenRnn] # print('r here is : ',r.shape) #skip-rnn if (self.skip > 0): # print('here is skip!') s = c[:,:, int(-self.pt * self.skip):].contiguous(); # print('s1 here is : ',s.shape)#5 100 45 # print('-----------',batch_size, self.hidC, self.pt, self.skip) s = s.view(batch_size, self.hidC, int(self.pt), self.skip) #2,250,9,5 # print('s2 here is : ',s.shape) s = s.permute(2,0,3,1).contiguous() # print('s3 here is : ',s.shape) s = s.view(self.pt, batch_size * self.skip, self.hidC) # print('s4 here is : ',s.shape) _, s = self.GRUskip(s) s = s.view(batch_size, self.skip * self.hidS) # print('s5 here is : ',s.shape) s = self.dropout(s); # [batch_size, hiddenSkip] # print('s6 here is : ',s.shape) # æŠŠ(batch_size, hiddenRnn)å’Œ(batch_size, hiddenSkip)æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œ # ç„¶åé€šè¿‡å…¨è¿æ¥ï¼Œå¾—åˆ°(batch_size, data_dim)çš„éçº¿æ€§è¾“å‡º r = torch.cat((r,s),1) # print('r here is : ',r.shape) res = self.linear1(r) # [batch_size, data_dim(å³self.m)] è¿™ä¸ªçš„è¾“å‡ºå’Œè¾“å…¥æ˜¯ä¸€æ ·å¤§çš„ï¼Œä¸å¯¹ # print('res here is : ',res.shape) #highway if (self.hw > 0): # print('here is hw') z = x[:, -self.hw:, :] # print('z here is : ',z.shape) z = z.permute(0,2,1).contiguous().view(-1, self.hw) # print('z here is : ',z.shape)#4,1500 z = self.highway(z) # è¿‡çº¿æ€§å±‚ # print('z here is : ',z.shape)#2,1 # z = z.view(-1,self.m)#30 # print('z here is : ',z.shape) res = res + z# ç›¸åŠ  2,12 # print('res here is : ',res.shape) if (self.output): res = self.output(res)# è¿‡ä¸€å±‚æ¿€æ´»å‡½æ•°ï¼Œè®ºæ–‡é‡Œè¡¨ç¤ºreluæ•ˆæœæ¯”tanhæ›´å¥½ return res Data Processing from pcap to pickle import os import time from scapy.all import * #from pcapng.scanner import FileScanner import numpy as np import os import multiprocessing as mp import pickle as pk def pkts2X(pkts): X = [] #lens = [] for p in pkts: #=================================== # step 1 : remove Ether Header #=================================== r = raw(p)[14:] r = np.frombuffer(r, dtype = np.uint8) #p.show() #=================================== # step 2 : pad 0 to UDP Header # it seems that we need to do nothing this step # I found some length of raw data is larger than 1500 # remove them. #=================================== if (TCP in p or UDP in p): \"\"\" if UDP in p: # todo : padding 0 to print ('UDP', r[:20]) print(p[IP].src, p[IP].dst) else : print('TCP', r[:20]) print(p[IP].src, p[IP].dst) \"\"\" if (len(r) > 1500): pass else: X.append(r) #lens.append(len(r)) else: pass return X#, lens def get_data_by_file(filename): pkts = rdpcap(filename) X = pkts2X(pkts) # save X to npy and delete the original pcap (it's too large). return X def task(filename): global dict_name2label global counter head, tail = os.path.split(filename) cond1 = os.path.isfile(os.path.join('data', tail+'.pickle')) cond2 = os.path.isfile(os.path.join('data', tail+'_class.pickle')) if (cond1 and cond2): with lock: counter.value += 1 print('[{}] {}'.format(counter, filename)) return '#ALREADY#' X = get_data_by_file(filename) if (not cond1): y = [dict_name2label[tail]] * len(X) with open(os.path.join('data', tail+'.pickle'), 'wb') as f: pk.dump((X, y), f) if (not cond2): y2 = [dict_name2class[tail]] * len(X) with open(os.path.join('data', tail+'_class.pickle'), 'wb') as f: pk.dump(y2, f) with lock: counter.value += 1 print('[{}] {}'.format(counter, filename)) return 'Done' def gen_todo_list(directory, check = None): files = os.listdir(directory) todo_list = [] for f in files: fullpath = os.path.join(directory, f) if os.path.isfile(fullpath): if check is not None: if check(f): todo_list.append(fullpath) else: todo_list.append(fullpath) return todo_list #========================================= # mp init #========================================= with open('fileName2Application.pickle', 'rb') as f: dict_name2label = pk.load(f) with open('fileName2Characterization.pickle', 'rb') as f: dict_name2class = pk.load(f) lock = mp.Lock() counter = mp.Value('i', 0) cpus = mp.cpu_count()//2 pool = mp.Pool(processes=cpus) todo_list = gen_todo_list('../pcap') #todo_list = todo_list[:3] total_number = len(todo_list) done_list = [] res = pool.map(task, todo_list) print(len(res)) Links to two files needed fileName2Application.pickle fileName2Characterization.pickle from pickle to npy/txt import time # å‡†å¤‡æ•°æ®é›† import torch from torch.utils.data import Dataset, DataLoader import pickle as pk from sklearn.preprocessing import LabelBinarizer import numpy as np import time import os class MyDataset(Dataset): \"\"\" ä¸‹è½½æ•°æ®ã€åˆå§‹åŒ–æ•°æ®ï¼Œéƒ½å¯ä»¥åœ¨è¿™é‡Œå®Œæˆ \"\"\" def __init__(self,data_path): self.data_path = data_path self.data = self.data(task_type = 'class') self.X_train = torch.from_numpy(np.array(self.data[0])).to(torch.float32) self.X_val = torch.from_numpy(np.array(self.data[1])).to(torch.float32) self.X_test = torch.from_numpy(np.array(self.data[2])).to(torch.float32) self.y_train_onehot = torch.from_numpy(np.array(self.data[3])) self.y_val_onehot = torch.from_numpy(np.array(self.data[4])) self.y_test_onehot = torch.from_numpy(np.array(self.data[5])) def data(self, task_type): # load è³‡æ–™ data_time = time.time() X_train, y_train, X_val, y_val, X_test, y_test = self.load_data(task_type) print('The time consumption of loading data is : {}'.format(time.time()-data_time)) # print('yyyyyyyyyyyyyyyy', y_train[1]) # normalize X # X_train , X_val, X_test = np.array(X_train) / 255, np.array(X_val) / 255, np.array(X_test) / 255 # æŠŠ y çš„ string åšæˆ one hot encoding å½¢å¼ coding_time = time.time() label_encoder = LabelBinarizer() y_train_onehot = label_encoder.fit_transform(y_train) y_val_onehot = label_encoder.transform(y_val) y_test_onehot = label_encoder.transform(y_test) print('The time consumption of coding in one-hot is : {}'.format(time.time()-coding_time)) data = [X_train , X_val, X_test, y_train_onehot, y_val_onehot, y_test_onehot] return data def dump(self, data, filename): with open(filename, 'wb') as f: pk.dump(data, f) def load(self, filename): with open(filename, 'rb') as f: data = pk.load(f) return data def gen_todo_list(self, check = None): files = os.listdir(self.data_path) todo_list = [] for f in files: fullpath = os.path.join(self.data_path, f) if os.path.isfile(fullpath): if check is not None: if check(f): todo_list.append(fullpath) else: todo_list.append(fullpath) return todo_list def check(self, filename): return not '_class' in filename def load_data(self, task_type): max_data_nb = 10000 todo_list = self.gen_todo_list(check = self.check) train_rate = 0.64 val_rate = 0.16 X_train = [] y_train = [] X_val = [] y_val = [] X_test = [] y_test = [] for counter, filename in enumerate(todo_list): (tmpX, tmpy) = self.load(filename) if task_type == 'class': tmpy = self.load('.'.join(filename.split('.')[:-1]) + '_class.pickle') tmpX , tmpy = tmpX[:max_data_nb], tmpy[:max_data_nb] assert(len(tmpX) == len(tmpy)) tmpX = self.processX(tmpX) train_num = int(len(tmpX) * train_rate) val_num = int(len(tmpX) * val_rate) X_train.extend(tmpX[:train_num]) y_train.extend(tmpy[:train_num]) X_val.extend(tmpX[train_num: train_num + val_num]) y_val.extend(tmpy[train_num: train_num + val_num]) X_test.extend(tmpX[train_num + val_num:]) y_test.extend(tmpy[train_num + val_num:]) print('\\rLoading... {}/{}'.format(counter+1,len(todo_list)), end = '') print('\\r{} Data loaded. '.format(len(todo_list))) return X_train, y_train, X_val, y_val, X_test, y_test def processX(self, X): X = np.array(X) lens = [len(x) for x in X] maxlen = 1500 tmpX = np.zeros((len(X), maxlen)) mask = np.arange(maxlen) = len(self.index_list): raise StopIteration return self.index_list[self.pos] def __iter__(self): self.pos = -1 return self def __len__(self): return len(self.index_list) def do(data_path = '../data'): print('preparing dataset...') trainset = MyDataset(data_path=data_path) # è·å¾—æ•°æ®é›†çš„é•¿åº¦ len(), å³length train_data_size = len(trainset.X_train) # æ ¼å¼åŒ–å­—ç¬¦ä¸², format() ä¸­çš„æ•°æ®ä¼šæ›¿æ¢ {} print(\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸º: {}\".format(train_data_size)) # åœ¨GPUä¸ŠåŠ è½½æ•°æ® print('loading X_train...') X_train = trainset.X_train print(len(X_train)) print('loading y_train_onehot...') y_train_onehot = trainset.y_train_onehot print(len(y_train_onehot)) print('loading X_val...') X_val = trainset.X_val print(len(X_val)) print('loading y_val_onehot...') y_val_onehot = trainset.y_val_onehot print(len(y_val_onehot)) print('loading X_test...') X_test = trainset.X_test print(len(X_test)) print('loading y_test_onehot...') y_test_onehot = trainset.y_test_onehot print(len(y_test_onehot)) print('loading is done.') print('saving x_train...') np.save('../data2/x_train', X_train) print('saving x_val...') np.save('../data2/x_val', X_val) print('saving x_test...') np.save('../data2/x_test', X_test) print('saving y_train...') np.save('../data2/y_train_onehot', y_train_onehot) print('saving y_val...') np.save('../data2/y_val_onehot', y_val_onehot) print('saving y_test...') np.save('../data2/y_test_onehot', y_test_onehot) def do2(): print('saving x_train...') X_train = np.load('../data2/x_train.npy') np.savetxt('../data2/x_train.txt', X_train) print('saving x_val...') X_val = np.load('../data2/x_val.npy') np.savetxt('../data2/x_val.txt', X_val) print('saving x_test...') X_test = np.load('../data2/x_test.npy') np.savetxt('../data2/x_test.txt', X_test) print('saving y_train...') y_train_onehot = np.load('../data2/y_train_onehot.npy') np.savetxt('../data2/y_train_onehot.txt', y_train_onehot) print('saving y_val...') y_val_onehot = np.load('../data2/y_val_onehot.npy') np.savetxt('../data2/y_val_onehot.txt', y_val_onehot) print('saving y_test...') y_test_onehot = np.load('../data2/y_test_onehot.npy') np.savetxt('../data2/y_test_onehot.txt', y_test_onehot) if __name__ == '__main__': do2() DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:55:27 "},"DP/TrafficClassification/2.html":{"url":"DP/TrafficClassification/2.html","title":"Related Papers","keywords":"","body":"Related Papers Author = DanteSU English paper [1] Aceto G, D Ciuonzo, Montieri A, et al. Mobile Encrypted Traffic Classification Using Deep Learning[C]// IEEE/ACM Network Traffic Measurement and Analysis Conference (TMA'18). ACM, 2018. [2] Wei W, Ming Z, Wang J, et al. End-to-end encrypted traffic classification with one-dimensional convolution neural networks[C]// 2017 IEEE International Conference on Intelligence and Security Informatics (ISI). IEEE, 2017. [3] Chen Z, Ke H, Jian L, et al. Seq2Img: A sequence-to-image based approach towards IP traffic classification using convolutional neural networks[C]// 2017 IEEE International Conference on Big Data (Big Data). IEEE, 2017. [4] Rezaei S, Liu X. how to achieve high classification accuracy with just a few labels: a semi-supervised approach using sampled packets *[J]. 2019. [5] Lopez-Martin M, Carro B, Sanchez-Esguevillas A, et al. Network Traffic Classifier With Convolutional and Recurrent Neural Networks for Internet of Things[J]. IEEE Access, 2017, PP(99):1-1. [6] Wei W, Sheng Y, Wang J, et al. HAST-IDS: Learning Hierarchical Spatial- Temporal Features Using Deep Neural Networks to Improve Intrusion Detection[J]. IEEE Access, 2018, 6(99):1792-1806. [7] Hchst J, Baumgrtner L, Hollick M, et al. Unsupervised Traffic Flow Classification Using a Neural Autoencoder[C]// 2017 IEEE 42nd Conference on Local Computer Networks (LCN). IEEE, 2017. [8] LotfollahiMohammad, Siavoshanimahdi J, Zaderamin S H, et al. Deep packet: a novel approach for encrypted traffic classification using deep learning[J]. Soft Computing, 2019. [9] Vu L, Bui C T, Nguyen Q U. A Deep Learning Based Method for Handling Imbalanced Problem in Network Traffic Classification[C]// Eighth International Symposium on Information & Communication Technology. ACM, 2017:333-339. [10] Shen M, Zhang J, Zhu L, et al. Accurate Decentralized Application Identification via Encrypted Traffic Analysis Using Graph Neural Networks[J]. IEEE Transactions on Information Forensics and Security, 2021, PP(99):1-1. [11] Lashkari A H, Draper-Gil G, Mamun M, et al. Characterization of Encrypted and VPN Traffic Using Time-Related Features[C]// The International Conference on Information Systems Security and Privacy (ICISSP). 2016. [12] Shiravi A, Shiravi H, Tavallaee M, et al. Toward developing a systematic approach to generate benchmark datasets for intrusion detection[J]. Computers & Security, 2012, 31(3):357-374. [13] Moustafa N, Slay J. UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)[C]// Military Communications and Information Systems Conference (MilCIS), 2015. IEEE, 2015. [14] Moustafa N, Slay J. The evaluation of Network Anomaly Detection Systems: Statistical analysis of the UNSW-NB15 data set and the comparison with the KDD99 data set[J]. Information Security Journal A Global Perspective, 2016:1-14. [15] Moustafa N, et al. Novel Geometric Area Analysis Technique for Anomaly Detection Using Trapezoidal Area Estimation on Large-Scale Networks[J]. IEEE Transactions on Big Data, 2017. [16] Moustafa N, Creech G, Slay J. Big Data Analytics for Intrusion Detection System: Statistical Decision-Making Using Finite Dirichlet Mixture Models[J]. 2017. [17] Sarhan M, Layeghy S, Moustafa N, et al. NetFlow Datasets for Machine Learning-based Network Intrusion Detection Systems[J]. 2020. [18] Stber T, Frank M, Schmitt J, et al. Who do you sync you are?: smartphone fingerprinting via application behaviour[M]. 2013. [19] Aceto G, Ciuonzo D, Montieri A, et al. Traffic Classification of Mobile Apps through Multi-Classification[C]// IEEE Global Communications Conference (Globecom). IEEE, 2017. [20] Ran D, Dvir A, Pele O, et al. I Know What You Saw Last Minute - Encrypted HTTP Adaptive Video Streaming Title Classification[J]. IEEE Transactions on Information Forensics and Security, 2017, PP(12):3039-3049. [21] Taylor V F, Spolaor R, Conti M, et al. Robust Smartphone App Identification Via Encrypted Network Traffic Analysis[J]. IEEE Transactions on Information Forensics and Security, 2017, 13(1):63-78. [22] J. Zhang, et al. Robust network traffic classification, IEEE/ACM Transactions on Networking (TON), vol. 23, no. 4, 2015, pp. 1257-1270. [23] Woodward M, Finn C. Active One-shot Learning[J]. NIPS (2016) Deep Reinforcement Learning Workshop, 2018. [24] Rezaei S, Liu X. Deep Learning for Encrypted Traffic Classification: An Overview[J]. IEEE Communications Magazine, 2019, 57(5):76-81. Chinese Papers [25] å†·æ¶›.åŸºäºæ·±åº¦å­¦ä¹ çš„åŠ å¯†æµé‡åˆ†ç±»ç ”ç©¶ç»¼è¿°[J].è®¡ç®—æœºä¸ç°ä»£åŒ–,2021(08):112-120. [26] å¼ ç¨£è£,åœä½‘å†›,é™ˆåš,å­™é‡é‘«,ç‹æ¶µ,èƒ¡å…ˆå›.åŸºäºå¤šå±‚åŒå‘ SRU ä¸æ³¨æ„åŠ›æ¨¡å‹çš„åŠ å¯†æµé‡åˆ†ç±»æ–¹æ³• [J/OL]. è®¡ç®—æœºå·¥ç¨‹ :1-15[2022-03- 22].DOI:10.19678/j.issn.1000-3428.0063626. [27] çš‡ç”«é›¨å©·,æä¸½é¢–,ç‹æµ·æ´²,æ²ˆå¯Œå¯,é­åŒæƒ.è‡ªæ³¨æ„åŠ›çš„å¤šç‰¹å¾ç½‘ç»œæµé‡å¼‚å¸¸æ£€æµ‹ä¸åˆ†ç±»[J].åä¸œå¸ˆèŒƒå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ),2021(06):161-173. DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 23:19:17 "},"DP/TrafficClassification/3.html":{"url":"DP/TrafficClassification/3.html","title":"Related Links","keywords":"","body":"Related Links Author = DanteSU Datasets åç§° ç½‘å€ CICDataset http://205.174.165.80/ VPN 2016 - Datasets - Research - Canadian Institute for Cybersecurity - UNB https://www.unb.ca/cic/datasets/vpn.html ç½‘ç»œå®‰å…¨æ•°æ®é›†æ±‡æ€» AI Paddle https://aistudio.baidu.com/aistudio/projectdetail/1236018 ç½‘ç»œå®‰å…¨æ•°æ®é›† https://blog.csdn.net/Jesusons/article/details/117459736 IP Network Traffic Flows Labeled with 75 Apps https://www.kaggle.com/datasets/jsrojas/ip-network-traffic-flows-labeled-with-87-apps/code ISCXTor2016 https://blog.csdn.net/wisemanchen/article/details/111877592 Code åç§° ç½‘å€ Deep Packet https://blog.munhou.com/2020/04/05/Pytorch-Implementation-of-Deep-Packet-A-Novel-Approach-For-Encrypted-Tra%EF%AC%83c-Classi%EF%AC%81cation-Using-Deep-Learning/https://github.com/KimythAnly/deeppacket PaperWithCode https://paperswithcode.com/paper/deep-packet-a-novel-approach-for-encryptedhttps://paperswithcode.com/paper/deep-learning-for-network-traffic GHM loss https://github.com/shuxinyin/NLP-Loss-Pytorch/blob/master/unbalanced_loss/GHM_loss.py LSTNet https://github.com/laiguokun/LSTNet Blogs åç§° ç½‘å€ çŸ¥ä¹æµé‡åˆ†ç±»æ€»ç»“ https://www.zhihu.com/people/yi-tun-4/posts ç½‘ç»œåŠ å¯†æµé‡å®éªŒâ€“åŸºäºåŸå§‹æµé‡ https://mathpretty.com/11408.html åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œç½‘ç»œæµé‡è¯†åˆ« https://www.cnblogs.com/bonelee/p/10303108.html Encrypted traffic åŠ å¯†æµé‡åˆ†ç±»ä»»åŠ¡è¿›å±•ç»¼è¿° https://blog.csdn.net/weixin_41763134/article/details/104219211 æµé‡åˆ†ç±»æ–¹æ³•è®¾è®¡ï¼ˆä¸€ï¼‰â€”â€”å‚è€ƒè®ºæ–‡æ•´ç† https://blog.csdn.net/pnnngchg/article/details/79826949 NLPå¤§èµ›å† å†›æ€»ç»“ï¼š300ä¸‡çŸ¥ä¹å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»ä»»åŠ¡(é™„æ·±åº¦å­¦ä¹ æºç ) http://www.360doc.com/content/17/1124/18/40903010_706805642.shtml æ–‡æœ¬åˆ†ç±»æ¦‚è¿°ï¼ˆnlpï¼‰ https://blog.csdn.net/u014248127/article/details/80774668 å°†åˆ†ç±»ç½‘ç»œæµé‡ç‰¹å¾è½¬æ¢ä¸ºæ•°å€¼-ISCX VPN2016æ•°æ®é›† https://www.pythonheidong.com/blog/article/786185/bb4b0cfd6260ffd780da/ å…³äºæ·±åº¦å­¦ä¹ çš„ç½‘ç»œæµé‡åˆ†ç±»è®ºæ–‡æ•´ç†ï¼ˆäºŒï¼‰ https://blog.csdn.net/caiguanhong/article/details/110292236?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_antiscanv2&spm=1001.2101.3001.4242.1&utm_relevant_index=3 è¯»æ–‡çŒ®â€”æœºå™¨å­¦ä¹ åº”ç”¨åˆ°ç½‘ç»œæµé‡åˆ†ç±»ç»¼è¿° https://blog.csdn.net/weixin_43129841/article/details/121195735 5åˆ†é’Ÿç†è§£Focal Lossä¸GHMâ€”â€”è§£å†³æ ·æœ¬ä¸å¹³è¡¡åˆ©å™¨ https://zhuanlan.zhihu.com/p/80594704 PyTorchç»ƒä¹ ï¼ˆäºŒï¼‰ é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œ(LSTM) https://zhuanlan.zhihu.com/p/259650072 PyTorchçš„nn.LSTMä½¿ç”¨è¯´æ˜ https://blog.csdn.net/github_31101389/article/details/107093867 LSTNETâ€”â€”deep time series modelsçš„é›†å¤§æˆè€… https://zhuanlan.zhihu.com/p/467944750 Papers åç§° ç½‘å€ ã€2022å¹´é€šä¿¡ä¸šç»æµè¿è¡Œæƒ…å†µä¹‹äº” ç§»åŠ¨äº’è”ç½‘æµé‡å¿«é€Ÿå¢é•¿ã€‘-å›½å®¶å‘å±•å’Œæ”¹é©å§”å‘˜ä¼š https://www.ndrc.gov.cn/fzggw/jgsj/gjss/sjdt/202201/t20220106_1311526.html?code=&state=123 2021å¹´1~10æœˆé€šä¿¡ä¸šç»æµè¿è¡Œæƒ…å†µ-ã€ç»´æ™®æœŸåˆŠå®˜ç½‘ã€‘ http://qikan.cqvip.com/Qikan/Article/Detail?id=7106372868 åŸºäºæ·±åº¦å­¦ä¹ çš„åŠ å¯†æµé‡åˆ†ç±»ç ”ç©¶ç»¼è¿° - ä¸­å›½çŸ¥ç½‘ https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=JYXH202108020&uniplatform=NZKPT&v=y1kdKYHGttl6RkCkLqM_NjfJtCVzGpWODHSDCv9D9FHGSUFJwmwqDICJsZd9fuy6 PERT: Payload Encoding Representation from Transformer for Encrypted Traffic Classification https://www.zte.com.cn/global/about/magazine/zte-communications/2021/en202104/ResearchPaper/en202104010.html åŸºäºæ·±åº¦å­¦ä¹ çš„ç½‘ç»œæµé‡åˆ†ç±»ç ”ç©¶ https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFDTEMP&filename=1021855723.nh&uniplatform=NZKPT&v=lwfkkv6d_nbjJlZYLvJw5tP_hFtb78227vxGXK0n9ZrwRazEzVZB9iMF3DS5d9gY è‡ªæ³¨æ„åŠ›çš„å¤šç‰¹å¾ç½‘ç»œæµé‡å¼‚å¸¸æ£€æµ‹ä¸åˆ†ç±» https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=HDSZ202106016&uniplatform=NZKPT&v=1Q8AQAHIjB5I8oC008gC2wG1t1mWGdGgzg9-SoCkWcCKgGscaT-QNwQOpqalq1Pn åŸºäºå¤šå±‚åŒå‘SRUä¸æ³¨æ„åŠ›æ¨¡å‹çš„åŠ å¯†æµé‡åˆ†ç±»æ–¹æ³• https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CAPJ&dbname=CAPJLAST&filename=JSJC2022022300H&uniplatform=NZKPT&v=SoV27XeYZugzFYILQLTmSO6NQ7tOhAKLtBGby3YnA-_ILYTRi_fRfPl3bBF1_hd0 åŸºäºæ·±åº¦å­¦ä¹ çš„ç½‘ç»œæµé‡åˆ†ç±»ç³»ç»Ÿçš„ç ”ç©¶ä¸å®ç° https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFD202201&filename=1021124063.nh&uniplatform=NZKPT&v=frLKwSePYe7UTBLgp3W8R0ejb6prUQlENBCZIUoSshwMuQRkK12hXBAubQicvtl6 åŸºäºå·ç§¯æ³¨æ„åŠ›é—¨æ§å¾ªç¯ç½‘ç»œçš„åŠ å¯†æµé‡åˆ†ç±»æ–¹æ³• https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=XXCN202107007&uniplatform=NZKPT&v=FpR6QUdRBpzh4clnsUrl5XrgmPKh6IWyeBxvrzHadyvY9U4auRUWpfB-Dn7rWkOE VPN Network Traffic Classification Using Entropy Estimation and Time-Related Features https://link.springer.com/chapter/10.1007/978-981-16-3945-6_50 Others http://mawi.wide.ad.jp/mawi/ DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:34:11 "},"DP/StyleTransfer/":{"url":"DP/StyleTransfer/","title":"å§¿æ€è¿ç§»","keywords":"","body":"å§¿æ€è¿ç§» Basic Information Lead-in DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:59:30 "},"DP/StyleTransfer/1.html":{"url":"DP/StyleTransfer/1.html","title":"Info","keywords":"","body":"Info DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:34:47 "},"DP/CRS/":{"url":"DP/CRS/","title":"å¯¹è¯æ¨è","keywords":"","body":"å¯¹è¯å¼æ¨èç³»ç»Ÿ Basic Information Lead-in DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:59:03 "},"DP/CRS/1.html":{"url":"DP/CRS/1.html","title":"Info","keywords":"","body":"Info Related Papers åç§° ç½‘å€ Review-augmented Conversational Recommendation https://arxiv.org/pdf/2106.00957.pdf Towards Emotional Support Dialog Systems https://arxiv.org/abs/2106.01144 Why You Should Listen to This Song: Reason Generation for Explainable Recommendation https://ieeexplore.ieee.org/document/8637420 INSPIRED:Towards Sociable Recommendation Dialog System https://arxiv.org/abs/2009.14306 CRSLab: An Open-Source Toolkit for Building Conversational Recommender System https://arxiv.org/abs/2101.00939 DEUX: An Attribute-Guided Framework for Sociable Recommendation Dialog Systems https://arxiv.org/abs/2105.00825 A Model of Social Explanations for a Conversational Movie Recommendation System http://eprints.gla.ac.uk/193937/ Related Links åç§° ç½‘å€ CRSLabï¼šå¯èƒ½æ˜¯æœ€é€‚åˆä½ çš„å¯¹è¯æ¨èç³»ç»Ÿå¼€æºåº“ https://blog.csdn.net/WYDQXCG/article/details/112361106 è½¬è½½ å¯¹è¯æ¨èç³»ç»Ÿç»¼è¿°è®ºæ–‡ï¼ŒA Survey on CRS https://zhuanlan.zhihu.com/p/127030405 Towards Explainable Conversational Recommendation https://www.aminer.cn/pub/5ef96b048806af6ef277218c/towards-explainable-conversational-recommendationhttps://www.bilibili.com/video/av969740822/ å¯¹è¯æ¨èç³»ç»Ÿç›¸å…³è®ºæ–‡åˆ†ç±»æ•´ç† https://zhuanlan.zhihu.com/p/383494625 A Survey on Conversational Recommender Systems https://blog.csdn.net/qq_39609267/article/details/108707734https://blog.csdn.net/weixin_43993244/article/details/106845080 å¯¹è¯æ¨èç³»ç»Ÿ_RSPapers + æ–°å¢å¯¹è¯æ¨èç³»ç»Ÿè®ºæ–‡åˆé›† https://blog.csdn.net/weixin_39643865/article/details/111331361 æ¨èç®—æ³•æœ€å‰æ²¿+CIKM2020æ¨èç³»ç»Ÿè®ºæ–‡ä¸€è§ˆ https://blog.csdn.net/abcdefg90876/article/details/109040152 äº¬ä¸œ å¯¹è¯æ¨èç³»ç»Ÿè°ƒç ” https://blog.csdn.net/weixin_45519842/article/details/119770014 CRS Tutorial at IJCAI2021 https://web-ainf.aau.at/pub/jannach/slides/Tutorial-Conversational-Recommender-Systems-IJCAI-2021.pdf DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 00:53:40 "},"DP/CG/":{"url":"DP/CG/","title":"è®¡ç®—æœºå›¾å½¢å­¦","keywords":"","body":"è®¡ç®—æœºå›¾å½¢å­¦ Basic Information Notes Lead-in ç›¸æœºæˆåƒå‡ ä½•ï¼ŒæŠ•å½±å‡ ä½• è®¡ç®—æœºå›¾å½¢å­¦ Math for Computer Graphics Greg Turk, August 2019 Twenty-two years ago, I wrote an essay about what math is important for computer graphics. That document is now fairly dated, and I have decided that it is time to re-visit this question. I am writing this essay in part for college students who want to know what courses may be relevant to the study of computer graphics. For this reason, I will remark on the departments that are likely to offer courses in a given topic. Hopefully it is obvious that you do not need to be a college student to read this essay! Computer graphics draws upon many different areas of mathematics for tools that help accomplish various computational tasks. For as long as you want to pursue computer graphics, you should also plan to continue to learn more mathematical techniques. There are very few corners of computer graphics that do not make use of some form of mathematics. The most important point that I want to convey in this essay is the following. The mathematical topics that are often the most useful to graphics are so-called Numerical Methods. These are the tools that take abstract mathematical concepts (differentiation, integration, matrix inversion, etc.) and turn them into concrete algorithms that we can use to find numerical results to the problem at hand. When you first learn in calculus class how to differentiate and integrate, you start by doing this symbolically. (For example, the derivative of the sine function is cosine.) In graphics, we need to be able to translate the symbolic answer to a given problem into a numerical technique that can be implemented on the computer. For this reason, it is most often the applied mathematics courses (not those in pure mathematics)that are the most relevant to graphics. The numerical methods that are useful for graphics are frequently the same tools that various engineers use. This means that sometimes the most useful courses for graphics may not be in the math department. They may instead be found in other departments such as electrical engineering or mechanical engineering. In this essay I am going to refer the four core areas of computer graphics. These areas are: Modeling - creating 3D shape descriptions of objects Animation - making objects move Image Synthesis, also called Rendering - making pictures from 3D shapes Image and Video Manipulation I am going to visit the mathematics useful to graphics in an order that (approximately) lines up with the order of the four topics listed above. Note that modeling and animation often make use of similar mathematics. The same is true of the other pair â€” image synthesis and image/video manipulation often use similar math tools. Before I visit any of these topics, however, I am going to start with the math needed for a first course in graphics. Mathematical Basics: Linear Algebra and Trigonometry The most important topics for starting out in graphics are Linear Algebra and Trigonometry. We usually describe the location of a 3D graphics object according to its x, y and z coordinates. We can then apply the following operations on a 3D object: translate (move), scale (change size), and rotate. Translation and scale are accomplished using addition and multiplication, respectively. Rotation is done using sine and cosine, hence the need for trigonometry. The x, y and z coordinates of an object can be conveniently represented as a 3D vector, and the translate, scale and rotate operations can be described as multiplication by a matrix (of size 3x3 or 4x4). This is one of the reasons that a background in linear algebra is important for starting in graphics. Several other concepts from linear algebra also are useful, including matrix inversion, dot product, and cross product. Multivariable Calculus Many of the more advanced topics in computer graphics make use of the tools of Multivariable Calculus. These topics are usually saved for a second or third course in calculus. Many of the representations that are used in computer graphics are functions of multiple variables, and thus require tools to reason about derivatives and integrals of such functions. If you want to study computer graphics beyond a first course in the area, I strongly recommend taking the full sequence of calculus classes that your school offers. Differential Geometry Differential Geometry is the measurement of properties of curves and surfaces, and these techniques are very important for modeling in graphics. Common graphics-related tasks that fall under this domain include determining tangents, measuring curvature, evaluating lengths and areas, and finding shortest paths. Often differential geometry techniques are combined with optimization methods (more on this below). Fortunately, many math departments offer an undergraduate course in differential geometry. Computational Geometry Computational Geometry is the study of algorithms that efficiently and robustly solve geometric problems. Some common problems in this area include find convex hulls, finding nearest neighbors to a given query point, determining the intersection between two surfaces,and triangulating a polygon. The tools of computational geometry are frequently used in both modeling and animation (e.g for collision detection). Strictly speaking, computational geometry is a branch of computer science theory, not mathematics. You are more likely to find a course in computational geometry in a computer science department rather than in a math department. Numerical Linear Algebra The one topic in applied mathematics that is perhaps the most important across a wide array of graphics problems is Numerical Linear Algebra. Usually the study of numerical methods for linear algebra is typically not covered in a first course in linear algebra. The linear algebra problems that arise from computer graphics often require setting up and solving large linear systems of equations, with very large matrices and thousands or tens of thousands of unknowns. The simple methods that you learn for solving matrix equations in a first linear algebra course do not work for such problems. Instead, you need to learn to describe the linear systems in a sparse matrix form (much more memory efficient) and learn about iterative techniques for solving such systems. Some of these methods used include Jacobi, Gauss-Seidel, and the conjugate gradient method. Occasionally you may run into other related numerical problems such as finding eigenvectors and eigenvalues. Optimization Many problems in both modeling and animation describe a given task as an Optimization problem. Say we wish to create a smooth object that passes through a given set of points. First, the object in question is represented numerically, such as a collection of triangles that describes the shape of the surface. Next, we represent a desired quality of the object numerically, such as the smoothness of the surface. The problem is now to find the positions of the trianglesâ€™ vertices that maximizes the smoothness measure, while still passing through the given set of points. Such a minimization problem is described as a large linear system of equations, and iterative numerical techniques are used to solve such a system. Partial Differential Equations Animation of materials such as water, rubber and snow require numerical methods for Partial Differential Equations (PDEâ€™s). The equations that arise from these problems include diffusion equations, transport equations, Laplace equations and Poisson equations. These are often solved by turning the problem into a large linear system of equations, or formulating the problem as one of constrained optimization. You are unlikely to learn much about these techniques in a calculus class. The techniques for solving such problems are more often studied in engineering courses and numerical methods courses. A well-known method for solving some of these problems is know as the Finite Element Method (FEM). Although it is by no means the only method for solving some of these problems, it is one of the more important techniques, and there are often courses devoted to this approach. Not only are these numerical techniques important for computer animation, they also arise frequently in 3D modeling problems. Ordinary Differential Equations The animation of characters (people, animals, robots) is often performed by representing the character as a collection of rigid objects that are connected by joints. For example, a personâ€™s arm can be described as an upper arm segment, a lower arm segment, and an elbow joint that connects these two segments. The motion of a character described in this way is governed by the numerical integration of Ordinary Differential Equations (ODEâ€™s). Alas, a typical course in ODEâ€™s will most likely give you very little in the way of help for this, because such courses are heavy on symbolic solutions instead of numerical solutions. A course on numerical methods is much more likely to discuss the relevant numerical methods (forward Euler, midpoint method, implicit integration, Runge-Kutta, etc.) Signal Processing Many areas in image synthesis and image manipulation touch upon signal processing. Indeed, these techniques are sometimes also relevant to modeling and animation as well. We usually represent an image as 2D grid of pixels, where each pixel is given a color. This regular array of color values can be thought of as a digital representation of a 2D function, and this is a â€œsignalâ€. We can perform operations on our image (the signal) such as contrast modification, blurring, warping, sharpening, and so on. The shape of a surface or the motion of an animated character can also be thought of as a signal, making these techniques relevant to modeling and animation as well. Often the best way to analyze and process signals is to convert them into another representation by using tools such as the Fourier transform. Signal processing is heavily used in the study of electronics and audio, so courses on this topic are often taught in an electrical engineering department. Monte Carlo Integration Methods While the problems in animation usually lead to differential equations, those of image synthesis are usually integral equations. The amount of light that reaches a light-detecting element in a camera or our eye is the sum of all the light coming from all different directions, and that light may have come from several different light sources and bounced off a number of different materials. Such as sum of light paths can be written as an integral equation. While you may learn of basic quadrature methods for calculating integrals in an introductory calculus class, it turns out that such methods do not work well for light transport problems. Instead, random sampling of many different light paths is a much better way to go. These techniques are referred to as Monte Carlo Methods, and these randomization techniques were named for the resort of the same name where gambling casinos are big business. Unfortunately, courses on Monte Carlo techniques are pretty rare. The Rise of Machine Learning If you are studying computer science, you are undoubtably aware that the area of machine learning has recently become huge. (I am writing this in 2019.) In particular, the methods of deep neural networks have seen an explosion of activity. It probably comes as no surprise that deep learning has had a large impact in computer graphics. Neural networks are used for numerous graphics tasks, including: where to shoot rays for better lighting calculations, denoising images, controlling the motion of virtual characters, classifying 3D models, and for image editing. If you want to study graphics, it is important to learn the tools of machine learning, and especially to learn about neural networks. Note that machine learning is closely related the mathematical topics of probability and statistics. Off The Beaten Path Some topics in mathematics are not as commonly used in graphics as those that I have mentioned above. In the old version of this essay, I said that Topology and Abstract Algebrawere not useful for graphics. Now I have to correct myself. Topology As it turns out, one of my own PhD students, Eugene Zhang, did his dissertation work in computer graphics that drew primarily from the area of topology. He studied how to create and edit vector and tensor fields based on the critical points of the fields. Analyzing the connections between these critical points is very much a problem of topology. His work is not the only such case, and there are several other techniques in graphics that draw heavily upon ideas from topology. Abstract Algebra Abstract algebra is the study of objects such as groups, rings and fields. While many of these mathematical constructs are not particularly useful to computer graphics, a researcher named Ken Turkowski pointed out to me that group theory does in fact play an important role in graphics. When we describe the orientation of a 3D object, and when we want to change its orientation, we are using group theory. The space of all 3D orientations is known as the group SO(3), and it turns out this is a fairly counter-intuitive mathematical object. Researchers in graphics have used several different ways of describing elements in this group and operations over these elements, including 3x3 matrices, quaternions, and exponential maps. Describing smooth changes in orientation often leads graphics researchers to study SO(3). Number Theory The topic of number theory is the study of the integers, and researchers in this area investigates questions such as the distribution of prime numbers. Famously, Fermatâ€™s Last Theorem (now solved!) is a problem in number theory. The mathematician G. H. Hardy wrote a book entitled â€œA Mathematicianâ€™s Apologyâ€, in which he describes the beauty of pure mathematics. One of the themes of his book is that his own area of expertise, number theory, is a topic that is to be appreciated in and of itself. He goes on to say that number theory really doesnâ€™t have much in the way of practical applications to real-world problems. So far as I know, number theory is not particularly useful in computer graphics. If you choose to study number theory, you should do it for the beauty of the topic and not for any possible application in graphics. DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 10:21:25 "},"DP/CG/1.html":{"url":"DP/CG/1.html","title":"Info","keywords":"","body":"Info Related Links åç§° ç½‘å€ SIGGRAPH 2021 https://www.neuralrender.com Instant Neural Graphics Primitives https://github.com/NVlabs/instant-ngp ç‰©ç†ä»¿çœŸä¸­çš„ç¬¦å·è·ç¦»åœºï¼ˆSDFï¼‰ https://zhuanlan.zhihu.com/p/390625164 ã€è¯‘ã€‘Signed Distance Fields(æœ‰ç¬¦å·çš„è·ç¦»åœº) https://zhuanlan.zhihu.com/p/357606643 è§†ç½‘è†œRetinaæŠ€æœ¯ https://www.cnblogs.com/constantince/p/15475408.html DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 20:40:19 "},"DP/CG/2.html":{"url":"DP/CG/2.html","title":"Notes","keywords":"","body":"Notes DanteSU Â Â Â Â Â Â Â Â Â Â  updated 2022-06-05 15:22:59 "}}