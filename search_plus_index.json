{"./":{"url":"./","title":"Introduction","keywords":"","body":"写在前面 大家好啊，我是DanteSU，一个梦想是成为计算机科学家的初学者 本网站主要是用来记录我的一些学习经历和试错经验，当然还有一些有用的链接。 emmm 大概就是这样吧，有问题欢迎随时通过 Github 与我联系。 DanteSU            updated 2022-04-06 21:27:29 "},"part1/":{"url":"part1/","title":"服务器使用","keywords":"","body":"服务器使用中一些常见问题与常用操作码 Anaconda Terminal Pytorch Others DanteSU            updated 2022-04-06 21:32:52 "},"part1/1.html":{"url":"part1/1.html","title":"Anaconda","keywords":"","body":"Anaconda Author = DanteSU Conda使用 查看安装的软件包 conda list 查看虚拟环境 conda env list conda info -e 检查更新conda版本 conda update conda 安装与卸载包 conda install package_name=version_in_need conda uninstall package_name 创建与删除虚拟环境 conda create -n env_name (package_name=version_in_need) python=3.7 conda remove -n env_name --all 清理虚拟环境的垃圾 conda clean --all 删除包 conda remove --name env_name package_name 激活与退出虚拟环境 Linux: source activate env_name source deactivate env_name Windows: conda activate conda deactivate env_name pip使用 查看安装包信息（路径、依赖） pip show package_name 一键安装需要的包 requirements.txt 生成 pip freeze >requirements.txt 安装 pip install -r requirements.txt Conda版本 conda install --yes --file requirements.txt environment.yaml activate env_name conda env export > environment.yaml conda env create -f environment.yaml DanteSU            updated 2022-04-06 10:49:10 "},"part1/2.html":{"url":"part1/2.html","title":"Terminal","keywords":"","body":"Terminal Author = DanteSU 查看CUDA版本 $ nvcc -V $ nvcc --version 查看Nvidia显卡状态 $ nvidia-smi 清屏幕 Windows $ cls Linux/Mac $ clear 查看显卡设备和显卡的驱动 $ ubuntu-drivers devices 查看是否安装显卡驱动 $ glxinfo | grep rendering 离线后台程序 $ apt install screen $ screen -S w1 新建一个w1工作窗口 $ screen -ls 查看当前所有的运行窗口 $ screen -d w1 将w1窗口离线 $ screen -r w1 接入窗口w1 $ ctrl+A+D 退出当前窗口，回到主界面 $ screen -X -S w1 quit 删除w1这个窗口 $ screen kill +编号/名称 删除窗口 下载 wget $ wget [option] [url] 基本操作构成 $ wget url 根据文件地址下载 $ wget -O new_name url 使用其它名称保存文件 $ wget -P new_path url 更改文件保存位置 $ wget -c url 中断后的继续下载 $ wget -t 40 url 增加尝试次数（默认20次） $ wget --ftp-user= --ftp-password= url 从FTP加密服务器下载内容 $ wget -U 'xxx' url 模拟浏览器下载 比如 xxx 是 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.43 Safari/537.36 $ wget -b url 后台下载 $ tail -f wget-log 查看后台下载日志 $ vim downloads.txt 下载多个文件 $ wget -i downloads.txt DanteSU            updated 2022-04-06 10:02:22 "},"part1/3.html":{"url":"part1/3.html","title":"Pytorch","keywords":"","body":"Pytorch Author = DanteSU 安装示例 For CUDA 11.3 官方源 conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c conda-forge 清华源 地址 https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ 安装 conda install cudatoolkit=11.3 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64/ conda install pytorch torchvision torchaudio -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ 注意事项 安装pytorch的时候，在检查安装内容那一项，不要着急输入 yes，先检查一下是否是 GPU 版本的pytorch再安装，如果不是，可以等一会再做尝试或者重新进入需要配置的环0:。1“2境 检验安装成功 $ python import torch torch.cuda.is_available() torch.cuda.get_device_name() torch.__version__ torch.cuda.device_count() DanteSU            updated 2022-04-06 15:53:50 "},"part1/4.html":{"url":"part1/4.html","title":"Others","keywords":"","body":"Others Author = DanteSU Colab防断 function ConnectButton(){ console.log(\"Connect pushed\"); document.querySelector(\"#connect\").click() } setInterval(ConnectButton,60000); cv2安装 $ pip install opencv-python Under building... DanteSU            updated 2022-04-06 11:19:40 "},"part2/":{"url":"part2/","title":"Gitbook","keywords":"","body":"Gitbook 安装 基本使用 部署到Github Markdown使用 相关链接 DanteSU            updated 2022-04-06 20:55:50 "},"part2/1.html":{"url":"part2/1.html","title":"安装","keywords":"","body":"安装 Author = DanteSU Nodejs 因为Gitbook依赖Nodejs，所以首先要安装Nodejs，而且因为gitbook后来很久未更新，所以对新版的nodejs兼容性不好，容易出bug，建议最多使用到第10版的nodejs Mac 从 https://nodejs.org/en/ 下载并安装 Nodejs ，安装完后可通过终端命令 node -v 检验是否安装成功。 后面可能报错，所以可以直接通过 brew 命令下载低版本的 nodejs： $ brew install node@10 $ echo 'export PATH=\"/usr/local/opt/node@10/bin:$PATH\"' >> ~/.zshrc $ source ~/.zshrc $ # 查看版本及是否安装成功 $ node -v $ npm -v Linux Under building... Windows Under building... 安装Gitbook $ npm install gitbook-cli -g # 查看版本号 $ gitbook -V DanteSU            updated 2022-04-06 11:30:58 "},"part2/2.html":{"url":"part2/2.html","title":"基本使用","keywords":"","body":"基本使用 Author = DanteSU 创建新的book $ gitbook init 生成与预览 生成 $ gitbook build 若只执行gitbook build，会生成_book目录，但不能预览。 在这个目录中，对于每一个 markdown 文件都生成了一个相应的 html 文件，同时在 _book/gitbook 文件夹中存放了一些主题、字体、样式与图像等文件 预览 $ gitbook serve ./{book_name} 最后一个参数指定输出静态网站内容的目录，可省略，默认会在当前目录下新建一个子目录_book (base) dantesu@DanteSudeMacBook-Pro gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 14 explicitly listed info: loading plugin \"splitter\"... OK info: loading plugin \"expandable-chapters-small\"... OK info: loading plugin \"anchors\"... OK info: loading plugin \"github\"... OK info: loading plugin \"github-buttons\"... OK info: loading plugin \"sharing-plus\"... OK info: loading plugin \"anchor-navigation-ex\"... OK info: loading plugin \"favicon\"... OK info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 10 pages info: found 2 asset files info: >> generation finished with success in 1.1s ! Starting server ... Serving book on http://localhost:4000 样式 $ gitbook install 更新样式中的插件后需要使用此命令来安装新的插件，否则会报错，比如： (base) dantesu@DanteSudeMBP gitbook % gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 25 plugins are installed info: 16 explicitly listed Error: Couldn't locate plugins \"page-footer-ex\", Run 'gitbook install' to install plugins from registry. 样式例子 以下是我暂时在使用的样式 { \"title\": \"DanteSU's House\", \"author\": \"DanteSU\", \"description\": \"All I know is here\", \"language\": \"zh-hans\", \"gitbook\": \"3.2.3\", \"styles\": { \"website\": \"./styles/website.css\" }, \"structure\": { \"readme\": \"README.md\" }, \"links\": { \"sidebar\": { \"但丁世界（在建）\": \"https://dante-su.github.io/\" } }, \"plugins\": [ \"-sharing\", \"splitter\", \"expandable-chapters-small\", \"anchors\", \"github\", \"github-buttons\", \"sharing-plus\", \"anchor-navigation-ex\", \"favicon\" ], \"pluginsConfig\": { \"github\": { \"url\": \"https://github.com/Dante-Su\" }, \"sharing\": { \"douban\": false, \"facebook\": false, \"google\": false, \"hatenaBookmark\": false, \"instapaper\": false, \"line\": false, \"linkedin\": false, \"messenger\": false, \"pocket\": false, \"qq\": false, \"qzone\": false, \"stumbleupon\": false, \"twitter\": false, \"viber\": false, \"vk\": false, \"weibo\": false, \"whatsapp\": false, \"all\": [ \"google\", \"facebook\", \"weibo\", \"twitter\", \"qq\", \"qzone\", \"linkedin\", \"pocket\" ] }, \"anchor-navigation-ex\": { \"showLevel\": false }, \"favicon\":{ \"shortcut\": \"./source/images/favicon.jpg\", \"bookmark\": \"./source/images/favicon.jpg\", \"appleTouch\": \"./source/images/apple-touch-icon.jpg\", \"appleTouchMore\": { \"120x120\": \"./source/images/apple-touch-icon.jpg\", \"180x180\": \"./source/images/apple-touch-icon.jpg\" } } } } 样式网站 https://www.npmjs.com/search?q=gitbook-plugin-theme&ranking=quality DanteSU            updated 2022-04-06 16:55:53 "},"part2/3.html":{"url":"part2/3.html","title":"部署到Github","keywords":"","body":"部署到Github Author = DanteSU 创建新的book DanteSU            updated 2022-04-06 11:10:42 "},"part2/4.html":{"url":"part2/4.html","title":"Markdown使用","keywords":"","body":"Markdown使用 Author = DanteSU 基本用法 链接 页内链接 利用html标签实现 定义一个锚(id)： 跳转到的地方 跳转链接的位置： [点击跳转](#jump) 资源链接 超链接 数学公式 DanteSU            updated 2022-04-06 21:01:22 "},"part2/5.html":{"url":"part2/5.html","title":"相关链接","keywords":"","body":"相关链接 Author = DanteSU Under building... DanteSU            updated 2022-04-06 11:19:34 "},"part3/":{"url":"part3/","title":"图像处理","keywords":"","body":"图像处理 图像缩放 图像修改格式 DanteSU            updated 2022-04-06 10:53:19 "},"part3/1.html":{"url":"part3/1.html","title":"图像缩放","keywords":"","body":"图像缩放 Author = DanteSU import cv2 import os import glob def img_resize(): # iterations path = input(r\"Input the path of image to be processed(eg: D:\\picture\\1.jpg):\") print('Path of image here is : ',path) path_rewrite = input(r\"Input the path of restoring the image(eg: D:\\picture):\") for i in glob.glob(path): print('I here is : ', i) im1 = cv2.imread(i) # print('The original image data are: ', im1) im2 = cv2.resize(im1,(256,256)) # (256,256)是缩放后的像素数 # print('The resized image data are: ', im2) cv2.imwrite(os.path.join(path_rewrite,'resized_' + os.path.basename(i)),im2) if __name__ == '__main__': img_resize() DanteSU            updated 2022-04-06 10:56:21 "},"part3/2.html":{"url":"part3/2.html","title":"图像修改格式","keywords":"","body":"图像修改格式 Author = DanteSU 一般情况 import cv2 import os import glob def change_img_format(): # iterations path = input(r\"Input the path of image to be processed(eg: D:\\picture\\1.jpg):\") print('Path of image here is : ',path) path_rewrite = input(r\"Input the path of restoring the image(eg: D:\\picture):\") img_format = input(r\"Input the format you want(eg: jpg):\") for i in glob.glob(path): print('I here is : ', i) im = cv2.imread(i) new_path = os.path.join(path_rewrite,'new_name'+'.'+img_format) cv2.imwrite(new_path,im) if __name__ == '__main__': change_img_format() 针对 ico （图标）文件 ''' 常用图标大小： [ (256, 256), (128, 128), (64, 64), (48, 48), (32, 32), (24, 24), (16, 16) ] ''' from PIL import Image def make_ico_file(src_image_file, dist_ico_file, size): size = [int(size), int(size)] image = Image.open(src_image_file) image_cropped = image.crop((0, 0, 256, 256)) image_cropped.save(dist_ico_file, sizes=size) if __name__ == '__main__': make_ico_file(input(r\"Input the path of the image(eg: D:\\picture\\1.jpg):\"), input(r'Input the name of icon(eg: favicon):'), input(r'Input the same of icon(eg: 256):')) DanteSU            updated 2022-04-06 21:17:11 "},"part4/":{"url":"part4/","title":"姿态迁移","keywords":"","body":"姿态迁移 第一节 DanteSU            updated 2022-04-06 11:07:42 "},"part5/":{"url":"part5/","title":"流量分类","keywords":"","body":"流量分类 相关论文 开题报告 数据集 Deep-Packet DanteSU            updated 2022-04-06 21:34:26 "},"part5/1.html":{"url":"part5/1.html","title":"相关论文","keywords":"","body":"相关论文 Author = DanteSU Deep packet: a novel approach for encrypted traffic classification using deep learning Deep packet Mobile Encrypted Traffic Classification Using Deep Learning: Experimental Evaluation, Lessons Learned, and Challenges DanteSU            updated 2022-04-06 10:23:08 "},"part5/2.html":{"url":"part5/2.html","title":"开题报告","keywords":"","body":"开题报告 Author = DanteSU ！！！本文禁止在取得作者同意之前以任何形式使用！！！ 一、课题来源、目的、意义 随着我国经济的高速发展，人民生活水平日益提高，对高速上网的需求也持续增加。经历了数次通信技术的更新迭代，时至今日，民用 5G 已经逐步在全国范围内铺设开来。伴随着网络技术的快速发展，同一时间段内产生的互联网流量明显增多。根据工信部发布的《2021 年 1~10 月通信业经济运行情况》显示，虽然互联网接入流量增速稍稍放缓，但在未来较长时期增长量仍将基本稳定，随宏观经济波动，疫情持续存在，月累计流量将持续增长。 流量的持续增加也会带来一些日常生活中出现问题的增加，比如互联网服务提供商 (ISP) 及其设备供应商面对的愈发困难的网络管理问题。网络运营商需要及时了解网络中的内容，以便他们能够快速做出反应以支持其各种业务目标。伴随着流量总量的增长和新类型流量的出现，曾经的网络流量分类算法难掩颓势，我们需要更准确、更快速、更易于实现、对新的流量类型也能做出处理的网络流量分类算法来帮助我们解决网络流量管理中的新的问题。 流量分类问题已经研究了二十年，相关研究结果得到了广泛的应用。目前流量分类技术的目的是要检测流量模式，从而优先客户自动分配网络资源，或识别客户使用网络资源是否在某种程度上违反了运营商的服务条款，当然，还有一些调整网络流量解包与调取的顺序以优化用户体验的作用。最近，政府还明确了互联网服务提供商在“合法拦截”违法 IP 数据流量方面的义务。正如电话公司必须支持拦截电话一样，互联网服务供应商越来越受政府要求提供特定个人在特定时间点的网络使用信息的要求。 目前流量分类有基于端口的数据包检测、对有效载荷的检测、对基于统计学的特征检测等方法。这些方法都已经在过去得到很好的应用，但由于通信技术的发展，互联网流量的巨大变化，特别是加密流量的增加，它们的准确性已经在下降。随着机器学习方法的普及，研究人员最近研究了这些方法用于流量分类任务并达到了很高的精度，实现了很好的效果。相比于传统流量分类技术，基于机器学习或者深度学习的技术具有操作简单，资源消耗少，实时性好等优点，可以广泛运用于互联网服务供应商的流量管理系统等地方。与此同时，近几年深度学习技术的快速发展，使得一些算法在很多任务的精度和速度上都达到了前所未有的水平，这使得在流量管理系统中应用一套端到端的方案成为可能。由此我想在基于深度学习技术的网络流量分类这一方面进行一定的研究，并考虑流量分类在一些特殊状态下如面对很多未曾见过的应用流量情况下的表现。 二、国内外研究现状 2.1 流量分类任务 2.1.1 传统的流量分类技术 基于端口的方法 通过端口号进行流量分类是这项任务最古老和最著名的方法。基于端口的分类器使用数据包的 TCP/UDP 标头中的信息来提取假定与特定应用程序相关联的端口号。提取端口号后，与分配的 IANA TCP/UDP 端口号进行比较，进行流量分类。提取过程简单，端口号不受加密方案的影响。由于提取过程快速，这种方法经常用于防火墙和访问控制列表。众所周知，基于端口的分类是网络流量识别最简单、最快的方法之一。然而，端口混淆、网络地址转换、端口转发、协议嵌入和随机端口分配的普遍性大大降低了这种方法的准确性。根据相关研究，目前只有 30% 到 70% 的互联网流量可以使用基于端口的分类方法进行分类。由于这些原因，需要更复杂的流量分类方法来对现代网络流量进行分类。 有效载荷检测技术 这些技术基于对数据包应用层有效载荷中可用信息的分析。大多数有效负载检测方法，也称为深度数据包检测，使用预定义的模式(如正则表达式)作为每个协议的签名。然后使用派生的模式来区分协议彼此。每当发布新协议时都需要更新模式，并且用户隐私问题是这种方法最重要的缺点之一。虽然有人提出了一种新的深度数据包检测系统，可以在不解密的情况下检查加密的有效负载，从而解决了用户隐私问题，但它只能处理 HTTP 安全流量。 统计和机器学习方法 其中一些方法，主要称为统计方法，有一个有偏见的假设，即每个应用程序的基础流量具有一些几乎独有的统计特征。每种统计方法都使用自己的函数和统计数据。有一种办法是基于数据包到达时间和归一化 阈值的概率密度函数的协议指纹。他们对 HTTP、POP3 和 SMTP 等一组协议的准确率高达 91%。在类似的工作中，还有人考虑了数据包大小的概率密度函数。他们的方案能够识别更广泛的协议，包括文件传输协议 (FTP)、互联网消息访问协议 (IMAP)、SSH 和 TELNET，准确率高达87%。 现如今，已经有了大量机器学习方法来对流量进行分类。比如有贝叶斯神经网络，该网络经过训练可以对包括 Kazaa、BitTorrent、GnuTella 在内的大多数知名 P2P 协议进行分类，并达到 99% 的准确率。使用朴素贝叶斯分类器和核密度估计器可以在同一组应用程序上实现 96% 的准确度。在流量分类问题上，人工神经网络方法可以胜过朴素贝叶斯方法。在“ISCX VPN-nonVPN”流量数据集上发表的两篇最重要的论文都是基于机器学习方法的。还有一些使用与时间相关的特征的研究，例如流的持续时间、每秒流字节数、前向和后向到达间隔时间等，使用 k-最近邻和 C4.5 决策树算法来分类网络流量。最终可以实现了大约 92% 的召回率，使用 C4.5 算法分类了六大类流量，包括网站浏览、电子邮件、聊天、流媒体、文件传输和 IP 语音。还在通过 VPN 隧道传输的同一数据集上使用 C4.5 算法实现了大约 88% 的召回率。还有一些研究手动选择 111 个流动特征并使用 k-最近邻算法在 14 类应用中实现了 94% 的准确率。所有这些方法的主要缺点是特征提取和特征选择阶段基本上是在专家的帮助下完成的。因此，这些方法耗时、昂贵且容易出现人为错误。此外，对于使用 k-最近邻分类器的情况，当用于预测时，该算法的执行时间是一个主要问题。 2.1.1 基于深度学习的流量分类技术 A. 多层感知机 多层感知机(MLP)是第一个神经网络架构，由一个输入层、一个输出层和几个隐藏层神经元组成。每层都有几个神经元，这些神经元与相邻层紧密相连，如图 1 所示。神经元对其输入进行加权求和，并通过非线性激活函数产生输出。从理论上讲，足够密集且足够深的多层感知机可以估计任意函数。然而，由于模型需要学习大量的参数，这个模型通常非常复杂、低效并且难以针对任意复杂问题进行训练。尽管单独使用深度多层感知机已经证明效果很差，但使用几层全连接的神经元的感知机仍然可以作为其他模型中间的组成部分使用。对于网络流量分类，单纯的多层感知机由于其复杂性和准确性低而很少使用。在 [1] 中，将许多深度学习方法与随机森林 (RF) 算法进行了比较，以显示性能差距。他们使用 3 个具有不同标签数量的移动数据集。许多深度学习方法在其中两个数据集中优于随机森林算法。然而，实验设置并不完全公平，因为用于 RF、MLP 和其他深度学习方法的输入特征不同。因此，不应将其结果视为对传统机器学习方法的全面比较。 图 1 多层感知机 B. 卷积神经网络 与多层感知机类似，卷积神经网络 (CNN) 也由几个具有可学习参数的层组成。多层感知机无法很好地处理导致隐藏层中有大量可学习参数的高维数据。卷积神经网络架构，如图 2 所示，通过使用卷积层解决了这个问题。在卷积层中，使用了一组具有少量可学习参数的小内核。同一组内核用于整合输入以产生下一层的输出。通过在层中使用相同的多个内核，可学习参数的数量显着减少。在整个输入上使用这些内核有助于模型更轻松地捕获移位不变特征。 池化层也用于一个或几个卷积层之后进行二次采样。此外，最后的隐藏层通常采用全连接层。[2] 中提出了最简单的卷积神经网络 (CNN) 模型，它基本上用一维向量表示每个流或会话，来输入到卷积神经网络模型。他们的卷积神经网络模型有 2 个卷积层、2 个池化层和 2 个全连接层。它们对每个数据包中的字节进行归一化，并且仅使用前 784 个字节。他们在 12 个类别的加密应用程序数据集上评估他们的模型，并表现出比使用时间序列和统计特征的 C4.5 方法有显着改进。在 [3] 中，作者还使用具有 2 个卷积层、2 个池化层和 3 个全连接层的卷积神经网络来执行协议和应用程序分类任务。他们使用再现内核希尔伯特空间 (RKHS) 嵌入并将早期时间序列数据转换为二维图像。他们的卷积神经网络模型在协议和应用分类任务中优于经典的机器学习方法和多层感知机。 [4] 中使用基于简单一维卷积神经网络的半监督方法对五个谷歌应用程序进行分类。他们训练了一个模型，从具有大量未标记数据集的几个采样数据包中预测整个流的统计特征。然后，他们将权重转移到一个新模型，并重新训练它以执行应用分类任务，只使用几个标记样本。他们展示了使用采样时间序列特征而不是前 n 个数据包的可能性，这对于高带宽操作网络可行性更高 [4]。 图 2 卷积神经网络 C. 循环神经网络 循环神经网络 (RNN) 是包含用于存储时间信息的循环的神经网络，如图3 所示。循环神经网络是专门为顺序数据设计的，其中输出可能不仅取决于最后一个输入，还取决于之前的输入。循环神经网络已成功应用于语音识别、时间序列预测、翻译和语言建模等一系列任务。梯度消失和爆炸使得学习长期的依赖关系变得困难(例如，相距很远的输入之间的依赖)，是传统循环神经网络中的一个常见障碍。长短期记忆 (LSTM) 通过添加一组控制何时存储或删除 信息的门来缓解这些问题。对于网络分类任务，研究发现混合模型优于纯长短期记忆模型或卷积神经网络模型 [5]。卷积神经网络和循环神经网络都在 [6]、[5] 中用于不同的应用来捕捉流的空间和时间特征。除了微小的差异之外，两项研究都将前 6 到 30 个数据包的内容带到卷积神经网络模型、循环神经网络或长短期记忆模型。尽管确切的输入特征、神经网络架构和数据集不同，但它们都达到了很高的精度。尽管它们在序列数据方面取得了成功，但长短期记忆并不适合需要显式和外部存储器的复杂任务。最近引入了新的架构，例如记忆网络和神经图灵机 (NTM)，以将显式记忆嵌入到架构中，称为记忆增强神经网络 (MANN)。记忆增强神经网络已成功应用于语言建模、问答和一次性学习。但尚未研究记忆增强神经网络在网络分类任务上的性能。 图 3 循环神经网络 D. 自编码器 (AE) 相对于上述模型，自编码器 (AE) 具有明显更小的隐藏层的神经网络，目的是在输出端重建输入，如图 4 所示。内部的编码表示可用于数据压缩或降维。多层感知机、卷积神经网络和循环神经网络都可以用作自编码器架构的一部分。自编码器广泛用于初始化深度架构的权重。自编码器有一些变体，例如去噪自编码器 (DAE) 通过输入带噪音的样本来输出完整的输入样本，从而迫使模型学习更稳健的特征，以及用于生成的变分自编码器 (VAE)可以产生模拟目标分布的虚假数据。更复杂的架构，称为堆叠式自动编码器 (SAE)，堆叠了多个自编码器，其中每个自编码器的输出都是下一个自编码器的输入，整个模型以贪婪的逐层方式进行训练。也可以训练一个混合学习框架，它将自编码器与多层感知机或其他模型相结合，从一开始就带有标记数据。因此，该模型同时学习输入和输出分布。这种混合模型使用多目标损失函数进行训练，包括标准输出损失以及重建损失。自编码器通常使用无监督的方式来获得输入数据的表示，这些表示以后可以用作分类器的一部分。例如，在 [7] 中，使用自编码器来重构输入。然后，将 softmax 层应用于自编码器的编码内部表示，最后达到了不错的精度。他们使用自己的私有数据集，包含 7 种流量类型。此外，他们使用 12 个区间和两个流向的 9 个统计特征作为输入。在 [8] 中，作者使用标头和有效负载数据在 ISCX VPN non-VPN 数据集上训练一维卷积神经网络和堆叠式自编码器模型。两种模型都显示出很高的准确性，但卷积神经网络模型的性能略优于堆叠式自编码器模型。 图 4 自编码器 E. 生成对抗网络 生成对抗网络 (GAN) 是一种无监督技术，可同时训练生成模型和判别模型。如图 5 所示，生成器旨在生成目标分布的数据，而判别器模型旨在区分真实数据和生成数据。这两种模型通常都是神经网络。首先训练生成器以通过判别器最大化错误概率。然后，固定生成器并训练鉴别器以最小化错误概率，同时输入真实和生成的数据。继续该过程直到收敛。尽管生成对抗网络难以训练和收敛，但它已被用于许多应用中，例如创建逼真的图像、从图像重建 3D 模型、提高图像质量、为数据稀缺的应用创建合成数据。生成模型可用于处理网络流量分类中的数据集不平衡问题。不平衡问题是指每个类别的样本数量变化很大的情况。在这种情况下，机器学习算法通常难以正确预测数据较少的类别。处理不平衡数据集最常见和最简单的方法是对数据较少的类别进行过采样，复制产生更多的样本，或对数据较多的类别进行欠采样，从其中删除一些样本。在 [9] 中，辅助分类的生成对抗网络(AC- GAN)可以生成用于监督网络分类任务的合成样本。 AC-GAN 和传统生成对抗网络的主要区别在于 AC-GAN 同时将随机噪声和类标签作为输入，从而生成输入类标签的样本。他们使用具有两个类(SSH 和非 SSH)的公共数据集、 22 个统计特征来作为输入。他们仅使用深度模型来生成合成数据。对于分类部分，他们使用经典的机器学习算法，包括支持向量机、随机森林和决策树。 图 5 生成对抗网络 F. 图神经网络 图神经网络(GNN)是一种直接作用于图结构上的神经网络。如图 6 所示，图神经网络的一个典型应用是节点分类，本质上，图中的每个节点都与一个标签相关联，我们希望预测未标记节点的标签。在节点分类问题中，每个节点都可以用其特征表示并且与已标记的标签相关联。给定部分标记的图，目标是利用这些标记的节点来预测未标记的节点标签。它通过学习得到每个节点的高维向量(状态)表示，同时包含其相邻节点的信息。Shen 等人 [10] 提出了一种称为“流量交互图(TIG)”的图结构，基于图神经网络分类器，识别去中心化应用程序(DApp)。该文采用图来表征流量交互特征，将流量按流划分，每条流包含一系列数据包，每个包以五元组(源/目的 IP，源/目的端口，协议)表示。从用户角度看，将上行流数据包长度设为负数，将下行流数据包长度设为正数。 图 6 图神经网络 2.2 基于深度学习的流量分类技术 基于深度学习的流量分类任务是指使用深度学习的经典技术来设计一个端到端的网络流量分类器，虽然没有专家设计的逐个分解步骤，但是在处理速度和准确度上都有更好的表现。之前的流量分类方法有的通过传输采取的端口号来分类，有的根据流量的有效载荷来推断内容，再讲他们分成不同的类，还有一些根据统计学模型来根据概率推断类别的，也是一些传统机器学习方法关注的点。 三、研究目标和方案 3.1 研究目标 针对流量分类的现行方法，阅读论文并加以实现，总结实验方法和实验手法，并在此基础上尝试发现问题提出更好的解决方案。 3.2 研究方案 3.2.1 流程设计 对于网络流量数据包的分类，我们需要训练出一个基于机器学习的模型来处理此问题。因为现阶段，深度学习发展如火如荼，有很多比较新的办法在很多问题上都有很好的效果，所以我们选取深度学习方法来解决此问题。对于深度学习中的模型训练而言，主要有两个最重要的关键，一个是模型的选择，另一个是数据的选取。流程设计如图 7 所示。首先我们将选取的数据集进行预处理来选择合适的特征，之后通过特征降维得到可以用来训练的样本数据，输入进入机器学习模型训练，经过一系列参数调整与训练，我们可以得到最终的一个分类器。将待分类样本输入进入训练完成的分类模型就可以得到分类的结果了。 图 7 流程图 3.2.2 模型选择 主要研究的算法是 RNN 与 Autoregressive Transformer，并在实际场景中加以实验检验。由于 RNN 有很多优化网络结构的变体，通过各种各样的处理减小计算开销，所以可实现性很高。而因为 Transformer 使用了自注意力机制，从而对全局信息的掌握度很好，而且训练可以并行化，效率高。 3.2.3 数据集设计 对于网络流量数据，以相关论文采用的开源数据集(比如 ISCX-VPN2016[11], ISCX2012[12], UNSW-NB15[13][14][15][16][17])为基础，根据直接搜集法与脚本生成法，以及其他类似数据集的收集办法，以多个数据集结合，交叉验证的办法(混合生成法)。 直接搜集法: 借助 Wireshark、Tcpdump、Sniffer 等抓包工具在真实环境中捕捉数据制作数据集。 脚本生成法:模拟攻击流量常利用脚本或虚拟网络产生，如模拟 APT 攻击、 IOT 攻击、内网渗透等攻击流量来组成数据集。 四、课题研究进度安排 表 1 课题研究进度安排表 阶段 任务名称 开始时间 完成时间 1 阅读文献，了解当前技术现状 2020/12/31 2021/03/10 2 学习相关知识 2021/03/10 2021/04/01 3 进行实验 2021/04/01 2021/05/01 4 撰写论文，准备答辩 2021/05/01 2021/05/31 五、主要参考文献 [1] Aceto G, D Ciuonzo, Montieri A, et al. Mobile Encrypted Traffic Classification Using Deep Learning[C]// IEEE/ACM Network Traffic Measurement and Analysis Conference (TMA'18). ACM, 2018. [2] Wei W, Ming Z, Wang J, et al. End-to-end encrypted traffic classification with one-dimensional convolution neural networks[C]// 2017 IEEE International Conference on Intelligence and Security Informatics (ISI). IEEE, 2017. [3] Chen Z, Ke H, Jian L, et al. Seq2Img: A sequence-to-image based approach towards IP traffic classification using convolutional neural networks[C]// 2017 IEEE International Conference on Big Data (Big Data). IEEE, 2017. [4] Rezaei S, Liu X. how to achieve high classification accuracy with just a few labels: a semi-supervised approach using sampled packets *[J]. 2019. [5] Lopez-Martin M, Carro B, Sanchez-Esguevillas A, et al. Network Traffic Classifier With Convolutional and Recurrent Neural Networks for Internet of Things[J]. IEEE Access, 2017, PP(99):1-1. [6] Wei W, Sheng Y, Wang J, et al. HAST-IDS: Learning Hierarchical Spatial- Temporal Features Using Deep Neural Networks to Improve Intrusion Detection[J]. IEEE Access, 2018, 6(99):1792-1806. [7] Hchst J, Baumgrtner L, Hollick M, et al. Unsupervised Traffic Flow Classification Using a Neural Autoencoder[C]// 2017 IEEE 42nd Conference on Local Computer Networks (LCN). IEEE, 2017. [8] LotfollahiMohammad, Siavoshanimahdi J, Zaderamin S H, et al. Deep packet: a novel approach for encrypted traffic classification using deep learning[J]. Soft Computing, 2019. [9] Vu L, Bui C T, Nguyen Q U. A Deep Learning Based Method for Handling Imbalanced Problem in Network Traffic Classification[C]// Eighth International Symposium on Information & Communication Technology. ACM, 2017:333-339. [10] Shen M, Zhang J, Zhu L, et al. Accurate Decentralized Application Identification via Encrypted Traffic Analysis Using Graph Neural Networks[J]. IEEE Transactions on Information Forensics and Security, 2021, PP(99):1-1. [11] Lashkari A H, Draper-Gil G, Mamun M, et al. Characterization of Encrypted and VPN Traffic Using Time-Related Features[C]// The International Conference on Information Systems Security and Privacy (ICISSP). 2016. [12] Shiravi A, Shiravi H, Tavallaee M, et al. Toward developing a systematic approach to generate benchmark datasets for intrusion detection[J]. Computers & Security, 2012, 31(3):357-374. [13] Moustafa N, Slay J. UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)[C]// Military Communications and Information Systems Conference (MilCIS), 2015. IEEE, 2015. [14] Moustafa N, Slay J. The evaluation of Network Anomaly Detection Systems: Statistical analysis of the UNSW-NB15 data set and the comparison with the KDD99 data set[J]. Information Security Journal A Global Perspective, 2016:1-14. [15] Moustafa N, et al. Novel Geometric Area Analysis Technique for Anomaly Detection Using Trapezoidal Area Estimation on Large-Scale Networks[J]. IEEE Transactions on Big Data, 2017. [16] Moustafa N, Creech G, Slay J. Big Data Analytics for Intrusion Detection System: Statistical Decision-Making Using Finite Dirichlet Mixture Models[J]. 2017. [17] Sarhan M, Layeghy S, Moustafa N, et al. NetFlow Datasets for Machine Learning-based Network Intrusion Detection Systems[J]. 2020. [18] Stber T, Frank M, Schmitt J, et al. Who do you sync you are?: smartphone fingerprinting via application behaviour[M]. 2013. [19] Aceto G, Ciuonzo D, Montieri A, et al. Traffic Classification of Mobile Apps through Multi-Classification[C]// IEEE Global Communications Conference (Globecom). IEEE, 2017. [20] Ran D, Dvir A, Pele O, et al. I Know What You Saw Last Minute - Encrypted HTTP Adaptive Video Streaming Title Classification[J]. IEEE Transactions on Information Forensics and Security, 2017, PP(12):3039-3049. [21] Taylor V F, Spolaor R, Conti M, et al. Robust Smartphone App Identification Via Encrypted Network Traffic Analysis[J]. IEEE Transactions on Information Forensics and Security, 2017, 13(1):63-78. [22] J. Zhang, et al. Robust network traffic classification, IEEE/ACM Transactions on Networking (TON), vol. 23, no. 4, 2015, pp. 1257-1270. [23] Woodward M, Finn C. Active One-shot Learning[J]. NIPS (2016) Deep Reinforcement Learning Workshop, 2018. [24] Rezaei S, Liu X. Deep Learning for Encrypted Traffic Classification: An Overview[J]. IEEE Communications Magazine, 2019, 57(5):76-81. [25] 冷涛.基于深度学习的加密流量分类研究综述[J].计算机与现代化,2021(08):112-120. [26] 张稣荣,卜佑军,陈博,孙重鑫,王涵,胡先君.基于多层双向 SRU 与注意力模型的加密流量分类方法 [J/OL]. 计算机工程 :1-15[2022-03- 22].DOI:10.19678/j.issn.1000-3428.0063626. [27] 皇甫雨婷,李丽颖,王海洲,沈富可,魏同权.自注意力的多特征网络流量异常检测与分类[J].华东师范大学学报(自然科学版),2021(06):161-173. DanteSU            updated 2022-04-06 21:32:27 "},"part5/3.html":{"url":"part5/3.html","title":"数据集","keywords":"","body":"数据集 Author = DanteSU DanteSU            updated 2022-04-06 10:12:54 "},"part5/4.html":{"url":"part5/4.html","title":"Deep-Packet","keywords":"","body":"Deep-Packet Blog Link https://blog.munhou.com/2020/04/05/Pytorch-Implementation-of-Deep-Packet-A-Novel-Approach-For-Encrypted-Tra%EF%AC%83c-Classi%EF%AC%81cation-Using-Deep-Learning/ Structure .github FUNDING.yml ml init.py dataset.py metrics.py model.py utils.py .gitignore create_train_test_set.py env_linux_cpu.yaml preprocessing.py README.md train_cnn.py utils.py files FUNDING.yml # These are supported funding model platforms github: # Replace with up to 4 GitHub Sponsors-enabled usernames e.g., [user1, user2] patreon: # Replace with a single Patreon username open_collective: # Replace with a single Open Collective username ko_fi: # Replace with a single Ko-fi username tidelift: # Replace with a single Tidelift platform-name/package-name e.g., npm/babel community_bridge: # Replace with a single Community Bridge project-name e.g., cloud-foundry liberapay: # Replace with a single Liberapay username issuehunt: # Replace with a single IssueHunt username otechie: # Replace with a single Otechie username custom: ['paypal.me/munhou'] init.py dataset.py import torch def dataset_collate_function(batch): feature = torch.stack([torch.tensor([data['feature']]) for data in batch]) label = torch.tensor([data['label'] for data in batch]) transformed_batch = { 'feature': feature, 'label': label } return transformed_batch metrics.py import multiprocessing from pathlib import Path import datasets import numpy as np import torch import pandas as pd from torch.nn import functional as F from torch.utils.data import DataLoader from ml.dataset import dataset_collate_function def confusion_matrix(data_path, model, num_class): data_path = Path(data_path) model.eval() cm = np.zeros((num_class, num_class), dtype=np.float) dataset_dict = datasets.load_dataset(str(data_path.absolute())) dataset = dataset_dict[list(dataset_dict.keys())[0]] try: num_workers = multiprocessing.cpu_count() except: num_workers = 1 dataloader = DataLoader(dataset, batch_size=4096, num_workers=num_workers, collate_fn=dataset_collate_function) for batch in dataloader: x = batch['feature'].float().to(model.device) y = batch['label'].long() y_hat = torch.argmax(F.log_softmax(model(x), dim=1), dim=1) for i in range(len(y)): cm[y[i], y_hat[i]] += 1 return cm def get_precision(cm, i): tp = cm[i, i] tp_fp = cm[:, i].sum() return tp / tp_fp def get_recall(cm, i): tp = cm[i, i] p = cm[i, :].sum() return tp / p def get_classification_report(cm, labels=None): rows = [] for i in range(cm.shape[0]): precision = get_precision(cm, i) recall = get_recall(cm, i) if labels: label = labels[i] else: label = i row = { 'label': label, 'precision': precision, 'recall': recall } rows.append(row) return pd.DataFrame(rows) model.py import multiprocessing import datasets import torch from pytorch_lightning import LightningModule from torch import nn as nn from torch.nn import functional as F from torch.utils.data import DataLoader from ml.dataset import dataset_collate_function class CNN(LightningModule): def __init__(self, c1_output_dim, c1_kernel_size, c1_stride, c2_output_dim, c2_kernel_size, c2_stride, output_dim, data_path, signal_length): super().__init__() # save parameters to checkpoint self.save_hyperparameters() # two convolution, then one max pool self.conv1 = nn.Sequential( nn.Conv1d( in_channels=1, out_channels=self.hparams.c1_output_dim, kernel_size=self.hparams.c1_kernel_size, stride=self.hparams.c1_stride ), nn.ReLU() ) self.conv2 = nn.Sequential( nn.Conv1d( in_channels=self.hparams.c1_output_dim, out_channels=self.hparams.c2_output_dim, kernel_size=self.hparams.c2_kernel_size, stride=self.hparams.c2_stride ), nn.ReLU() ) self.max_pool = nn.MaxPool1d( kernel_size=2 ) # flatten, calculate the output size of max pool # use a dummy input to calculate dummy_x = torch.rand(1, 1, self.hparams.signal_length, requires_grad=False) dummy_x = self.conv1(dummy_x) dummy_x = self.conv2(dummy_x) dummy_x = self.max_pool(dummy_x) max_pool_out = dummy_x.view(1, -1).shape[1] # followed by 5 dense layers self.fc1 = nn.Sequential( nn.Linear( in_features=max_pool_out, out_features=200 ), nn.Dropout(p=0.05), nn.ReLU() ) self.fc2 = nn.Sequential( nn.Linear( in_features=200, out_features=100 ), nn.Dropout(p=0.05), nn.ReLU() ) self.fc3 = nn.Sequential( nn.Linear( in_features=100, out_features=50 ), nn.Dropout(p=0.05), nn.ReLU() ) # finally, output layer self.out = nn.Linear( in_features=50, out_features=self.hparams.output_dim ) def forward(self, x): # make sure the input is in [batch_size, channel, signal_length] # where channel is 1 # signal_length is 1500 by default batch_size = x.shape[0] # 2 conv 1 max x = self.conv1(x) x = self.conv2(x) x = self.max_pool(x) x = x.reshape(batch_size, -1) # 3 fc x = self.fc1(x) x = self.fc2(x) x = self.fc3(x) # output x = self.out(x) return x def train_dataloader(self): # expect to get train folder dataset_dict = datasets.load_dataset(self.hparams.data_path) dataset = dataset_dict[list(dataset_dict.keys())[0]] try: num_workers = multiprocessing.cpu_count() except: num_workers = 1 dataloader = DataLoader(dataset, batch_size=16, num_workers=num_workers, collate_fn=dataset_collate_function, shuffle=True) return dataloader def configure_optimizers(self): return torch.optim.Adam(self.parameters()) def training_step(self, batch, batch_idx): x = batch['feature'].float() y = batch['label'].long() y_hat = self(x) entropy = F.cross_entropy(y_hat, y) self.log('training_loss', entropy, prog_bar=True, logger=True, on_step=True, on_epoch=True) loss = {'loss': entropy} return loss utils.py from pathlib import Path import numpy as np import torch from pytorch_lightning import Trainer from pytorch_lightning.callbacks import EarlyStopping from pytorch_lightning.loggers import TensorBoardLogger from pytorch_lightning.utilities.seed import seed_everything from ml.model import CNN def train_cnn(c1_kernel_size, c1_output_dim, c1_stride, c2_kernel_size, c2_output_dim, c2_stride, output_dim, data_path, epoch, gpus, model_path, signal_length, logger): # prepare dir for model path if model_path: model_path = Path(model_path) model_path.parent.mkdir(parents=True, exist_ok=True) # seed everything seed_everything(seed=9876, workers=True) model = CNN( c1_kernel_size=c1_kernel_size, c1_output_dim=c1_output_dim, c1_stride=c1_stride, c2_kernel_size=c2_kernel_size, c2_output_dim=c2_output_dim, c2_stride=c2_stride, output_dim=output_dim, data_path=data_path, signal_length=signal_length, ).float() trainer = Trainer(val_check_interval=1.0, max_epochs=epoch, gpus=gpus, logger=logger, callbacks=[EarlyStopping(monitor='training_loss', mode='min', check_on_train_epoch_end=True)]) trainer.fit(model) # save model trainer.save_checkpoint(str(model_path.absolute())) def train_application_classification_cnn_model(data_path, model_path, gpu): logger = TensorBoardLogger('application_classification_cnn_logs', 'application_classification_cnn') train_cnn(c1_kernel_size=4, c1_output_dim=200, c1_stride=3, c2_kernel_size=5, c2_output_dim=200, c2_stride=1, output_dim=17, data_path=data_path, epoch=20, gpus=gpu, model_path=model_path, signal_length=1500, logger=logger) def train_traffic_classification_cnn_model(data_path, model_path, gpu): logger = TensorBoardLogger('traffic_classification_cnn_logs', 'traffic_classification_cnn') train_cnn(c1_kernel_size=5, c1_output_dim=200, c1_stride=3, c2_kernel_size=4, c2_output_dim=200, c2_stride=3, output_dim=12, data_path=data_path, epoch=20, gpus=gpu, model_path=model_path, signal_length=1500, logger=logger) def load_cnn_model(model_path, gpu): if gpu: device = 'cuda' else: device = 'cpu' model = CNN.load_from_checkpoint(str(Path(model_path).absolute()), map_location=torch.device(device)).float().to( device) model.eval() return model def load_application_classification_cnn_model(model_path, gpu=False): return load_cnn_model(model_path=model_path, gpu=gpu) def load_traffic_classification_cnn_model(model_path, gpu=False): return load_cnn_model(model_path=model_path, gpu=gpu) def normalise_cm(cm): with np.errstate(all='ignore'): normalised_cm = cm / cm.sum(axis=1, keepdims=True) normalised_cm = np.nan_to_num(normalised_cm) return normalised_cm .gitignore # Byte-compiled / optimized / DLL files __pycache__/ *.py[cod] *$py.class # C extensions *.so # Distribution / packaging .Python build/ develop-eggs/ dist/ downloads/ eggs/ .eggs/ lib/ lib64/ parts/ sdist/ var/ wheels/ pip-wheel-metadata/ share/python-wheels/ *.egg-info/ .installed.cfg *.egg MANIFEST # PyInstaller # Usually these files are written by a python script from a template # before PyInstaller builds the exe, so as to inject date/other infos into it. *.manifest *.spec # Installer logs pip-log.txt pip-delete-this-directory.txt # Unit test / coverage reports htmlcov/ .tox/ .nox/ .coverage .coverage.* .cache nosetests.xml coverage.xml *.cover *.py,cover .hypothesis/ .pytest_cache/ cover/ # Translations *.mo *.pot # Django stuff: *.log local_settings.py db.sqlite3 db.sqlite3-journal # Flask stuff: instance/ .webassets-cache # Scrapy stuff: .scrapy # Sphinx documentation docs/_build/ # PyBuilder .pybuilder/ target/ # Jupyter Notebook .ipynb_checkpoints # IPython profile_default/ ipython_config.py # pyenv # For a library or package, you might want to ignore these files since the code is # intended to run in multiple environments; otherwise, check them in: # .python-version # pipenv # According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control. # However, in case of collaboration, if having platform-specific dependencies or dependencies # having no cross-platform support, pipenv may install dependencies that don't work, or not # install all needed dependencies. #Pipfile.lock # PEP 582; used by e.g. github.com/David-OConnor/pyflow __pypackages__/ # Celery stuff celerybeat-schedule celerybeat.pid # SageMath parsed files *.sage.py # Environments .env .venv env/ venv/ ENV/ env.bak/ venv.bak/ # Spyder project settings .spyderproject .spyproject # Rope project settings .ropeproject # mkdocs documentation /site # mypy .mypy_cache/ .dmypy.json dmypy.json # Pyre type checker .pyre/ # pytype static type analyzer .pytype/ # Cython debug symbols cython_debug/ # idea .idea/ # unknown .DS_Store # data data/ processed_data/ train_test_data/ # model file model/ # logs lightning_logs/ # transfer file transfer.sh # backup file *.bak create_train_test_set.py import os import sys from pathlib import Path import click import psutil from pyspark.sql import SparkSession, Window from pyspark.sql.functions import col, monotonically_increasing_id, lit, row_number, rand def top_n_per_group(spark_df, groupby, topn): spark_df = spark_df.withColumn('rand', rand(seed=9876)) window = Window.partitionBy(col(groupby)).orderBy(col('rand')) return ( spark_df .select(col('*'), row_number().over(window).alias('row_number')) .where(col('row_number') env_linux_cpu.yaml name: deep_packet channels: - defaults - plotly - pytorch - conda-forge dependencies: - python=3.8 - pip=21.2.4 - jupyterlab=3.2.1 - scikit-learn=1.0.2 - pandas=1.3.5 - dask=2021.10.0 - pyarrow=4.0.1 - seaborn=0.11.2 - matplotlib=3.5.0 - click=8.0.3 - tensorboard=2.6.0 - datasets=1.17.0 - pyspark=3.1.2 - ipywidgets=7.6.5 - pytorch::pytorch=1.10.1 - pytorch::torchvision=0.11.2 - pytorch::torchaudio=0.10.1 - pytorch::cpuonly=2.0 - plotly::plotly=5.5.0 - conda-forge::scapy=2.4.5 - conda-forge::pytorch-lightning=1.5.8 preprocessing.py from pathlib import Path import click import numpy as np import pandas as pd from joblib import Parallel, delayed from scapy.compat import raw from scapy.layers.inet import IP, UDP from scapy.layers.l2 import Ether from scapy.packet import Padding from scipy import sparse from utils import should_omit_packet, read_pcap, PREFIX_TO_APP_ID, PREFIX_TO_TRAFFIC_ID def remove_ether_header(packet): if Ether in packet: return packet[Ether].payload return packet def mask_ip(packet): if IP in packet: packet[IP].src = '0.0.0.0' packet[IP].dst = '0.0.0.0' return packet def pad_udp(packet): if UDP in packet: # get layers after udp layer_after = packet[UDP].payload.copy() # build a padding layer pad = Padding() pad.load = '\\x00' * 12 layer_before = packet.copy() layer_before[UDP].remove_payload() packet = layer_before / pad / layer_after return packet return packet def packet_to_sparse_array(packet, max_length=1500): arr = np.frombuffer(raw(packet), dtype=np.uint8)[0: max_length] / 255 if len(arr) 0 and i % output_batch_size == 0: part_output_path = Path(str(output_path.absolute()) + f'_part_{batch_index:04d}.parquet') df = pd.DataFrame(rows) df.to_parquet(part_output_path) batch_index += 1 rows.clear() # final write if rows: df = pd.DataFrame(rows) part_output_path = Path(str(output_path.absolute()) + f'_part_{batch_index:04d}.parquet') df.to_parquet(part_output_path) # write success file with Path(str(output_path.absolute()) + '_SUCCESS').open('w') as f: f.write('') print(output_path, 'Done') @click.command() @click.option('-s', '--source', help='path to the directory containing raw pcap files', required=True) @click.option('-t', '--target', help='path to the directory for persisting preprocessed files', required=True) @click.option('-n', '--njob', default=-1, help='num of executors', type=int) def main(source, target, njob): data_dir_path = Path(source) target_dir_path = Path(target) target_dir_path.mkdir(parents=True, exist_ok=True) if njob == 1: for pcap_path in sorted(data_dir_path.iterdir()): transform_pcap(pcap_path, target_dir_path / (pcap_path.name + '.transformed')) else: Parallel(n_jobs=njob)( delayed(transform_pcap)(pcap_path, target_dir_path / (pcap_path.name + '.transformed')) for pcap_path in sorted(data_dir_path.iterdir())) if __name__ == '__main__': main() train_cnn.py import click from ml.utils import train_application_classification_cnn_model, train_traffic_classification_cnn_model @click.command() @click.option('-d', '--data_path', help='training data dir path containing parquet files', required=True) @click.option('-m', '--model_path', help='output model path', required=True) @click.option('-t', '--task', help='classification task. Option: \"app\" or \"traffic\"', required=True) @click.option('--gpu', help='whether to use gpu', default=True, type=bool) def main(data_path, model_path, task, gpu): if gpu: gpu = -1 else: gpu = None if task == 'app': train_application_classification_cnn_model(data_path, model_path, gpu) elif task == 'traffic': train_traffic_classification_cnn_model(data_path, model_path, gpu) else: exit('Not Support') if __name__ == '__main__': main() utils.py from pathlib import Path from scapy.layers.dns import DNS from scapy.layers.inet import TCP from scapy.packet import Padding from scapy.utils import PcapReader # for app identification PREFIX_TO_APP_ID = { # AIM chat 'aim_chat_3a': 0, 'aim_chat_3b': 0, 'aimchat1': 0, 'aimchat2': 0, # Email 'email1a': 1, 'email1b': 1, 'email2a': 1, 'email2b': 1, # Facebook 'facebook_audio1a': 2, 'facebook_audio1b': 2, 'facebook_audio2a': 2, 'facebook_audio2b': 2, 'facebook_audio3': 2, 'facebook_audio4': 2, 'facebook_chat_4a': 2, 'facebook_chat_4b': 2, 'facebook_video1a': 2, 'facebook_video1b': 2, 'facebook_video2a': 2, 'facebook_video2b': 2, 'facebookchat1': 2, 'facebookchat2': 2, 'facebookchat3': 2, # FTPS 'ftps_down_1a': 3, 'ftps_down_1b': 3, 'ftps_up_2a': 3, 'ftps_up_2b': 3, # Gmail 'gmailchat1': 4, 'gmailchat2': 4, 'gmailchat3': 4, # Hangouts 'hangout_chat_4b': 5, 'hangouts_audio1a': 5, 'hangouts_audio1b': 5, 'hangouts_audio2a': 5, 'hangouts_audio2b': 5, 'hangouts_audio3': 5, 'hangouts_audio4': 5, 'hangouts_chat_4a': 5, 'hangouts_video1b': 5, 'hangouts_video2a': 5, 'hangouts_video2b': 5, # ICQ 'icq_chat_3a': 6, 'icq_chat_3b': 6, 'icqchat1': 6, 'icqchat2': 6, # Netflix 'netflix1': 7, 'netflix2': 7, 'netflix3': 7, 'netflix4': 7, # SCP 'scp1': 8, 'scpdown1': 8, 'scpdown2': 8, 'scpdown3': 8, 'scpdown4': 8, 'scpdown5': 8, 'scpdown6': 8, 'scpup1': 8, 'scpup2': 8, 'scpup3': 8, 'scpup5': 8, 'scpup6': 8, # SFTP 'sftp1': 9, 'sftp_down_3a': 9, 'sftp_down_3b': 9, 'sftp_up_2a': 9, 'sftp_up_2b': 9, 'sftpdown1': 9, 'sftpdown2': 9, 'sftpup1': 9, # Skype 'skype_audio1a': 10, 'skype_audio1b': 10, 'skype_audio2a': 10, 'skype_audio2b': 10, 'skype_audio3': 10, 'skype_audio4': 10, 'skype_chat1a': 10, 'skype_chat1b': 10, 'skype_file1': 10, 'skype_file2': 10, 'skype_file3': 10, 'skype_file4': 10, 'skype_file5': 10, 'skype_file6': 10, 'skype_file7': 10, 'skype_file8': 10, 'skype_video1a': 10, 'skype_video1b': 10, 'skype_video2a': 10, 'skype_video2b': 10, # Spotify 'spotify1': 11, 'spotify2': 11, 'spotify3': 11, 'spotify4': 11, # Torrent 'torrent01': 12, # Tor 'torfacebook': 13, 'torgoogle': 13, 'tortwitter': 13, 'torvimeo1': 13, 'torvimeo2': 13, 'torvimeo3': 13, 'toryoutube1': 13, 'toryoutube2': 13, 'toryoutube3': 13, # Vimeo 'vimeo1': 14, 'vimeo2': 14, 'vimeo3': 14, 'vimeo4': 14, # Voipbuster 'voipbuster1b': 15, 'voipbuster2b': 15, 'voipbuster3b': 15, 'voipbuster_4a': 15, 'voipbuster_4b': 15, # Youtube 'youtube1': 16, 'youtube2': 16, 'youtube3': 16, 'youtube4': 16, 'youtube5': 16, 'youtube6': 16, 'youtubehtml5_1': 16, } ID_TO_APP = { 0: 'AIM Chat', 1: 'Email', 2: 'Facebook', 3: 'FTPS', 4: 'Gmail', 5: 'Hangouts', 6: 'ICQ', 7: 'Netflix', 8: 'SCP', 9: 'SFTP', 10: 'Skype', 11: 'Spotify', 12: 'Torrent', 13: 'Tor', 14: 'Vimeo', 15: 'Voipbuster', 16: 'Youtube', } # for traffic identification PREFIX_TO_TRAFFIC_ID = { # Chat 'aim_chat_3a': 0, 'aim_chat_3b': 0, 'aimchat1': 0, 'aimchat2': 0, 'facebook_chat_4a': 0, 'facebook_chat_4b': 0, 'facebookchat1': 0, 'facebookchat2': 0, 'facebookchat3': 0, 'hangout_chat_4b': 0, 'hangouts_chat_4a': 0, 'icq_chat_3a': 0, 'icq_chat_3b': 0, 'icqchat1': 0, 'icqchat2': 0, 'skype_chat1a': 0, 'skype_chat1b': 0, # Email 'email1a': 1, 'email1b': 1, 'email2a': 1, 'email2b': 1, # File Transfer 'ftps_down_1a': 2, 'ftps_down_1b': 2, 'ftps_up_2a': 2, 'ftps_up_2b': 2, 'sftp1': 2, 'sftp_down_3a': 2, 'sftp_down_3b': 2, 'sftp_up_2a': 2, 'sftp_up_2b': 2, 'sftpdown1': 2, 'sftpdown2': 2, 'sftpup1': 2, 'skype_file1': 2, 'skype_file2': 2, 'skype_file3': 2, 'skype_file4': 2, 'skype_file5': 2, 'skype_file6': 2, 'skype_file7': 2, 'skype_file8': 2, # Streaming 'vimeo1': 3, 'vimeo2': 3, 'vimeo3': 3, 'vimeo4': 3, 'youtube1': 3, 'youtube2': 3, 'youtube3': 3, 'youtube4': 3, 'youtube5': 3, 'youtube6': 3, 'youtubehtml5_1': 3, # Torrent 'torrent01': 4, # VoIP 'facebook_audio1a': 5, 'facebook_audio1b': 5, 'facebook_audio2a': 5, 'facebook_audio2b': 5, 'facebook_audio3': 5, 'facebook_audio4': 5, 'hangouts_audio1a': 5, 'hangouts_audio1b': 5, 'hangouts_audio2a': 5, 'hangouts_audio2b': 5, 'hangouts_audio3': 5, 'hangouts_audio4': 5, 'skype_audio1a': 5, 'skype_audio1b': 5, 'skype_audio2a': 5, 'skype_audio2b': 5, 'skype_audio3': 5, 'skype_audio4': 5, # VPN: Chat 'vpn_aim_chat1a': 6, 'vpn_aim_chat1b': 6, 'vpn_facebook_chat1a': 6, 'vpn_facebook_chat1b': 6, 'vpn_hangouts_chat1a': 6, 'vpn_hangouts_chat1b': 6, 'vpn_icq_chat1a': 6, 'vpn_icq_chat1b': 6, 'vpn_skype_chat1a': 6, 'vpn_skype_chat1b': 6, # VPN: File Transfer 'vpn_ftps_a': 7, 'vpn_ftps_b': 7, 'vpn_sftp_a': 7, 'vpn_sftp_b': 7, 'vpn_skype_files1a': 7, 'vpn_skype_files1b': 7, # VPN: Email 'vpn_email2a': 8, 'vpn_email2b': 8, # VPN: Streaming 'vpn_vimeo_a': 9, 'vpn_vimeo_b': 9, 'vpn_youtube_a': 9, # VPN: Torrent 'vpn_bittorrent': 10, # VPN VoIP 'vpn_facebook_audio2': 11, 'vpn_hangouts_audio1': 11, 'vpn_hangouts_audio2': 11, 'vpn_skype_audio1': 11, 'vpn_skype_audio2': 11, } ID_TO_TRAFFIC = { 0: 'Chat', 1: 'Email', 2: 'File Transfer', 3: 'Streaming', 4: 'Torrent', 5: 'Voip', 6: 'VPN: Chat', 7: 'VPN: File Transfer', 8: 'VPN: Email', 9: 'VPN: Streaming', 10: 'VPN: Torrent', 11: 'VPN: Voip', } def read_pcap(path: Path): packets = PcapReader(str(path)) return packets def should_omit_packet(packet): # SYN, ACK or FIN flags set to 1 and no payload if TCP in packet and (packet.flags & 0x13): # not payload or contains only padding layers = packet[TCP].payload.layers() if not layers or (Padding in layers and len(layers) == 1): return True # DNS segment if DNS in packet: return True return False DanteSU            updated 2022-04-06 21:34:20 "},"part6/":{"url":"part6/","title":"常用链接","keywords":"","body":"常用链接 常用网站官网 它山之 玉 bug经验集 岗位资源 DanteSU            updated 2022-04-06 20:57:49 "},"part6/1.html":{"url":"part6/1.html","title":"常用网站官网","keywords":"","body":"常用网站官网 DanteSU            updated 2022-04-06 17:56:44 "},"part6/2.html":{"url":"part6/2.html","title":"它山之 玉","keywords":"","body":"它山之 玉 计算机视觉 医学图像处理 1 From 知乎 划重点! ! ! 其实医学领域的顶会和顶刊相对来说好中一点!只要大家多从CVPR/ICCV/ECCV.上看一些相关论文，从里面跟踪一些最新技术(创新点)，再把这些新技术(创新点)应用到医学图像领域的某些任务,打败该任务下现有的SOTA算法并解决相关的问题即可。0K~，恭喜你可以开始写论文了!至于中不中还要看你写的怎么样，毕竟顶会顶刊的投稿质量可不允许错误语法一大堆， 图表不规范，以及文章逻辑不通等! English TOEFL Duolinguo English Test (DET) Supervisors with high quality publications in HK 1 From 知乎 作者：lenn 链接：https://www.zhihu.com/question/332075078/answer/738266074 CUHK: IE/EE: Multimedia Laboratory 全部faculty (http://mmlab.ie.cuhk.edu.hk/) CSE: Prof. Jiaya Jia (http://jiaya.me/) Dr. Qi Dou (http://www.cse.cuhk.edu.hk/~qdou/) HKUST: CSE: Prof. Dit-Yan Yeung (https://sites.google.com/view/dyyeung) Prof. James Kwok (https://www.cse.ust.hk/~jamesk/) Chi Keung Tang (http://www.cs.ust.hk/~cktang/bio-sketch-review.htm) Prof. Long Quan (https://www.cse.ust.hk/~quan/) Prof. Pedro V. Sander (https://www.cse.ust.hk/~psander/) Dr. Qifeng Chen (https://cqf.io/) Dr. Dan Xu (Dan Xu - Homepage) ECE: Dr. Shaojie Shen (https://www.ece.ust.hk/eeshaojie) HKU: CS: Prof. Yizhou Yu (https://i.cs.hku.hk/~yzyu/) Dr. Ping Luo (http://luoping.me/) EE: Dr. Xiaojuan Qi (Xiaojuan Qi) CityU: CS: Prof. Chong-Wah Ngo (http://vireo.cs.cityu.edu.hk/index.html) Dr. Antoni Bert Chan (http://visal.cs.cityu.edu.hk/) Prof. Rynson Lau (http://www.cs.cityu.edu.hk/~rynson/) Dr. Kede Ma (Kede Ma, home page) Dr. Jing Liao (https://liaojing.github.io/html/) SCM: Prof. Hongbo Fu (http://sweb.cityu.edu.hk/hongbofu/) PolyU: COMP: Prof. Lei Zhang (https://www4.comp.polyu.edu.hk/~cslzhang/) Dr. Bo Yang (The Hong Kong Polytechnic University) HKBU: CS: Prof. Yiu Ming Cheung (https://www.comp.hkbu.edu.hk/~ymc/) DanteSU            updated 2022-04-06 21:16:56 "},"part6/3.html":{"url":"part6/3.html","title":"bug经验集","keywords":"","body":"bug经验集 DanteSU            updated 2022-04-06 17:57:11 "},"part6/4.html":{"url":"part6/4.html","title":"岗位资源","keywords":"","body":"岗位资源 NOTICE: 在每一个分隔栏之间，按照时间的顺序，最新的消息都在最上方易于寻找 - Job Intern 青藤云 Release Time: 4/26 2022 青藤云安全-信息安全实习生招聘（6月到岗即可） 【工作地点】 北京市海淀区创业路8号群英科技园 【工作职责】 python与shell恶意脚本检测引擎的开发； 恶意脚本检测引擎的测试； 搜集恶意脚本以及业界的检测方式； 【任职资格】 本科或以上学历； 熟悉python、shell和c语言，使用python或c做过实际项目； 了解编译原理，熟悉脚本语言内部执行过程； 对网络安全知识有一定了解，熟悉常见的脚本利用漏洞； 【工作时长】 9：30—19：00 【福利待遇】 实习补贴180-200/天，有餐补、房补、电脑补贴，可开具实习证明，团队氛围nice 【申请方式】 将简历发送至 hanyl1104@163.com，简历及邮件命名格式为【姓名+学校+专业】 有问题加wx 13641251014 OPPO Release Time: 4/14 2022 OPPO22届春招｜23届暑期实习生火热开启！投递使用内推码优先筛选! 内推码：XYDS42780811 网申网址：https://careers.oppo.com/campus 软件类、硬件类、AI/算法类、产品类、工程技术类、采购类、品牌策划类、销售服务类、综合职能类 总有一款适合你 OPPO工作环境VR上线，欢迎沉浸体验：https://720yun.com/t/38vkz9fwgpl#scene_id=78676648 2022届春招缺口较多岗位(依次排序)：系统工程师，安卓应用工程师，驱动工程师，无线通信协议工程师，Linux系统工程师，多媒体开发工程师，计算机视觉算法开发工程师 实习生岗位缺口： 非技术类缺口较多的岗位：财务管理专员，关务管理专员 技术类缺口较多的岗位：计算机视觉算法，影像算法，linux系统，安卓应用(缺口最大)，多媒体开发，多媒体系统，驱动，系统工程师(缺口次多)，软件测试开发(缺口第三多) 内推码XYDS42780811 OPPO华科官方校招群 913802534 百度 Release Time: 4/13 2022 百度23届实习内推 ，即将截止 🌟 600+OFFER 发放、多种岗位选择，实习转正率超过70% 🌟 内推简历免筛选 ，直达笔试 地点：北京、上海、深圳、大连 网申👉 https://talent.baidu.com/ 内推码👉ISKWSB ㊙️秋招提前批7月开启，内推免笔试， 直通面试～没办法实习的同学，记得收藏内推码，秋招提前批助你更快拿 offer❗ 深信服 Release Time: 4/10 2022 深信服实习生招聘 岗位：开发类、市场类、安全类、算法类、产品规划类等六⼤类岗位 地点：深圳、⻓沙、北京、南京 福利：包住宿、包三餐、包往返车票、月薪4000起，更多福利等你解锁 投递通道： pc端：https://app.mokahr.com/campus_apply/sangfor/6146#/home ⼿机端：关注【深信服招聘】-【校园招聘】-【实习招聘】 信服圈（为了更好的通过面试，建议大家关注信服圈儿进行学习）： 人群： 对简历如何书写、面试如何准备有相关疑惑的 已经明确了自己的求职方向，想要提升能力的 想要和更多志同道合的人一起交流求职想法的 不确定自己未来职业发展方向该如何做抉择的 内容：体系化的市场课程、hr 模拟面试、研发校招真题、学长学姐爆料等 福利：免费的简历模板，专业化的hr辅导，海量的行业知识等 如何关注： 扫码或直接微信公众号搜索【信服圈⼉】进行关注 更多详情：https://mp.weixin.qq.com/s/RIRirwgM72dqCeBgloNlLg 北京泰铼投资 Release Time: 4/2 2022 春季校招/实习 量化研究员/交易员/市场/数据开发...多岗位招募中📮 时间：实习岗位需实习满4个月及以上，校招岗需毕业前实习[太阳] 工作地点：北京西城区西环广场 工作内容: 涉及量化投研、二级市场交易、金融机构对接合作、交易系统开发等多种方向 希望你: 2022届或2023届国内外应届毕业生 有数学、计算机、金融等相关专业背景，专业基础扎实，逻辑清晰，表达清楚 有量化投资或互联网算法/开发相关实习经验的同学优先 薪酬福利： 研究实习生RMB 400~600/天， 研发实习生RMB 300/天，校招薪资单独沟通，wlb拒绝996 表现优秀的实习生将被推荐参与之后的项目，并可获得转正机会 公司正式实习生，可开实习证明 内推码：DS5bJZPu 腾讯 Release Time: 2/18 2022 🔥 腾讯2022实习生招聘即将启动！ 欢迎大家搜索/扫码加入【腾讯华中区23届官方实习交流群】 群内将会提供： 腾讯官方招聘信息 解答关于实习的各种疑问 线上线下活动预告 ✨ 技术类QQ群群号：701302439 ✨ 非技术类QQ群群号：760545855 Research Intern Dr. Yang YOU in NUS Release Time: 4/20 2022 新加坡国立大学(NUS) AI高性能计算实验室实习生招募，导师为尤洋老师，尤老师博士毕业于加州大学伯克利分校，尤老师个人主页：https://www.comp.nus.edu.sg/~youy/，实验室主页：https://ai.comp.nus.edu.sg/ 本次CVPR 2022实验室投稿5篇论文全部被接收： https://www.zhihu.com/question/502566228/answer/2379895566。 尤老师是NUS的校长青年教授，实验室氛围开放，加入的话有发过顶会的学长亲自指导，可供选择的方向包括自监督、数据集治理、自动驾驶、图像检索、度量学习等，实习结束后可以提供在NUS的科研经历证明。在国内的同学可以推荐到阿里、字节、美团、华为等公司纯科研实习，有条件的同学也可以申请经费到新加坡交流。感兴趣的同学可以发邮件到kai.wang@comp.nus.edu.sg VSRP of KAUST Release Time: 长期有效 阿卜杜拉国王科技大学的 VSRP(Visiting Student Research Program) 项目，全球相关研究领域本科生、硕士生、博士生均可申请，每月工资 1000 USD，办公提供 Mac，可以解决出行问题，线下参加需要两针得到认证的疫苗接种证明，在COVID-19席卷全球期间可以申请Remote。 具体项目与监督者详见网址：https://vsrp.kaust.edu.sa PhD Position Dr. Kai ZHAO in UAB Release Time: 4/13 2022 发个招生信息，还请大家多多支持[机智] 阿拉巴马大学伯明翰分校(The University of Alabama at Birmingham) 助理教授赵恺 ( https://cs.ucr.edu/~kzhao016/ ) 招收2022秋季或2023春季入学的计算机博士生3~4名。教授本人本科毕业于北京大学计算机系，博士毕业于加州大学河滨分校计算机科学与工程系。研究方向覆盖高性能计算，并行分布式计算，大数据的管理和分析，高能效深度学习等。赵恺教授在数据库和高性能计算两个领域的顶级会议(ICDE, HPDC, SC, ICS)发表论文十余篇，所参与研发的数据压缩框架SZ获得了2021年的美国R&D100创新奖(2021 R&D 100 Awards)。 学生资助和发展：所有录取学生均提供全额奖学金(包括生活费，学费，和健康保险)并提供实验设备(最新Mac或Linux电脑)。赵恺教授和美国阿贡国家实验室(Argonne National Laboratory)保持着长期合作，学生表现优异可在暑假前往国家实验室跟随各个领域的资深科学家实习。 大学简介：阿拉巴马大学伯明翰分校(简称UAB)，是一所美国著名的公立研究型大学，拥有极高的全球排名(US News 第147，THE 第169)。UAB医学系统是美国最大的医学中心之一，为学生提供无忧的健康保障。UAB计算机科学系研究领域覆盖高性能计算，并行和分布式计算，数据挖掘，医疗数据分析，机器学习，系统和网络安全，区块链，云计算，编程语言等。计算机科学系于2019年搬入全新的办公楼，拥有领先的硬件设施(例如全M1的Mac教室)。UAB城郊(Vestavia Hills等地)距离学校10分钟车程，治安远好于美国绝大多数地区，并拥有完善的商业(Costco, 陈家园 Hometown Supermarket, Trader Joe's等)，十分适合亚裔生活。UAB交通便利，距离伯明翰机场10分钟，距离亚特兰大，纳什维尔，和孟菲斯车程2-3小时，距离墨西哥湾最佳白沙滩 Destin 和大雾山国家公园车程4小时，周末休闲采购娱乐都相对便捷。 学生要求：本科就读任何专业的学生均可申请，不要求有科研经历。要求学生自学能力强，逻辑思维严密，有恒心和毅力，并对攻读博士学位有强烈兴趣。 申请方式：请将简历，TOEFL成绩，课程成绩单，及个人专长等发送到kzhao@uab.edu。 Dr. Peng GAO in Virginia Tech Release Time: 3/7 2022 18届王xx：和高教授做了六个月intern，有了两篇很好的产出，申请季高教授给了我巨大的支持和帮助，和我单独聊了几个小时分享他读博的经验建议。最后因为个人原因选了地理位置在加州的学校，没有继续留组读PhD。非常推荐高教授的团队，教授非常nice和friendly，科研质量很高，工业界学术界connection都非常强。推荐给在找暑研和22Fall/23Spring/23Fall PhD机会的朋友们 https://people.cs.vt.edu/penggao/ DanteSU            updated 2022-04-06 10:33:57 "}}