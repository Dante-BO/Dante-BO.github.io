
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>PyTorch · DanteSU's House</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="DanteSU">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-page-footer-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    

        
    
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../DP/" />
    
    
    <link rel="prev" href="2.html" />
    

    
        <link rel="shortcut icon" href='../source/images/favicon.ico' type="image/x-icon">
    
    
        <link rel="bookmark" href='../source/images/favicon.ico' type="image/x-icon">
    
    
        <link rel="apple-touch-icon" href='../source/images/favicon.ico'>
    
    
        
        <link rel="apple-touch-icon" sizes="120x120" href="../source/images/favicon.ico">
        
        <link rel="apple-touch-icon" sizes="180x180" href="../source/images/favicon.ico">
        
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://dante-su.github.io/" target="_blank" class="custom-link">但丁世界（在建）</a>
        </li>
    
        
        <li>
            <a href="https://github.com/hyffun" target="_blank" class="custom-link">猪猪之家</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    写在前面
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../Links/">
            
                <a href="../Links/">
            
                    
                    常用链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../OpCode/">
            
                <a href="../OpCode/">
            
                    
                    操作码
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../OpCode/1.html">
            
                <a href="../OpCode/1.html">
            
                    
                    Terminal
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../OpCode/2.html">
            
                <a href="../OpCode/2.html">
            
                    
                    Anaconda
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../OpCode/3.html">
            
                <a href="../OpCode/3.html">
            
                    
                    Python Lib
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../OpCode/4.html">
            
                <a href="../OpCode/4.html">
            
                    
                    Gitbook
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../OpCode/5.html">
            
                <a href="../OpCode/5.html">
            
                    
                    Markdown
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../OpCode/6.html">
            
                <a href="../OpCode/6.html">
            
                    
                    Others
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../Mix/">
            
                <a href="../Mix/">
            
                    
                    杂记
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../Mix/1.html">
            
                <a href="../Mix/1.html">
            
                    
                    笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../Mix/2.html">
            
                <a href="../Mix/2.html">
            
                    
                    bug经验集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../Mix/3.html">
            
                <a href="../Mix/3.html">
            
                    
                    bug解决链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../Mix/4.html">
            
                <a href="../Mix/4.html">
            
                    
                    岗位资源
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="./">
            
                <a href="./">
            
                    
                    及时代码
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.5.1" data-path="1.html">
            
                <a href="1.html">
            
                    
                    图像缩放
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.2" data-path="2.html">
            
                <a href="2.html">
            
                    
                    图像修改格式
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.5.3" data-path="3.html">
            
                <a href="3.html">
            
                    
                    PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../DP/">
            
                <a href="../DP/">
            
                    
                    深度学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../DP/TrafficClassification/">
            
                <a href="../DP/TrafficClassification/">
            
                    
                    流量分类
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="../DP/TrafficClassification/1.html">
            
                <a href="../DP/TrafficClassification/1.html">
            
                    
                    Open Source
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="../DP/TrafficClassification/2.html">
            
                <a href="../DP/TrafficClassification/2.html">
            
                    
                    Related Papers
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="../DP/TrafficClassification/3.html">
            
                <a href="../DP/TrafficClassification/3.html">
            
                    
                    Related Links
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../DP/StyleTransfer/">
            
                <a href="../DP/StyleTransfer/">
            
                    
                    姿态迁移
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="../DP/StyleTransfer/1.html">
            
                <a href="../DP/StyleTransfer/1.html">
            
                    
                    Info
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../DP/CRS/">
            
                <a href="../DP/CRS/">
            
                    
                    对话推荐
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" data-path="../DP/CRS/1.html">
            
                <a href="../DP/CRS/1.html">
            
                    
                    Info
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../DP/CG/">
            
                <a href="../DP/CG/">
            
                    
                    计算机图形学
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.4.1" data-path="../DP/CG/1.html">
            
                <a href="../DP/CG/1.html">
            
                    
                    Info
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >PyTorch</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#pytorch"><b></b>PyTorch</a></li><ul><li><span class="title-icon "></span><a href="#&#x6837;&#x4F8B;"><b></b>&#x6837;&#x4F8B;</a></li><ul><li><span class="title-icon "></span><a href="#trainpy"><b></b>train.py</a></li><li><span class="title-icon "></span><a href="#utils"><b></b>utils</a></li></ul></ul></ul></div><a href="#pytorch" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h1 id="pytorch"><a name="pytorch" class="anchor-navigation-ex-anchor" href="#pytorch"><i class="fa fa-link" aria-hidden="true"></i></a><a name="pytorch" class="plugin-anchor" href="#pytorch"><i class="fa fa-link" aria-hidden="true"></i></a>PyTorch</h1>
<p><strong>Author = DanteSU</strong></p>
<h2 id="&#x6837;&#x4F8B;"><a name="&#x6837;&#x4F8B;" class="anchor-navigation-ex-anchor" href="#&#x6837;&#x4F8B;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x6837;&#x4F8B;" class="plugin-anchor" href="#&#x6837;&#x4F8B;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x6837;&#x4F8B;</h2>
<h3 id="trainpy"><a name="trainpy" class="anchor-navigation-ex-anchor" href="#trainpy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="trainpy" class="plugin-anchor" href="#trainpy"><i class="fa fa-link" aria-hidden="true"></i></a>train.py</h3>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> click

<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime

<span class="hljs-keyword">import</span> torch
<span class="hljs-comment"># from torch import nn</span>
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-comment"># from torch.utils.tensorboard import SummaryWriter</span>

<span class="hljs-comment"># from sklearn.metrics import confusion_matrix</span>

<span class="hljs-keyword">from</span> utils.loss <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> utils.model <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> utils.loader <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> utils.others <span class="hljs-keyword">import</span> *


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(gpu_set, epoch, learning_rate, data_path, batch_size, loss,
    weight_decay=<span class="hljs-string">&apos;0.00001&apos;</span>, model_name = <span class="hljs-string">&apos;dp_cnn&apos;</span>, time_now = <span class="hljs-string">&apos;fake time&apos;</span>)</span>:</span>

    <span class="hljs-comment"># Load train and val data</span>
    print(<span class="hljs-string">&apos;Loading data...&apos;</span>)
    trainset, valset = load_train_data(data_path)

    <span class="hljs-comment"># Get and print useful settings</span>
    print(<span class="hljs-string">&apos;Getting settings...&apos;</span>)
    train_data_size,val_data_size,n_classes,input_lenghth = get_setting(trainset, valset)

    <span class="hljs-comment"># Using DataLoader to load data</span>
    print(<span class="hljs-string">&apos;Setting dataloader...&apos;</span>)
    train_dataloader = DataLoader(dataset=trainset,
                           batch_size=batch_size,
                           shuffle=<span class="hljs-keyword">True</span>
                           )
    val_dataloader = DataLoader(dataset=valset,
                           batch_size=batch_size,
                           shuffle=<span class="hljs-keyword">True</span>
                           )

    <span class="hljs-comment"># Set pytorch device</span>
    print(<span class="hljs-string">&apos;Setting device...&apos;</span>)
    device = get_device_name(gpu_set)

    <span class="hljs-comment"># Create the model</span>
    print(<span class="hljs-string">&apos;Creating model network...&apos;</span>)
    model = model_set(model_name,n_classes, batch_size,input_lenghth).to(device)

    <span class="hljs-comment"># Creat loss function</span>
    print(<span class="hljs-string">&apos;Creating loss function...&apos;</span>)
    loss_fn = loss_set(loss,device)

    <span class="hljs-comment"># create optimizer</span>
    print(<span class="hljs-string">&apos;Creating optimizer...&apos;</span>)
    <span class="hljs-comment"># optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)</span>
    optimizer = torch.optim.Adam(model.parameters(),
                lr=learning_rate,
                betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>),
                eps=<span class="hljs-number">1e-08</span>,
                weight_decay=weight_decay,
                amsgrad=<span class="hljs-keyword">False</span>)

    <span class="hljs-comment"># set some sets</span>
    total_train_step = <span class="hljs-number">0</span>                        <span class="hljs-comment"># record training&apos;s number</span>
    <span class="hljs-comment"># total_val_step = 0                         # record validating&apos;s number</span>

    <span class="hljs-comment"># use tensorboard</span>
    <span class="hljs-comment"># writer = SummaryWriter(&quot;logs_train&quot;)</span>

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(epoch):
        epoch_start_time = iters_time = time.time()  <span class="hljs-comment"># timer for entire epoch</span>
        <span class="hljs-comment"># iters_time = time.time()</span>
        print(<span class="hljs-string">&quot;------The {}th epoch starts------&quot;</span>.format(i+<span class="hljs-number">1</span>))

        <span class="hljs-comment"># train starts</span>
        training(train_dataloader,device,model,loss_fn,optimizer,batch_size,total_train_step,iters_time)

        validating(val_dataloader,val_data_size,device,model,loss_fn,time_now)

        save_checkpoints(time_now,model,model_name,i)

        print(<span class="hljs-string">&apos;The time consumption of this code is : {} s&apos;</span>.format(time.time() - epoch_start_time))

    <span class="hljs-comment"># writer.close()</span>


<span class="hljs-meta">@click.command()</span>
<span class="hljs-meta">@click.option(&apos;-g&apos;, &apos;--gpu_set&apos;, type=str, default=&apos;-1&apos;, help=&apos;gpu_set: e.g. 0  0,1,2, 0,2. use -1 for CPU&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-dp&apos;, &apos;--data_path&apos;, type=str, default=&apos;data&apos;, help=&apos;path of input data&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-e&apos;, &apos;--epoch&apos;, type=int, default=10, help=&apos;epoch&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-bs&apos;, &apos;--batch_size&apos;, type=int, default=1, help=&apos;batch size&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-lr&apos;, &apos;--learning_rate&apos;, type=float, default=1e-3, help=&apos;batch size&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-l&apos;, &apos;--loss&apos;, type=str, default=&apos;ce&apos;, help=&apos;loss function&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-wd&apos;, &apos;--weight_decay&apos;, type=float, default=1e-5, help=&apos;weight decay&apos;)</span>
<span class="hljs-meta">@click.option(&apos;-m&apos;, &apos;--model_name&apos;, type=str, default=&apos;lstm&apos;, </span>
    help=<span class="hljs-string">&apos;eg. lstm&apos;</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">(gpu_set, data_path, epoch, batch_size,learning_rate, loss, weight_decay,model_name)</span>:</span>
    total_time = time.time()
    time_now = datetime.now()

    record_parameter(gpu_set, epoch = epoch, learning_rate = learning_rate, data_path=data_path, batch_size = batch_size,
        loss = loss, weight_decay = weight_decay, model_name = model_name, time_now = time_now)

    train(gpu_set, epoch = epoch, learning_rate = learning_rate, data_path=data_path, batch_size = batch_size,
        loss = loss, weight_decay = weight_decay, model_name = model_name, time_now = time_now)
    run_time = time.time() - total_time

    record_run_time(run_time)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    main()
</code></pre>
<h3 id="utils"><a name="utils" class="anchor-navigation-ex-anchor" href="#utils"><i class="fa fa-link" aria-hidden="true"></i></a><a name="utils" class="plugin-anchor" href="#utils"><i class="fa fa-link" aria-hidden="true"></i></a>utils</h3>
<h4 id="loaderpy"><a name="loaderpy" class="anchor-navigation-ex-anchor" href="#loaderpy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="loaderpy" class="plugin-anchor" href="#loaderpy"><i class="fa fa-link" aria-hidden="true"></i></a>loader.py</h4>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> time


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_train_data</span><span class="hljs-params">(data_path)</span>:</span>
    print(<span class="hljs-string">&apos;preparing trainset...&apos;</span>)
    trainset_time = time.time()
    trainset = TrainDataset(data_path=data_path)
    print(<span class="hljs-string">&apos;trainset time consumption is :&apos;</span>, time.time()-trainset_time)
    print(<span class="hljs-string">&apos;preparing valset...&apos;</span>)
    valset_time = time.time()
    valset = ValDataset(data_path=data_path)
    print(<span class="hljs-string">&apos;trainset time consumption is :&apos;</span>, time.time()-valset_time)
    <span class="hljs-keyword">return</span> trainset, valset

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TrainDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
        &#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x3001;&#x521D;&#x59CB;&#x5316;&#x6570;&#x636E;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x5728;&#x8FD9;&#x91CC;&#x5B8C;&#x6210;
    &quot;&quot;&quot;</span> 
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data_path)</span>:</span>
        self.X_train = self.npy_loader(data_path+<span class="hljs-string">&apos;/x_train.npy&apos;</span>)
        self.y_train_onehot = self.npy_loader(data_path+<span class="hljs-string">&apos;/y_train_onehot.npy&apos;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        <span class="hljs-keyword">return</span> self.X_train[index].unsqueeze(<span class="hljs-number">0</span>), self.y_train_onehot[index]  <span class="hljs-comment"># .unsqueeze(0)</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.X_train)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">npy_loader</span><span class="hljs-params">(self,path)</span>:</span>
        <span class="hljs-keyword">return</span> torch.from_numpy(np.load(path))

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ValDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
        &#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x3001;&#x521D;&#x59CB;&#x5316;&#x6570;&#x636E;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x5728;&#x8FD9;&#x91CC;&#x5B8C;&#x6210;
    &quot;&quot;&quot;</span> 
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data_path)</span>:</span>
        self.X_val = self.npy_loader(data_path+<span class="hljs-string">&apos;/x_val.npy&apos;</span>)
        self.y_val_onehot = self.npy_loader(data_path+<span class="hljs-string">&apos;/y_val_onehot.npy&apos;</span>) 

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        <span class="hljs-keyword">return</span> self.X_val[index].unsqueeze(<span class="hljs-number">0</span>), self.y_val_onehot[index]  <span class="hljs-comment"># .unsqueeze(0)</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
       <span class="hljs-keyword">return</span> len(self.X_val)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">npy_loader</span><span class="hljs-params">(self,path)</span>:</span>
        <span class="hljs-keyword">return</span> torch.from_numpy(np.load(path))

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TestDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
        &#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x3001;&#x521D;&#x59CB;&#x5316;&#x6570;&#x636E;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x5728;&#x8FD9;&#x91CC;&#x5B8C;&#x6210;
    &quot;&quot;&quot;</span> 
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data_path)</span>:</span>
        self.X_test = self.npy_loader(data_path+<span class="hljs-string">&apos;/x_test.npy&apos;</span>)
        self.y_test_onehot = self.npy_loader(data_path+<span class="hljs-string">&apos;/y_test_onehot.npy&apos;</span>) 

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        <span class="hljs-keyword">return</span> self.X_test[index].unsqueeze(<span class="hljs-number">0</span>), self.y_test_onehot[index]  <span class="hljs-comment"># .unsqueeze(0)</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
       <span class="hljs-keyword">return</span> len(self.X_test)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">npy_loader</span><span class="hljs-params">(self,path)</span>:</span>
        <span class="hljs-keyword">return</span> torch.from_numpy(np.load(path))
</code></pre>
<h4 id="losspy"><a name="losspy" class="anchor-navigation-ex-anchor" href="#losspy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="losspy" class="plugin-anchor" href="#losspy"><i class="fa fa-link" aria-hidden="true"></i></a>loss.py</h4>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss_set</span><span class="hljs-params">(loss, device)</span>:</span>  
    <span class="hljs-keyword">if</span> loss ==<span class="hljs-string">&apos;ce&apos;</span>:
        <span class="hljs-keyword">return</span> nn.CrossEntropyLoss()
    <span class="hljs-keyword">if</span> loss == <span class="hljs-string">&apos;bce&apos;</span>:
        <span class="hljs-keyword">return</span> nn.BCELoss()    
    <span class="hljs-keyword">if</span> loss ==<span class="hljs-string">&apos;mlsm&apos;</span>:
        <span class="hljs-keyword">return</span> nn.MultiLabelSoftMarginLoss()        
    <span class="hljs-keyword">if</span> loss ==<span class="hljs-string">&apos;mlcce&apos;</span>:
        <span class="hljs-keyword">return</span> multilabel_categorical_crossentropy       
    <span class="hljs-keyword">if</span> loss ==<span class="hljs-string">&apos;fl1&apos;</span>:
        <span class="hljs-keyword">return</span> WeightedFocalLoss()       
    <span class="hljs-keyword">if</span> loss ==<span class="hljs-string">&apos;fl2&apos;</span>:
        <span class="hljs-keyword">return</span> focalBceLoss      
    <span class="hljs-keyword">if</span> loss == <span class="hljs-string">&apos;fl3&apos;</span>:
        <span class="hljs-keyword">return</span> focal_loss()       
    <span class="hljs-keyword">if</span> loss == <span class="hljs-string">&apos;fl4&apos;</span>:
        <span class="hljs-keyword">return</span> FocalLoss()        
    <span class="hljs-keyword">else</span>:
        print(<span class="hljs-string">&apos;loss name error!!!&apos;</span>)
        <span class="hljs-keyword">return</span> sys.exit(<span class="hljs-number">0</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WeightedFocalLoss</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-string">&quot;Non weighted version of Focal Loss&quot;</span>    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, alpha=<span class="hljs-number">.25</span>, gamma=<span class="hljs-number">2</span>, device = <span class="hljs-string">&apos;cuda:2&apos;</span>)</span>:</span>
            super(WeightedFocalLoss, self).__init__()        
            self.alpha = torch.tensor([alpha, <span class="hljs-number">1</span>-alpha]).to(device)        
            self.gamma = gamma

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, inputs, targets)</span>:</span>
            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=<span class="hljs-string">&apos;none&apos;</span>)        
            targets = targets.type(torch.long)        
            at = self.alpha.gather(<span class="hljs-number">0</span>, targets.data.view(<span class="hljs-number">-1</span>))        
            pt = torch.exp(-BCE_loss)        
            F_loss = at*(<span class="hljs-number">1</span>-pt)**self.gamma * BCE_loss        
            <span class="hljs-keyword">return</span> F_loss.mean()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">GHM_Loss</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, bins, alpha)</span>:</span>
        super(GHM_Loss, self).__init__()
        self._bins = bins
        self._alpha = alpha
        self._last_bin_count = <span class="hljs-keyword">None</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_g2bin</span><span class="hljs-params">(self, g)</span>:</span>
        <span class="hljs-keyword">return</span> torch.floor(g * (self._bins - <span class="hljs-number">0.0001</span>)).long()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_custom_loss</span><span class="hljs-params">(self, x, target, weight)</span>:</span>
        <span class="hljs-keyword">raise</span> NotImplementedError

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_custom_loss_grad</span><span class="hljs-params">(self, x, target)</span>:</span>
        <span class="hljs-keyword">raise</span> NotImplementedError

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x, target)</span>:</span>
        g = torch.abs(self._custom_loss_grad(x, target))
        bin_idx = self._g2bin(g)
        bin_count = torch.zeros((self._bins))
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(self._bins):
            bin_count[i] = (bin_idx == i).sum().item()

        N = x.size(<span class="hljs-number">0</span>)

        nonempty_bins = (bin_count &gt; <span class="hljs-number">0</span>).sum().item()
        gd = bin_count * nonempty_bins
        gd = torch.clamp(gd, min=<span class="hljs-number">0.0001</span>)
        beta = N / gd
        <span class="hljs-keyword">return</span> self._custom_loss(x, target, beta[bin_idx])

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">GHMC_Loss</span><span class="hljs-params">(GHM_Loss)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, bins, alpha,device=<span class="hljs-string">&apos;cuda:2&apos;</span>)</span>:</span>
        super(GHMC_Loss, self).__init__(bins, alpha)
        self.device = device

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_custom_loss</span><span class="hljs-params">(self, x, target, weight)</span>:</span>
        <span class="hljs-keyword">return</span> torch.sum((torch.nn.NLLLoss(reduce=<span class="hljs-keyword">False</span>)(torch.log(x),target)).mul(weight.to(self.device).detach()))/torch.sum(weight.to(self.device).detach())

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_custom_loss_grad</span><span class="hljs-params">(self, x, target)</span>:</span>
        x=x.to(self.device).detach()
        target=target.to(self.device)
        <span class="hljs-keyword">return</span> torch.tensor([x[i,target[i]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(target.shape[<span class="hljs-number">0</span>])])-target


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">focal_loss</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, alpha=<span class="hljs-number">0.25</span>, gamma=<span class="hljs-number">2</span>, num_classes = <span class="hljs-string">&apos;11&apos;</span>, size_average=True)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        focal_loss&#x635F;&#x5931;&#x51FD;&#x6570;, -&#x3B1;(1-yi)**&#x3B3; *ce_loss(xi,yi)
        &#x6B65;&#x9AA4;&#x8BE6;&#x7EC6;&#x7684;&#x5B9E;&#x73B0;&#x4E86; focal_loss&#x635F;&#x5931;&#x51FD;&#x6570;.
        :param alpha:   &#x963F;&#x5C14;&#x6CD5;&#x3B1;,&#x7C7B;&#x522B;&#x6743;&#x91CD;.      &#x5F53;&#x3B1;&#x662F;&#x5217;&#x8868;&#x65F6;,&#x4E3A;&#x5404;&#x7C7B;&#x522B;&#x6743;&#x91CD;,&#x5F53;&#x3B1;&#x4E3A;&#x5E38;&#x6570;&#x65F6;,&#x7C7B;&#x522B;&#x6743;&#x91CD;&#x4E3A;[&#x3B1;, 1-&#x3B1;, 1-&#x3B1;, ....],&#x5E38;&#x7528;&#x4E8E; &#x76EE;&#x6807;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x4E2D;&#x6291;&#x5236;&#x80CC;&#x666F;&#x7C7B; , retainnet&#x4E2D;&#x8BBE;&#x7F6E;&#x4E3A;0.25
        :param gamma:   &#x4F3D;&#x9A6C;&#x3B3;,&#x96BE;&#x6613;&#x6837;&#x672C;&#x8C03;&#x8282;&#x53C2;&#x6570;. retainnet&#x4E2D;&#x8BBE;&#x7F6E;&#x4E3A;2
        :param num_classes:     &#x7C7B;&#x522B;&#x6570;&#x91CF;
        :param size_average:    &#x635F;&#x5931;&#x8BA1;&#x7B97;&#x65B9;&#x5F0F;,&#x9ED8;&#x8BA4;&#x53D6;&#x5747;&#x503C;
        &quot;&quot;&quot;</span>
        super(focal_loss,self).__init__()
        self.size_average = size_average
        <span class="hljs-keyword">if</span> isinstance(alpha,list):
            <span class="hljs-keyword">assert</span> len(alpha)==num_classes   <span class="hljs-comment"># &#x3B1;&#x53EF;&#x4EE5;&#x4EE5;list&#x65B9;&#x5F0F;&#x8F93;&#x5165;,size:[num_classes] &#x7528;&#x4E8E;&#x5BF9;&#x4E0D;&#x540C;&#x7C7B;&#x522B;&#x7CBE;&#x7EC6;&#x5730;&#x8D4B;&#x4E88;&#x6743;&#x91CD;</span>
            print(<span class="hljs-string">&quot; --- Focal_loss alpha = {}, &#x5C06;&#x5BF9;&#x6BCF;&#x4E00;&#x7C7B;&#x6743;&#x91CD;&#x8FDB;&#x884C;&#x7CBE;&#x7EC6;&#x5316;&#x8D4B;&#x503C; --- &quot;</span>.format(alpha))
            self.alpha = torch.Tensor(alpha)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">assert</span> alpha&lt;<span class="hljs-number">1</span>   <span class="hljs-comment">#&#x5982;&#x679C;&#x3B1;&#x4E3A;&#x4E00;&#x4E2A;&#x5E38;&#x6570;,&#x5219;&#x964D;&#x4F4E;&#x7B2C;&#x4E00;&#x7C7B;&#x7684;&#x5F71;&#x54CD;,&#x5728;&#x76EE;&#x6807;&#x68C0;&#x6D4B;&#x4E2D;&#x4E3A;&#x7B2C;&#x4E00;&#x7C7B;</span>
            print(<span class="hljs-string">&quot; --- Focal_loss alpha = {} ,&#x5C06;&#x5BF9;&#x80CC;&#x666F;&#x7C7B;&#x8FDB;&#x884C;&#x8870;&#x51CF;,&#x8BF7;&#x5728;&#x76EE;&#x6807;&#x68C0;&#x6D4B;&#x4EFB;&#x52A1;&#x4E2D;&#x4F7F;&#x7528; --- &quot;</span>.format(alpha))
            self.alpha = torch.zeros(num_classes)
            self.alpha[<span class="hljs-number">0</span>] += alpha
            self.alpha[<span class="hljs-number">1</span>:] += (<span class="hljs-number">1</span>-alpha) <span class="hljs-comment"># &#x3B1; &#x6700;&#x7EC8;&#x4E3A; [ &#x3B1;, 1-&#x3B1;, 1-&#x3B1;, 1-&#x3B1;, 1-&#x3B1;, ...] size:[num_classes]</span>

        self.gamma = gamma

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, preds, labels)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        focal_loss&#x635F;&#x5931;&#x8BA1;&#x7B97;
        :param preds:   &#x9884;&#x6D4B;&#x7C7B;&#x522B;. size:[B,N,C] or [B,C]    &#x5206;&#x522B;&#x5BF9;&#x5E94;&#x4E0E;&#x68C0;&#x6D4B;&#x4E0E;&#x5206;&#x7C7B;&#x4EFB;&#x52A1;, B &#x6279;&#x6B21;, N&#x68C0;&#x6D4B;&#x6846;&#x6570;, C&#x7C7B;&#x522B;&#x6570;
        :param labels:  &#x5B9E;&#x9645;&#x7C7B;&#x522B;. size:[B,N] or [B]
        :return:
        &quot;&quot;&quot;</span>
        <span class="hljs-comment"># assert preds.dim()==2 and labels.dim()==1</span>
        preds = preds.view(<span class="hljs-number">-1</span>,preds.size(<span class="hljs-number">-1</span>))
        self.alpha = self.alpha.to(preds.device)
        preds_logsoft = F.log_softmax(preds, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># log_softmax</span>
        preds_softmax = torch.exp(preds_logsoft)    <span class="hljs-comment"># softmax</span>

        label = (labels.view(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)).type(torch.int64)
        preds_softmax = preds_softmax.gather(<span class="hljs-number">1</span>,label)   <span class="hljs-comment"># &#x8FD9;&#x90E8;&#x5206;&#x5B9E;&#x73B0;nll_loss ( crossempty = log_softmax + nll )</span>
        preds_logsoft = preds_logsoft.gather(<span class="hljs-number">1</span>,label)
        self.alpha = self.alpha.gather(<span class="hljs-number">0</span>,label)
        loss = -torch.mul(torch.pow((<span class="hljs-number">1</span>-preds_softmax), self.gamma), preds_logsoft)  <span class="hljs-comment"># torch.pow((1-preds_softmax), self.gamma) &#x4E3A;focal loss&#x4E2D; (1-pt)**&#x3B3;</span>

        loss = torch.mul(self.alpha, loss.t())
        <span class="hljs-keyword">if</span> self.size_average:
            loss = loss.mean()
        <span class="hljs-keyword">else</span>:
            loss = loss.sum()
        <span class="hljs-keyword">return</span> loss


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FocalLoss</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, gamma=<span class="hljs-number">2</span>, alpha=<span class="hljs-number">0.25</span>, size_average=True)</span>:</span>
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha
        <span class="hljs-keyword">if</span> isinstance(alpha,(float,int,torch.long)): self.alpha = torch.Tensor([alpha,<span class="hljs-number">1</span>-alpha])
        <span class="hljs-keyword">if</span> isinstance(alpha,list): self.alpha = torch.Tensor(alpha)
        self.size_average = size_average

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input, target)</span>:</span>
        <span class="hljs-keyword">if</span> input.dim()&gt;<span class="hljs-number">2</span>:
            input = input.view(input.size(<span class="hljs-number">0</span>),input.size(<span class="hljs-number">1</span>),<span class="hljs-number">-1</span>)  <span class="hljs-comment"># N,C,H,W =&gt; N,C,H*W</span>
            input = input.transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)    <span class="hljs-comment"># N,C,H*W =&gt; N,H*W,C</span>
            input = input.contiguous().view(<span class="hljs-number">-1</span>,input.size(<span class="hljs-number">2</span>))   <span class="hljs-comment"># N,H*W,C =&gt; N*H*W,C</span>
        target = target.view(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)

        logpt = F.log_softmax(input)
        logpt = logpt.gather(<span class="hljs-number">1</span>,target)
        logpt = logpt.view(<span class="hljs-number">-1</span>)
        pt = Variable(logpt.data.exp())

        <span class="hljs-keyword">if</span> self.alpha <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            <span class="hljs-keyword">if</span> self.alpha.type()!=input.data.type():
                self.alpha = self.alpha.type_as(input.data)
            at = self.alpha.gather(<span class="hljs-number">0</span>,target.data.view(<span class="hljs-number">-1</span>))
            logpt = logpt * Variable(at)

        loss = <span class="hljs-number">-1</span> * (<span class="hljs-number">1</span>-pt)**self.gamma * logpt
        <span class="hljs-keyword">if</span> self.size_average: <span class="hljs-keyword">return</span> loss.mean()
        <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> loss.sum()


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">focalBceLoss</span><span class="hljs-params">(pred,mask,device=<span class="hljs-string">&apos;cuda:3&apos;</span>)</span>:</span>
    <span class="hljs-comment"># pred[pred&lt;0]=0</span>
    <span class="hljs-comment"># pred[pred&gt;1]=1</span>
    <span class="hljs-comment"># BCE_loss = F.binary_cross_entropy_with_logits(pred, mask)</span>
    BCE_loss = multilabel_categorical_crossentropy(pred, mask)
    alpha = <span class="hljs-number">0.25</span>
    alpha = torch.tensor([alpha, <span class="hljs-number">1</span> - alpha]).to(device)
    gamma = <span class="hljs-number">2</span>
    targets = BCE_loss.type(torch.long)
    at = alpha.gather(<span class="hljs-number">0</span>, targets.data.view(<span class="hljs-number">-1</span>))
    pt = torch.exp(-BCE_loss)
    F_loss = at * (<span class="hljs-number">1</span> - pt) ** gamma * BCE_loss
    smooth = <span class="hljs-number">1e-5</span>
    pred = torch.sigmoid(pred)
    num = mask.size(<span class="hljs-number">0</span>)
    pred = pred.view(num, <span class="hljs-number">-1</span>)

    <span class="hljs-comment">#view()&#x7684;&#x4F5C;&#x7528;&#x76F8;&#x5F53;&#x4E8E;numpy&#x4E2D;&#x7684;reshape&#xFF0C;&#x91CD;&#x65B0;&#x5B9A;&#x4E49;&#x77E9;&#x9635;&#x7684;&#x5F62;&#x72B6;&#x3002;</span>
    <span class="hljs-comment">#print(mask.shape)</span>
    mask = mask.contiguous().view(num, <span class="hljs-number">-1</span>)
    intersection = (pred * mask)

    <span class="hljs-comment"># dice = (2. * intersection.sum(1) + smooth) / (pred.sum(1) + mask.sum(1) + smooth)</span>
    <span class="hljs-comment"># dice = 1 - dice.sum() / num</span>
    <span class="hljs-comment"># print(type(dice))    #&lt;class &apos;torch.Tensor&apos;&gt;</span>
    <span class="hljs-comment"># &#x56E0;&#x4E3A;&#x8FD4;&#x56DE;1&#x7EF4;tensor&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x60F3;&#x8C61;&#x6210;&#x53EA;&#x542B;&#x6709;1&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x5217;&#x8868;&#xFF0C;&#x8981;&#x4F7F;&#x7528;[0]&#x7D22;&#x5F15;&#x624D;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;float&#x6570;</span>
    <span class="hljs-comment"># print(type(dice.item()))</span>
    <span class="hljs-comment"># print(type(F_loss.item()))</span>
    <span class="hljs-comment">#</span>
    <span class="hljs-comment"># print(dice)</span>
    <span class="hljs-comment">#print(type(F_loss.item()))</span>

    <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * F_loss.item() +  BCE_loss


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">multilabel_categorical_crossentropy</span><span class="hljs-params">(y_pred,y_true)</span>:</span>
    y_pred = (<span class="hljs-number">1</span> - <span class="hljs-number">2</span> * y_true) * y_pred
    y_pred_neg = y_pred - y_true * <span class="hljs-number">1e12</span>
    y_pred_pos = y_pred - (<span class="hljs-number">1</span> - y_true) * <span class="hljs-number">1e12</span>
    zeros = torch.zeros_like(y_pred[..., :<span class="hljs-number">1</span>])
    y_pred_neg = torch.cat([y_pred_neg, zeros], dim=<span class="hljs-number">-1</span>)
    y_pred_pos = torch.cat([y_pred_pos, zeros], dim=<span class="hljs-number">-1</span>)
    neg_loss = torch.logsumexp(y_pred_neg, dim=<span class="hljs-number">-1</span>)
    pos_loss = torch.logsumexp(y_pred_pos, dim=<span class="hljs-number">-1</span>)
    <span class="hljs-keyword">return</span> neg_loss + pos_loss
</code></pre>
<h4 id="modelpy"><a name="modelpy" class="anchor-navigation-ex-anchor" href="#modelpy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="modelpy" class="plugin-anchor" href="#modelpy"><i class="fa fa-link" aria-hidden="true"></i></a>model.py</h4>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_set</span><span class="hljs-params">(model_name,n_classes, batch_size,input_lenghth)</span>:</span>
    <span class="hljs-keyword">if</span> model_name == <span class="hljs-string">&apos;resnet&apos;</span>:
        <span class="hljs-keyword">return</span> ResNet18(n_classes)
    <span class="hljs-keyword">if</span> model_name == <span class="hljs-string">&apos;lstm&apos;</span>:
        <span class="hljs-keyword">return</span> LSTM(input_lenghth, n_classes)
    <span class="hljs-keyword">else</span>:
        print(<span class="hljs-string">&apos;model name error!!!&apos;</span>)
        <span class="hljs-keyword">return</span> sys.exit(<span class="hljs-number">0</span>)


<span class="hljs-comment"># model 1</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, ch_in, ch_out)</span>:</span>
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.bn1 = nn.BatchNorm2d(ch_out)
        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.bn2 = nn.BatchNorm2d(ch_out)
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)

        self.extra = nn.Sequential()
        <span class="hljs-comment"># &#x5982;&#x679C;&#x8F93;&#x5165;&#x3001;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;&#x4E0D;&#x540C;&#xFF0C;&#x9700;&#x8F6C;&#x5316;&#x540E;&#x624D;&#x80FD;&#x76F8;&#x52A0;</span>
        <span class="hljs-keyword">if</span> ch_out != ch_in:
            self.extra = nn.Sequential(
                nn.Conv2d(ch_in, ch_out, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>),
                nn.BatchNorm2d(ch_out)
            )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.extra(x) + out
        <span class="hljs-keyword">return</span> out

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet18</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,n_classes)</span>:</span>
        super(ResNet18, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.BatchNorm2d(<span class="hljs-number">64</span>)
        )
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)
        <span class="hljs-comment"># 4 block [b, 64, h, w] =&gt; [b, 1024, h, w]</span>
        self.blk1 = ResNet(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)
        self.blk2 = ResNet(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>)
        self.blk3 = ResNet(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>)
        self.blk4 = ResNet(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>)
        <span class="hljs-comment"># &#x6CE8;&#x610F;&#x6700;&#x540E;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#x7EF4;&#x5EA6;&#xFF0C;&#x8FDB;&#x53BB;&#x4E4B;&#x524D;&#x9700;&#x8981;&#x5148;&#x6253;&#x5E73;</span>
        self.outlayer = nn.Linear(<span class="hljs-number">1024</span>*<span class="hljs-number">30</span>*<span class="hljs-number">50</span>, n_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = x.view(len(x),<span class="hljs-number">30</span>,<span class="hljs-number">-1</span>)
        x = x.unsqueeze(<span class="hljs-number">1</span>)
        x = self.conv1(x)
        x = self.relu(x)

        x = self.blk1(x)
        x = self.blk2(x)
        x = self.blk3(x)
        x = self.blk4(x)
        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)  <span class="hljs-comment"># &#x5148;&#x6253;&#x5E73;&#xFF0C;&#x518D;&#x8FDB;&#x5168;&#x8FDE;&#x63A5;</span>

        x = self.outlayer(x)
        <span class="hljs-keyword">return</span> x

<span class="hljs-comment"># model 2</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LSTM</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,INPUT_SIZE,n_classes)</span>:</span>
        super(LSTM, self).__init__()

        self.rnn = nn.LSTM(         <span class="hljs-comment"># if use nn.RNN(), it hardly learns</span>
            input_size=INPUT_SIZE,
            hidden_size=<span class="hljs-number">64</span>,         <span class="hljs-comment"># rnn hidden unit</span>
            num_layers=<span class="hljs-number">1</span>,           <span class="hljs-comment"># number of rnn layer</span>
            batch_first=<span class="hljs-keyword">True</span>,       <span class="hljs-comment"># input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)</span>
        )

        self.out = nn.Linear(<span class="hljs-number">64</span>, n_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># x shape (batch, time_step, input_size)</span>
        <span class="hljs-comment"># r_out shape (batch, time_step, output_size)</span>
        <span class="hljs-comment"># h_n shape (n_layers, batch, hidden_size)</span>
        <span class="hljs-comment"># h_c shape (n_layers, batch, hidden_size)</span>
        r_out, (h_n, h_c) = self.rnn(x, <span class="hljs-keyword">None</span>)   <span class="hljs-comment"># None represents zero initial hidden state</span>

        <span class="hljs-comment"># choose r_out at the last time step</span>
        out = self.out(r_out[:, <span class="hljs-number">-1</span>, :])
        <span class="hljs-keyword">return</span> out
</code></pre>
<h4 id="otherpy"><a name="otherpy" class="anchor-navigation-ex-anchor" href="#otherpy"><i class="fa fa-link" aria-hidden="true"></i></a><a name="otherpy" class="plugin-anchor" href="#otherpy"><i class="fa fa-link" aria-hidden="true"></i></a>other.py</h4>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">record_parameter</span><span class="hljs-params">(gpu_set, epoch, learning_rate, data_path, batch_size,loss, weight_decay, model_name, time_now)</span>:</span>
    fp = open(<span class="hljs-string">&apos;log/log.txt&apos;</span>,<span class="hljs-string">&apos;a&apos;</span>)
    fp.write(<span class="hljs-string">&apos;-&apos;</span>*<span class="hljs-number">100</span> + <span class="hljs-string">&apos;\n&apos;</span> + <span class="hljs-string">&apos;new training starts :&apos;</span> + <span class="hljs-string">&apos;\n&apos;</span>)
    fp.write(<span class="hljs-string">&apos;The time of running this code is {}:&apos;</span>.format(time_now) + <span class="hljs-string">&apos;\n&apos;</span>)
    fp.write(<span class="hljs-string">&apos;The hyper parameters are as follows: \n&apos;</span>+
        <span class="hljs-string">&apos;using gpu ids : {} \n&apos;</span>.format(gpu_set)+
        <span class="hljs-string">&apos;the path of data : {} \n&apos;</span>.format(data_path)+
        <span class="hljs-string">&apos;epoch numbers : {} \n&apos;</span>.format(epoch)+
        <span class="hljs-string">&apos;batch size : {} \n&apos;</span>.format(batch_size)+
        <span class="hljs-string">&apos;learning rate : {} \n&apos;</span>.format(learning_rate)+
        <span class="hljs-string">&apos;loss function : {} \n&apos;</span>.format(loss)+
        <span class="hljs-string">&apos;weight decay : {} \n&apos;</span>.format(weight_decay)+
        <span class="hljs-string">&apos;model name : {} \n&apos;</span>.format(model_name))
    fp.close()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">record_run_time</span><span class="hljs-params">(run_time)</span>:</span>
    print(<span class="hljs-string">&apos;The time consumption of this code is : : {}&apos;</span>.format(run_time))
    fp = open(<span class="hljs-string">&apos;log/log.txt&apos;</span>,<span class="hljs-string">&apos;a&apos;</span>)
    fp.write(<span class="hljs-string">&apos;The time consumption of this code is : {} \n&apos;</span>.format(run_time))
    fp.close()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_setting</span><span class="hljs-params">(trainset, valset)</span>:</span>
    <span class="hljs-comment"># get useful settings</span>
    train_data_size = len(trainset.X_train)
    val_data_size = len(valset.X_val)
    n_classes = len(trainset.y_train_onehot[<span class="hljs-number">0</span>])
    input_lenghth = len(trainset.X_train[<span class="hljs-number">0</span>])

    <span class="hljs-comment"># print to see</span>
    print(<span class="hljs-string">&quot;The length of train set is : {}&quot;</span>.format(train_data_size))
    print(<span class="hljs-string">&quot;The length of val set is : {}&quot;</span>.format(val_data_size))
    print(<span class="hljs-string">&quot;The number of classes is : {}&quot;</span>.format(n_classes))
    print(<span class="hljs-string">&quot;The length of each input is : {}&quot;</span>.format(input_lenghth))
    <span class="hljs-keyword">return</span> train_data_size,val_data_size,n_classes,input_lenghth

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_device_name</span><span class="hljs-params">(gpu_set)</span>:</span>
    <span class="hljs-keyword">if</span> gpu_set == <span class="hljs-string">&apos;-1&apos;</span>: 
        <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">&apos;cpu&apos;</span>)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">&apos;cuda:{}&apos;</span>.format(gpu_set))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">training</span><span class="hljs-params">(train_dataloader,device,model,loss_fn,optimizer,batch_size,total_train_step,iters_time)</span>:</span>
    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:
        traffic, targets = data

        traffic = traffic.to(device)
        targets = targets.to(device)

        outputs = model(traffic)           <span class="hljs-comment"># &#x5C06;&#x8BAD;&#x7EC3;&#x7684;&#x6570;&#x636E;&#x653E;&#x5165;</span>

        <span class="hljs-comment"># print(traffic.shape,outputs.shape,targets.shape)</span>
        <span class="hljs-comment"># print(outputs)</span>
        <span class="hljs-comment"># print(targets.float())</span>
        loss = loss_fn(outputs, targets.float())    <span class="hljs-comment"># &#x5F97;&#x5230;&#x635F;&#x5931;&#x503C;</span>

        optimizer.zero_grad()               <span class="hljs-comment"># &#x4F18;&#x5316;&#x8FC7;&#x7A0B;&#x4E2D;&#x9996;&#x5148;&#x8981;&#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x6E05;&#x96F6;</span>
        loss.backward()                     <span class="hljs-comment"># &#x8C03;&#x7528;&#x5F97;&#x5230;&#x7684;&#x635F;&#x5931;&#xFF0C;&#x5229;&#x7528;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#xFF0C;&#x5F97;&#x5230;&#x6BCF;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x8282;&#x70B9;&#x7684;&#x68AF;&#x5EA6;</span>
        optimizer.step()                    <span class="hljs-comment"># &#x5BF9;&#x53C2;&#x6570;&#x8FDB;&#x884C;&#x4F18;&#x5316;</span>
        total_train_step += batch_size               <span class="hljs-comment"># &#x4E0A;&#x9762;&#x5C31;&#x662F;&#x8FDB;&#x884C;&#x4E86;&#x4E00;&#x6B21;&#x8BAD;&#x7EC3;&#xFF0C;&#x8BAD;&#x7EC3;&#x6B21;&#x6570; +1</span>

        <span class="hljs-comment"># Print some information when the number of iterations divide by batch size equal 200</span>
        <span class="hljs-keyword">if</span> total_train_step/batch_size % <span class="hljs-number">200</span> == <span class="hljs-number">0</span>:
            print(<span class="hljs-string">&quot;Iterations: {}, time consumptions :{}, Loss: {}&quot;</span>.format(total_train_step,
                time.time() - iters_time, loss))
            iters_time = time.time()
            <span class="hljs-comment"># writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validating</span><span class="hljs-params">(val_dataloader,val_data_size,device,model,loss_fn,time_now)</span>:</span>
    total_val_loss = <span class="hljs-number">0</span>
    total_accuracy = <span class="hljs-number">0</span>  <span class="hljs-comment"># &#x51C6;&#x786E;&#x7387;</span>
    <span class="hljs-keyword">with</span> torch.no_grad():
        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> val_dataloader:
            traffic, targets = data

            traffic = traffic.to(device)
            targets = targets.to(device)

            outputs = model(traffic)
            loss = loss_fn(outputs, targets.float())  <span class="hljs-comment"># &#x8FD9;&#x91CC;&#x7684; loss &#x53EA;&#x662F;&#x4E00;&#x90E8;&#x5206;&#x6570;&#x636E;(data) &#x5728;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x4E0A;&#x7684;&#x635F;&#x5931;</span>
            total_val_loss = total_val_loss + loss  <span class="hljs-comment"># &#x6574;&#x4E2A;&#x6D4B;&#x8BD5;&#x96C6;&#x7684;loss</span>
            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets.argmax(<span class="hljs-number">1</span>)).sum() <span class="hljs-comment"># &#x5206;&#x7C7B;&#x6B63;&#x786E;&#x4E2A;&#x6570;</span>
            total_accuracy += accuracy  <span class="hljs-comment"># &#x76F8;&#x52A0;</span>
    fp = open(<span class="hljs-string">&apos;log/log.txt&apos;</span>,<span class="hljs-string">&apos;a&apos;</span>)
    fp.write(<span class="hljs-string">&apos;acc of {} is : &apos;</span>.format(time_now)+str(total_accuracy / val_data_size)+<span class="hljs-string">&apos;\n&apos;</span>)
    fp.close()

    print(<span class="hljs-string">&quot;The loss in the whole val dataset: {}&quot;</span>.format(total_val_loss))
    print(<span class="hljs-string">&quot;The acc of the whole val dataset: {}&quot;</span>.format(total_accuracy / val_data_size))
    <span class="hljs-comment"># print(&apos;&#x6574;&#x4F53;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x7684;&#x6DF7;&#x6DC6;&#x77E9;&#x9635;:{}&apos;.format(confusion_matrix()))</span>
    <span class="hljs-comment"># writer.add_scalar(&quot;val_loss&quot;, total_val_loss)</span>
    <span class="hljs-comment"># writer.add_scalar(&quot;val_accuracy&quot;, total_accuracy / val_data_size, total_val_step)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_checkpoints</span><span class="hljs-params">(time_now,model,model_name,i)</span>:</span>
    name_time_part = str(time_now)
    name_time_part = name_time_part[<span class="hljs-number">5</span>:<span class="hljs-number">10</span>]+<span class="hljs-string">&apos;|&apos;</span>+name_time_part[<span class="hljs-number">11</span>:<span class="hljs-number">19</span>]
    cp_path = Path(<span class="hljs-string">&apos;checkpoints/model_{}_{}&apos;</span>.format(model_name, name_time_part)) 
    cp_path.mkdir(parents=<span class="hljs-keyword">True</span>, exist_ok=<span class="hljs-keyword">True</span>)
    torch.save(model, <span class="hljs-string">&quot;checkpoints/model_{}_{}/model_{}.pth&quot;</span>.format(model_name, name_time_part, i))
    print(<span class="hljs-string">&quot;model has been saved.&quot;</span>)
</code></pre>
<footer class="page-footer-ex"> <span class="page-footer-ex-copyright"> <a href="https://github.com/Dante-Su" target="_blank">DanteSU</a> </span> &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; <span class="page-footer-ex-footer-update"> <i>updated</i> 2022-06-05 10:12:08 </span> </footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="2.html" class="navigation navigation-prev " aria-label="Previous page: 图像修改格式">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../DP/" class="navigation navigation-next " aria-label="Next page: 深度学习">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"PyTorch","level":"1.4.5.3","depth":3,"next":{"title":"深度学习","level":"1.5","depth":1,"path":"DP/README.md","ref":"DP/README.md","articles":[{"title":"流量分类","level":"1.5.1","depth":2,"path":"DP/TrafficClassification/README.md","ref":"DP/TrafficClassification/README.md","articles":[{"title":"Open Source","level":"1.5.1.1","depth":3,"path":"DP/TrafficClassification/1.md","ref":"DP/TrafficClassification/1.md","articles":[]},{"title":"Related Papers","level":"1.5.1.2","depth":3,"path":"DP/TrafficClassification/2.md","ref":"DP/TrafficClassification/2.md","articles":[]},{"title":"Related Links","level":"1.5.1.3","depth":3,"path":"DP/TrafficClassification/3.md","ref":"DP/TrafficClassification/3.md","articles":[]}]},{"title":"姿态迁移","level":"1.5.2","depth":2,"path":"DP/StyleTransfer/README.md","ref":"DP/StyleTransfer/README.md","articles":[{"title":"Info","level":"1.5.2.1","depth":3,"path":"DP/StyleTransfer/1.md","ref":"DP/StyleTransfer/1.md","articles":[]}]},{"title":"对话推荐","level":"1.5.3","depth":2,"path":"DP/CRS/README.md","ref":"DP/CRS/README.md","articles":[{"title":"Info","level":"1.5.3.1","depth":3,"path":"DP/CRS/1.md","ref":"DP/CRS/1.md","articles":[]}]},{"title":"计算机图形学","level":"1.5.4","depth":2,"path":"DP/CG/README.md","ref":"DP/CG/README.md","articles":[{"title":"Info","level":"1.5.4.1","depth":3,"path":"DP/CG/1.md","ref":"DP/CG/1.md","articles":[]}]}]},"previous":{"title":"图像修改格式","level":"1.4.5.2","depth":3,"path":"CodeForUse/2.md","ref":"CodeForUse/2.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-sharing","-lunr","-search","search-pro","splitter","expandable-chapters-small","anchors","github","github-buttons","sharing-plus","anchor-navigation-ex","favicon","copy-code-button","page-footer-ex"],"styles":{"website":"./styles/website.css"},"pluginsConfig":{"github":{"url":"https://github.com/Dante-Su"},"page-footer-ex":{"copyright":"[DanteSU](https://github.com/Dante-Su)","markdown":true,"update_format":"2022-06-05 HH:mm:ss","update_label":"<i>updated</i>"},"splitter":{},"search-pro":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"anchor-navigation-ex":{"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"mode":"float","multipleH1":true,"pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"printLog":false,"showGoTop":true,"showLevel":false},"favicon":{"shortcut":"./source/images/favicon.ico","bookmark":"./source/images/favicon.ico","appleTouch":"./source/images/favicon.ico","appleTouchMore":{"120x120":"./source/images/favicon.ico","180x180":"./source/images/favicon.ico"}},"github-buttons":{},"expandable-chapters-small":{},"copy-code-button":{},"sharing":{"qq":false,"all":["google","facebook","weibo","twitter","qq","qzone","linkedin","pocket"],"douban":false,"facebook":false,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":false,"messenger":false,"line":false,"vk":false,"pocket":false,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","author":"DanteSU","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"DanteSU's House","language":"zh-hans","links":{"sidebar":{"但丁世界（在建）":"https://dante-su.github.io/","猪猪之家":"https://github.com/hyffun"}},"gitbook":"3.2.3","description":"All I know is here"},"file":{"path":"CodeForUse/3.md","mtime":"2022-05-29T02:12:08.207Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2022-06-04T17:11:02.546Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

