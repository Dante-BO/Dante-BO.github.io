
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Open Source · DanteSU's House</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="DanteSU">
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-page-footer-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    

        
    
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="2.html" />
    
    
    <link rel="prev" href="./" />
    

    
        <link rel="shortcut icon" href='../../source/images/favicon.ico' type="image/x-icon">
    
    
        <link rel="bookmark" href='../../source/images/favicon.ico' type="image/x-icon">
    
    
        <link rel="apple-touch-icon" href='../../source/images/favicon.ico'>
    
    
        
        <link rel="apple-touch-icon" sizes="120x120" href="../../source/images/favicon.ico">
        
        <link rel="apple-touch-icon" sizes="180x180" href="../../source/images/favicon.ico">
        
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://dante-su.github.io/" target="_blank" class="custom-link">但丁世界（在建）</a>
        </li>
    
        
        <li>
            <a href="https://github.com/hyffun" target="_blank" class="custom-link">猪猪之家</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    写在前面
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../Links/">
            
                <a href="../../Links/">
            
                    
                    常用链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../OpCode/">
            
                <a href="../../OpCode/">
            
                    
                    操作码
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../OpCode/1.html">
            
                <a href="../../OpCode/1.html">
            
                    
                    Terminal
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../OpCode/2.html">
            
                <a href="../../OpCode/2.html">
            
                    
                    Anaconda
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../OpCode/3.html">
            
                <a href="../../OpCode/3.html">
            
                    
                    Python Lib
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../OpCode/4.html">
            
                <a href="../../OpCode/4.html">
            
                    
                    Gitbook
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../OpCode/5.html">
            
                <a href="../../OpCode/5.html">
            
                    
                    Markdown
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../../OpCode/6.html">
            
                <a href="../../OpCode/6.html">
            
                    
                    Others
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../Mix/">
            
                <a href="../../Mix/">
            
                    
                    杂记
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../../Mix/1.html">
            
                <a href="../../Mix/1.html">
            
                    
                    笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../../Mix/2.html">
            
                <a href="../../Mix/2.html">
            
                    
                    bug经验集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../../Mix/3.html">
            
                <a href="../../Mix/3.html">
            
                    
                    bug解决链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../../Mix/4.html">
            
                <a href="../../Mix/4.html">
            
                    
                    岗位资源
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../../CodeForUse/">
            
                <a href="../../CodeForUse/">
            
                    
                    及时代码
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.5.1" data-path="../../CodeForUse/1.html">
            
                <a href="../../CodeForUse/1.html">
            
                    
                    图像缩放
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.2" data-path="../../CodeForUse/2.html">
            
                <a href="../../CodeForUse/2.html">
            
                    
                    图像修改格式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.3" data-path="../../CodeForUse/3.html">
            
                <a href="../../CodeForUse/3.html">
            
                    
                    PyTorch
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../">
            
                <a href="../">
            
                    
                    深度学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="./">
            
                <a href="./">
            
                    
                    流量分类
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.5.1.1" data-path="1.html">
            
                <a href="1.html">
            
                    
                    Open Source
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.2" data-path="2.html">
            
                <a href="2.html">
            
                    
                    Related Papers
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.1.3" data-path="3.html">
            
                <a href="3.html">
            
                    
                    Related Links
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../StyleTransfer/">
            
                <a href="../StyleTransfer/">
            
                    
                    姿态迁移
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="../StyleTransfer/1.html">
            
                <a href="../StyleTransfer/1.html">
            
                    
                    Related Papers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../CRS/">
            
                <a href="../CRS/">
            
                    
                    对话推荐
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" data-path="../CRS/1.html">
            
                <a href="../CRS/1.html">
            
                    
                    Related Papers
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >Open Source</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#open-source"><b></b>Open source</a></li><ul><li><span class="title-icon "></span><a href="#useful-models"><b></b>Useful Models</a></li><ul><li><span class="title-icon "></span><a href="#headers"><b></b>Headers</a></li><li><span class="title-icon "></span><a href="#deep-packet-cnn"><b></b>Deep Packet CNN</a></li><li><span class="title-icon "></span><a href="#sae"><b></b>SAE</a></li><li><span class="title-icon "></span><a href="#resnet"><b></b>ResNet</a></li><li><span class="title-icon "></span><a href="#lstm"><b></b>LSTM</a></li><li><span class="title-icon "></span><a href="#cnntransformer"><b></b>CNN+Transformer</a></li><li><span class="title-icon "></span><a href="#lstnet"><b></b>LSTNet</a></li></ul><li><span class="title-icon "></span><a href="#data-processing"><b></b>Data Processing</a></li><ul><li><span class="title-icon "></span><a href="#from-pcap-to-pickle"><b></b>from pcap to pickle</a></li><li><span class="title-icon "></span><a href="#from-pickle-to-npytxt"><b></b>from pickle to npy/txt</a></li></ul></ul></ul></div><a href="#open-source" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h1 id="open-source"><a name="open-source" class="anchor-navigation-ex-anchor" href="#open-source"><i class="fa fa-link" aria-hidden="true"></i></a><a name="open-source" class="plugin-anchor" href="#open-source"><i class="fa fa-link" aria-hidden="true"></i></a>Open source</h1>
<h2 id="useful-models"><a name="useful-models" class="anchor-navigation-ex-anchor" href="#useful-models"><i class="fa fa-link" aria-hidden="true"></i></a><a name="useful-models" class="plugin-anchor" href="#useful-models"><i class="fa fa-link" aria-hidden="true"></i></a>Useful Models</h2>
<p><strong>Author = DanteSU</strong></p>
<h3 id="headers"><a name="headers" class="anchor-navigation-ex-anchor" href="#headers"><i class="fa fa-link" aria-hidden="true"></i></a><a name="headers" class="plugin-anchor" href="#headers"><i class="fa fa-link" aria-hidden="true"></i></a>Headers</h3>
<pre><code class="lang-py">
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> TransformerEncoder, TransformerEncoderLayer
</code></pre>
<h3 id="deep-packet-cnn"><a name="deep-packet-cnn" class="anchor-navigation-ex-anchor" href="#deep-packet-cnn"><i class="fa fa-link" aria-hidden="true"></i></a><a name="deep-packet-cnn" class="plugin-anchor" href="#deep-packet-cnn"><i class="fa fa-link" aria-hidden="true"></i></a>Deep Packet CNN</h3>
<pre><code class="lang-py"><span class="hljs-comment"># model 1</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DeepPacketCNN</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, n_classes, batch_size)</span>:</span>
        super(DeepPacketCNN, self).__init__()
        self.batch_size = batch_size
        self.conv1 = nn.Conv1d(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
        self.bn1 = nn.BatchNorm1d(<span class="hljs-number">200</span>)
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)

        self.conv2 = nn.Conv1d(<span class="hljs-number">200</span>, <span class="hljs-number">100</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)
        self.bn2 = nn.BatchNorm1d(<span class="hljs-number">100</span>)

        self.pool = nn.AvgPool1d(<span class="hljs-number">2</span>)

        self.dropout = nn.Dropout(p=<span class="hljs-number">0.25</span>)


        self.fc1 = nn.Sequential(nn.Linear(<span class="hljs-number">100</span> * <span class="hljs-number">372</span>, <span class="hljs-number">600</span>), <span class="hljs-comment"># 00 * 372</span>
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc2 = nn.Sequential(nn.Linear(<span class="hljs-number">600</span>, <span class="hljs-number">500</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc3 = nn.Sequential(nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">400</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc4 = nn.Sequential(nn.Linear(<span class="hljs-number">400</span>, <span class="hljs-number">300</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc5 = nn.Sequential(nn.Linear(<span class="hljs-number">300</span>, <span class="hljs-number">200</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc6 = nn.Sequential(nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">100</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc7 = nn.Sequential(nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">50</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )

        self.fc_out = nn.Linear(<span class="hljs-number">50</span>, n_classes)

        self.lsm = nn.LogSoftmax(dim=<span class="hljs-number">0</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># print(&apos;x1x1x1x1x1x1x1x1&apos;, x.shape)</span>
        x = self.conv1(x)
        <span class="hljs-comment"># print(&apos;x2x2x2x2x2x2x2x2&apos;, x.shape)</span>
        x = self.bn1(x)
        <span class="hljs-comment"># print(&apos;x3x3x3x3x3x3x3x3&apos;, x.shape)</span>
        x = self.relu(x)
        <span class="hljs-comment"># print(&apos;x4x4x4x4x4x4x4x4&apos;, x.shape)</span>

        x = self.conv2(x)
        <span class="hljs-comment"># print(&apos;x5x5x5x5x5x5x5x5&apos;, x.shape)</span>
        x = self.bn2(x)
        <span class="hljs-comment"># print(&apos;x6x6x6x6x6x6x6x6&apos;, x.shape)</span>
        x = self.relu(x)
        <span class="hljs-comment"># print(&apos;x7x7x7x7x7x7x7x7&apos;, x.shape)</span>

        x = self.pool(x).view(self.batch_size,<span class="hljs-number">-1</span>)
        <span class="hljs-comment"># print(&apos;x8x8x8x8x8x8x8x8&apos;, x.shape)</span>

        x = self.fc1(x)
        x = self.fc2(x)
        x = self.fc3(x)
        x = self.fc4(x)
        x = self.fc5(x)
        x = self.fc6(x)
        x = self.fc7(x)

        x = self.fc_out(x)
        <span class="hljs-comment"># print(&apos;xxxxxxxxxxxxxxxxxx&apos;,x.shape)</span>

        y = self.lsm(x)
        <span class="hljs-comment"># print(&apos;yyyyyyyyyyyyyyyyyy&apos;,y.shape)</span>

        <span class="hljs-keyword">return</span> y
</code></pre>
<h3 id="sae"><a name="sae" class="anchor-navigation-ex-anchor" href="#sae"><i class="fa fa-link" aria-hidden="true"></i></a><a name="sae" class="plugin-anchor" href="#sae"><i class="fa fa-link" aria-hidden="true"></i></a>SAE</h3>
<pre><code class="lang-py"><span class="hljs-comment"># model 2</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AutoEncoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, input_size, output_size)</span>:</span>
        super(AutoEncoder, self).__init__()

        self.forward_pass = nn.Sequential(nn.Linear(input_size, output_size),
                                          nn.Dropout(p=<span class="hljs-number">0.05</span>),
                                          nn.ReLU(<span class="hljs-keyword">True</span>)
                                          )

        self.backward_pass = nn.Linear(output_size, input_size)

        self.criterion = nn.MSELoss()
        self.optimizer = torch.optim.SGD(self.parameters(), lr=<span class="hljs-number">0.1</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = x.detach()

        y = self.forward_pass(x)

        <span class="hljs-keyword">if</span> self.training:
            x_reconstruct = self.backward_pass(y)
            loss = self.criterion(x_reconstruct, x.data)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

        <span class="hljs-keyword">return</span> y.detach()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StackedAutoEncoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, n_classes)</span>:</span>
        super(StackedAutoEncoder, self).__init__()

        self.ae1 = AutoEncoder(<span class="hljs-number">1500</span>, <span class="hljs-number">400</span>)
        self.ae2 = AutoEncoder(<span class="hljs-number">400</span>, <span class="hljs-number">300</span>)
        self.ae3 = AutoEncoder(<span class="hljs-number">300</span>, <span class="hljs-number">200</span>)
        self.ae4 = AutoEncoder(<span class="hljs-number">200</span>, <span class="hljs-number">100</span>)
        self.ae5 = AutoEncoder(<span class="hljs-number">100</span>, <span class="hljs-number">50</span>)

        self.fc_out = nn.Linear(<span class="hljs-number">50</span>, n_classes)

        self.lsm = nn.LogSoftmax(dim=<span class="hljs-number">0</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.ae1(x)
        x = self.ae2(x)
        x = self.ae3(x)
        x = self.ae4(x)
        x = self.ae5(x)

        y = self.fc_out(x)

        y = self.lsm(y)

        <span class="hljs-keyword">return</span> y
</code></pre>
<pre><code class="lang-py"><span class="hljs-comment"># model 3</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">trafficBert</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,n_classes)</span>:</span>
        super(trafficBert, self).__init__()
        self.bert = BertModel.from_pretrained(<span class="hljs-string">&apos;bert_pretrain&apos;</span>)  <span class="hljs-comment"># /bert_pretrain/</span>
        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.bert.parameters():
            param.requires_grad = <span class="hljs-keyword">True</span>  <span class="hljs-comment"># &#x6BCF;&#x4E2A;&#x53C2;&#x6570;&#x90FD;&#x8981; &#x6C42;&#x68AF;&#x5EA6;</span>
        self.fc = nn.Linear(<span class="hljs-number">768</span>, n_classes)   <span class="hljs-comment"># 768 -&gt; 2</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        print(<span class="hljs-string">&apos;_&apos;</span>*<span class="hljs-number">20</span>, x.shape)
        context = x[<span class="hljs-number">0</span>]  <span class="hljs-comment"># &#x8F93;&#x5165;&#x7684;&#x53E5;&#x5B50;   (ids, seq_len, mask)</span>
        types = x[<span class="hljs-number">1</span>]
        mask = x[<span class="hljs-number">2</span>]  <span class="hljs-comment"># &#x5BF9;padding&#x90E8;&#x5206;&#x8FDB;&#x884C;mask&#xFF0C;&#x548C;&#x53E5;&#x5B50;&#x76F8;&#x540C;size&#xFF0C;padding&#x90E8;&#x5206;&#x7528;0&#x8868;&#x793A;&#xFF0C;&#x5982;&#xFF1A;[1, 1, 1, 1, 0, 0]</span>
        _, pooled = self.bert(context, token_type_ids=types, 
                              attention_mask=mask, 
                              output_all_encoded_layers=<span class="hljs-keyword">False</span>) <span class="hljs-comment"># &#x63A7;&#x5236;&#x662F;&#x5426;&#x8F93;&#x51FA;&#x6240;&#x6709;encoder&#x5C42;&#x7684;&#x7ED3;&#x679C;</span>
        out = self.fc(pooled)   <span class="hljs-comment"># &#x5F97;&#x5230;10&#x5206;&#x7C7B;</span>
        <span class="hljs-keyword">return</span> out
</code></pre>
<h3 id="resnet"><a name="resnet" class="anchor-navigation-ex-anchor" href="#resnet"><i class="fa fa-link" aria-hidden="true"></i></a><a name="resnet" class="plugin-anchor" href="#resnet"><i class="fa fa-link" aria-hidden="true"></i></a>ResNet</h3>
<pre><code class="lang-py"><span class="hljs-comment"># model 4</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, ch_in, ch_out)</span>:</span>
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.bn1 = nn.BatchNorm2d(ch_out)
        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.bn2 = nn.BatchNorm2d(ch_out)
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)

        self.extra = nn.Sequential()
        <span class="hljs-comment"># &#x5982;&#x679C;&#x8F93;&#x5165;&#x3001;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;&#x4E0D;&#x540C;&#xFF0C;&#x9700;&#x8F6C;&#x5316;&#x540E;&#x624D;&#x80FD;&#x76F8;&#x52A0;</span>
        <span class="hljs-keyword">if</span> ch_out != ch_in:
            self.extra = nn.Sequential(
                nn.Conv2d(ch_in, ch_out, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>),
                nn.BatchNorm2d(ch_out)
            )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># print(&apos;-1&apos;*10,x.shape)</span>
        out = self.conv1(x)
        <span class="hljs-comment"># print(&apos;-2&apos;*10,out.shape)</span>
        out = self.bn1(out)
        <span class="hljs-comment"># print(&apos;-3&apos;*10,out.shape)</span>
        out = self.relu(out)
        <span class="hljs-comment"># print(&apos;-4&apos;*10,out.shape)</span>
        out = self.conv2(out)
        <span class="hljs-comment"># print(&apos;-5&apos;*10,out.shape)</span>
        out = self.bn2(out)
        <span class="hljs-comment"># print(&apos;-6&apos;*10,out.shape)</span>
        out = self.extra(x) + out
        <span class="hljs-comment"># print(&apos;-7&apos;*10,out.shape)</span>
        <span class="hljs-keyword">return</span> out

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet18</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,n_classes)</span>:</span>
        super(ResNet18, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.BatchNorm2d(<span class="hljs-number">64</span>)
        )
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)
        <span class="hljs-comment"># 4 block [b, 64, h, w] =&gt; [b, 1024, h, w]</span>
        self.blk1 = ResNet(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)
        self.blk2 = ResNet(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>)
        self.blk3 = ResNet(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>)
        self.blk4 = ResNet(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>)
        <span class="hljs-comment"># &#x6CE8;&#x610F;&#x6700;&#x540E;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#x7EF4;&#x5EA6;&#xFF0C;&#x8FDB;&#x53BB;&#x4E4B;&#x524D;&#x9700;&#x8981;&#x5148;&#x6253;&#x5E73;</span>
        self.outlayer = nn.Linear(<span class="hljs-number">1024</span>*<span class="hljs-number">30</span>*<span class="hljs-number">50</span>, n_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = x.view(len(x),<span class="hljs-number">30</span>,<span class="hljs-number">-1</span>)
        x = x.unsqueeze(<span class="hljs-number">1</span>)
        <span class="hljs-comment"># print(&apos;-1&apos;*10,x.shape)</span>
        x = self.conv1(x)
        <span class="hljs-comment"># print(&apos;-2&apos;*10,x.shape)</span>
        x = self.relu(x)
        <span class="hljs-comment"># print(&apos;-3&apos;*10,x.shape)</span>

        <span class="hljs-comment">#</span>
        x = self.blk1(x)
        <span class="hljs-comment"># print(&apos;-4&apos;*10,x.shape)</span>
        x = self.blk2(x)
        <span class="hljs-comment"># print(&apos;-5&apos;*10,x.shape)</span>
        x = self.blk3(x)
        <span class="hljs-comment"># print(&apos;-6&apos;*10,x.shape)</span>
        x = self.blk4(x)
        <span class="hljs-comment"># print(&apos;-7&apos;*10,x.shape)</span>
        <span class="hljs-comment"># print(x.size(0))</span>
        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)  <span class="hljs-comment"># &#x5148;&#x6253;&#x5E73;&#xFF0C;&#x518D;&#x8FDB;&#x5168;&#x8FDE;&#x63A5;</span>
        <span class="hljs-comment"># print(&apos;-8&apos;*10,x.shape)</span>

        x = self.outlayer(x)
        <span class="hljs-comment"># print(&apos;-9&apos;*10,x.shape)</span>
        <span class="hljs-keyword">return</span> x
</code></pre>
<h3 id="lstm"><a name="lstm" class="anchor-navigation-ex-anchor" href="#lstm"><i class="fa fa-link" aria-hidden="true"></i></a><a name="lstm" class="plugin-anchor" href="#lstm"><i class="fa fa-link" aria-hidden="true"></i></a>LSTM</h3>
<h4 id="pure-lstm"><a name="pure-lstm" class="anchor-navigation-ex-anchor" href="#pure-lstm"><i class="fa fa-link" aria-hidden="true"></i></a><a name="pure-lstm" class="plugin-anchor" href="#pure-lstm"><i class="fa fa-link" aria-hidden="true"></i></a>Pure LSTM</h4>
<pre><code class="lang-py"><span class="hljs-comment"># model 5</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LSTM</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,INPUT_SIZE,n_classes)</span>:</span>
        super(LSTM, self).__init__()

        self.rnn = nn.LSTM(         <span class="hljs-comment"># if use nn.RNN(), it hardly learns</span>
            input_size=INPUT_SIZE,
            hidden_size=<span class="hljs-number">64</span>,         <span class="hljs-comment"># rnn hidden unit</span>
            num_layers=<span class="hljs-number">1</span>,           <span class="hljs-comment"># number of rnn layer</span>
            batch_first=<span class="hljs-keyword">True</span>,       <span class="hljs-comment"># input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)</span>
        )

        self.out = nn.Linear(<span class="hljs-number">64</span>, n_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># x shape (batch, time_step, input_size)</span>
        <span class="hljs-comment"># r_out shape (batch, time_step, output_size)</span>
        <span class="hljs-comment"># h_n shape (n_layers, batch, hidden_size)</span>
        <span class="hljs-comment"># h_c shape (n_layers, batch, hidden_size)</span>
        r_out, (h_n, h_c) = self.rnn(x, <span class="hljs-keyword">None</span>)   <span class="hljs-comment"># None represents zero initial hidden state</span>

        <span class="hljs-comment"># choose r_out at the last time step</span>
        out = self.out(r_out[:, <span class="hljs-number">-1</span>, :])
        <span class="hljs-keyword">return</span> out
</code></pre>
<h4 id="lstmfc"><a name="lstmfc" class="anchor-navigation-ex-anchor" href="#lstmfc"><i class="fa fa-link" aria-hidden="true"></i></a><a name="lstmfc" class="plugin-anchor" href="#lstmfc"><i class="fa fa-link" aria-hidden="true"></i></a>LSTM+FC</h4>
<pre><code class="lang-py"><span class="hljs-comment"># model 5.1</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LSTM_FC2</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,INPUT_SIZE,n_classes)</span>:</span>
        super(LSTM_FC2, self).__init__()

        self.rnn = nn.LSTM(         <span class="hljs-comment"># if use nn.RNN(), it hardly learns</span>
            input_size=INPUT_SIZE,
            hidden_size=<span class="hljs-number">1024</span>,         <span class="hljs-comment"># rnn hidden unit</span>
            num_layers=<span class="hljs-number">1</span>,           <span class="hljs-comment"># number of rnn layer</span>
            batch_first=<span class="hljs-keyword">True</span>,       <span class="hljs-comment"># input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)</span>
        )
        self.fc1 = nn.Sequential(nn.Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">256</span>), <span class="hljs-comment"># 00 * 372</span>
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )
        self.fc2 = nn.Sequential(nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">64</span>),
                                 nn.Dropout(p=<span class="hljs-number">0.25</span>), nn.ReLU(<span class="hljs-keyword">True</span>)
                                 )

        self.out = nn.Linear(<span class="hljs-number">64</span>, n_classes)
        self.lsm = nn.LogSoftmax(dim=<span class="hljs-number">0</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># print(x.shape)</span>
        <span class="hljs-comment"># x shape (batch, time_step, input_size)</span>
        <span class="hljs-comment"># r_out shape (batch, time_step, output_size)</span>
        <span class="hljs-comment"># h_n shape (n_layers, batch, hidden_size)</span>
        <span class="hljs-comment"># h_c shape (n_layers, batch, hidden_size)</span>
        r_out, (h_n, h_c) = self.rnn(x, <span class="hljs-keyword">None</span>)   <span class="hljs-comment"># None represents zero initial hidden state</span>
        <span class="hljs-comment"># print(&apos;r_out is : &apos;,r_out.shape)</span>
        r_out = r_out[:, <span class="hljs-number">-1</span>, :]
        <span class="hljs-comment"># print(&apos;r_out is : &apos;,r_out.shape)</span>

        r_out = self.fc1(r_out)
        r_out = self.fc2(r_out)

        <span class="hljs-comment"># choose r_out at the last time step</span>
        out = self.out(r_out)
        <span class="hljs-comment"># print(&apos;out is : &apos;,out.shape)</span>

        <span class="hljs-keyword">return</span> out
</code></pre>
<h3 id="cnntransformer"><a name="cnntransformer" class="anchor-navigation-ex-anchor" href="#cnntransformer"><i class="fa fa-link" aria-hidden="true"></i></a><a name="cnntransformer" class="plugin-anchor" href="#cnntransformer"><i class="fa fa-link" aria-hidden="true"></i></a>CNN+Transformer</h3>
<pre><code class="lang-py"><span class="hljs-comment"># model 6</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResModule</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, ch_in, ch_out, kernel_size, stride)</span>:</span>
        super(ResModule, self).__init__()
        self.conv1 = nn.Conv1d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=(kernel_size<span class="hljs-number">-1</span>)//<span class="hljs-number">2</span>)
        self.bn1 = nn.BatchNorm1d(ch_out)
        self.conv2 = nn.Conv1d(ch_out, ch_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=(kernel_size<span class="hljs-number">-1</span>)//<span class="hljs-number">2</span>)
        self.bn2 = nn.BatchNorm1d(ch_out)
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)

        <span class="hljs-keyword">if</span> stride == <span class="hljs-number">1</span>:
            self.downsample = <span class="hljs-keyword">None</span>
        <span class="hljs-keyword">else</span>:    
            self.downsample = nn.Sequential(
                nn.Conv1d(ch_in, ch_out, kernel_size=<span class="hljs-number">1</span>, stride=stride), nn.BatchNorm1d(ch_out))

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            x = self.downsample(x)

        <span class="hljs-keyword">return</span> self.relu(x+out)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,ch)</span>:</span>
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv1d(<span class="hljs-number">1</span>, ch, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.BatchNorm1d(ch)
        )
        self.relu = nn.ReLU(inplace=<span class="hljs-keyword">True</span>)
        self.blk1 = ResModule(ch, ch*<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>)
        self.blk2 = ResModule(ch*<span class="hljs-number">2</span>, ch*<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>)
        self.blk3 = ResModule(ch*<span class="hljs-number">2</span>, ch*<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>)
        self.blk4 = ResModule(ch*<span class="hljs-number">4</span>, ch*<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>)


    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.conv1(x)
        x = self.relu(x)

        x = self.blk1(x)
        x = self.blk2(x)
        x = self.blk3(x)
        x = self.blk4(x)

        <span class="hljs-keyword">return</span> x

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PositionalEncoding</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, d_model: int, dropout: float = <span class="hljs-number">0.1</span>, max_len: int = <span class="hljs-number">5000</span>)</span>:</span>
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(<span class="hljs-number">1</span>)
        div_term = torch.exp(torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>) * (-math.log(<span class="hljs-number">10000.0</span>) / d_model))
        pe = torch.zeros(max_len, <span class="hljs-number">1</span>, d_model)
        pe[:, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term)
        pe[:, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term)
        self.register_buffer(<span class="hljs-string">&apos;pe&apos;</span>, pe)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x: Tensor)</span> -&gt; Tensor:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        &quot;&quot;&quot;</span>
        x = x + self.pe[:x.size(<span class="hljs-number">0</span>)]
        <span class="hljs-keyword">return</span> self.dropout(x)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN_TRAN</span><span class="hljs-params">(nn.Module)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, n_classes)</span>:</span>
        super(CNN_TRAN, self).__init__()

        self.cnn = CNN(ch=<span class="hljs-number">16</span>)

        emsize = <span class="hljs-number">64</span>
        self.pos_encoder = PositionalEncoding(emsize, dropout=<span class="hljs-number">0.2</span>)
        encoder_layers = TransformerEncoderLayer(d_model=emsize, nhead=<span class="hljs-number">4</span>, dim_feedforward=<span class="hljs-number">256</span>, dropout=<span class="hljs-number">0.2</span>)
        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=<span class="hljs-number">4</span>)
        self.d_model = emsize

        self.decoder = nn.Sequential(
            nn.Linear(<span class="hljs-number">64</span>*<span class="hljs-number">94</span>, <span class="hljs-number">512</span>),
            nn.ReLU(),
            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>),
            nn.ReLU(),
            nn.Linear(<span class="hljs-number">256</span>, n_classes)
        )

        <span class="hljs-comment"># self.init_weights()</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_weights</span><span class="hljs-params">(self)</span> -&gt; <span class="hljs-keyword">None</span>:</span>
        <span class="hljs-keyword">pass</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, src: Tensor)</span> -&gt; Tensor:</span>
        bs,_,_ = src.shape

        x = self.cnn(src).permute(<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)

        x = self.pos_encoder(x)
        x = self.transformer_encoder(x).permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)

        x = self.decoder(x.reshape(bs,<span class="hljs-number">-1</span>))

        pred = F.softmax(x,dim=<span class="hljs-number">1</span>)
        <span class="hljs-keyword">return</span> pred
</code></pre>
<h3 id="lstnet"><a name="lstnet" class="anchor-navigation-ex-anchor" href="#lstnet"><i class="fa fa-link" aria-hidden="true"></i></a><a name="lstnet" class="plugin-anchor" href="#lstnet"><i class="fa fa-link" aria-hidden="true"></i></a>LSTNet</h3>
<pre><code class="lang-py"><span class="hljs-comment"># model 7</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LSTNet</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, window=<span class="hljs-number">50</span>, input_dim=<span class="hljs-number">1500</span>,hidRNN=<span class="hljs-number">100</span>,hidCNN=<span class="hljs-number">250</span>,hidSkip=<span class="hljs-number">5</span>,CNN_kernel=<span class="hljs-number">5</span>,skip=<span class="hljs-number">5</span>,
            highway_window=<span class="hljs-number">1500</span>,dropout=float<span class="hljs-params">(<span class="hljs-number">0.2</span>)</span>,output_fun=<span class="hljs-string">&apos;sigmoid&apos;</span>)</span>:</span>
        super(LSTNet, self).__init__()
        <span class="hljs-comment"># P1500 m 1</span>
        self.use_cuda = <span class="hljs-keyword">True</span>
        self.P = window<span class="hljs-comment"># &#x65F6;&#x95F4;&#x5E8F;&#x5217;&#x7A97;&#x53E3;&#xFF0C;&#x8F93;&#x5165;&#x7F51;&#x7EDC;&#x7684;&#x65F6;&#x95F4;&#x6233;&#x957F;&#x5EA6;</span>
        self.m = <span class="hljs-number">30</span>; <span class="hljs-comment"># &#x65F6;&#x95F4;&#x5E8F;&#x5217;&#x8F93;&#x5165;&#x7EF4;&#x5EA6;</span>
        self.hidR = hidRNN <span class="hljs-comment"># RNN&#x5C42;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;</span>
        self.hidC = hidCNN <span class="hljs-comment"># CNN&#x5C42;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;</span>
        self.hidS = hidSkip <span class="hljs-comment"># Skip-RNN&#x5C42;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;</span>
        self.Ck = CNN_kernel <span class="hljs-comment"># CNN&#x5C42;kernel&#x5927;&#x5C0F;</span>
        self.skip = skip <span class="hljs-comment"># &#x5468;&#x671F;&#x957F;&#x5EA6;</span>
        self.pt = int((self.P - self.Ck)/self.skip) <span class="hljs-comment"># window&#x5728;kernel&#x4F5C;&#x7528;&#x4E0B;&#xFF0C;&#x4EE5;skip&#x4E3A;&#x5468;&#x671F;&#x7684;&#x6570;&#x636E;&#x6570;&#x91CF;&#x3002;&#x5468;&#x671F;&#x6570;&#x76EE;&#x3002; #50-5/5 =9</span>
        self.hw = highway_window <span class="hljs-comment"># highway&#x901A;&#x9053;&#x7684;&#x8F93;&#x51FA;&#x8282;&#x70B9;&#x6570;&#x76EE;</span>
        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, self.hidC, kernel_size = (self.Ck, self.m)) <span class="hljs-comment"># &#x7B2C;&#x4E00;&#x5C42;conv2d</span>
        self.GRU1 = nn.GRU(self.hidC, self.hidR) <span class="hljs-comment"># &#x7B2C;&#x4E00;&#x5C42;GRU</span>
        self.dropout = nn.Dropout(p = dropout)
        <span class="hljs-keyword">if</span> (self.skip &gt; <span class="hljs-number">0</span>): 
            self.GRUskip = nn.GRU(self.hidC, self.hidS)
            <span class="hljs-comment"># self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, self.m)</span>
            self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, <span class="hljs-number">11</span>)
        <span class="hljs-keyword">else</span>:
            self.linear1 = nn.Linear(self.hidR, self.m)
        <span class="hljs-keyword">if</span> (self.hw &gt; <span class="hljs-number">0</span>):
            <span class="hljs-comment"># self.highway = nn.Linear(self.hw, 1) # highway&#x540E;&#x8DDF;&#x7EBF;&#x6027;&#x5C42;</span>
            self.highway = nn.Linear(self.hw, <span class="hljs-number">11</span>)
        self.output = <span class="hljs-keyword">None</span>
        <span class="hljs-keyword">if</span> (output_fun == <span class="hljs-string">&apos;sigmoid&apos;</span>):
            self.output = F.sigmoid
        <span class="hljs-keyword">if</span> (output_fun == <span class="hljs-string">&apos;tanh&apos;</span>):
            self.output = F.tanh

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># print(&apos;x here is : &apos;,x.shape)#[2, 1, 1500]</span>
        batch_size = x.size(<span class="hljs-number">0</span>)
        <span class="hljs-comment"># print(&apos;batch_size here is : &apos;,batch_size)#2</span>
        <span class="hljs-comment"># &#x8F93;&#x5165; x dim = [batch_size, window_size, data_dim]</span>
        <span class="hljs-comment"># &#x56E0;&#x4E3A; CNN conv2d need [batch_size, in_channels, inputHeight, inputWidth],</span>
        <span class="hljs-comment"># &#x6240;&#x4EE5; x &#x8F6C;&#x53D8;&#x4E3A; c = [batch_size, 1, window_size, data_dim]</span>
        c = x.view(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, self.P, self.m)<span class="hljs-comment">#[4, 1, 1500, 1]</span>
        <span class="hljs-comment"># print(&apos;c1 here is : &apos;,c.shape)</span>
        <span class="hljs-comment"># &#x7ECF;&#x8FC7; conv1 &#x540E;&#xFF0C;out = [batch_size, out_channels, outHeight, outWidth],</span>
        <span class="hljs-comment"># &#x5176;&#x4E2D; outWidth = self.m &#x5373;&#x65F6;&#x95F4;&#x5E8F;&#x5217;&#x8F93;&#x5165;&#x7EF4;&#x5EA6;&#xFF0C;&#x5373;&#x6BCF;&#x6B21;kernel&#x6ED1;&#x52A8;&#x90FD;&#x4F1A;&#x5C06;&#x8F93;&#x5165;&#x7EF4;&#x5EA6;&#x53D8;&#x4E3A;1,</span>
        <span class="hljs-comment"># &#x6240;&#x4EE5; outWidth=1&#xFF0C;&#x9700;&#x8981; squeeze &#x4E3A;3&#x4E2A;&#x7EF4;&#x5EA6; [batch_size, out_channels, outHeight]</span>
        c = F.relu(self.conv1(c))<span class="hljs-comment">#2, 250, 46, 1]</span>
        <span class="hljs-comment"># print(&apos;c2 here is : &apos;,c.shape)</span>
        c = self.dropout(c)
        <span class="hljs-comment"># print(&apos;c3 here is : &apos;,c.shape)</span>
        c = torch.squeeze(c, <span class="hljs-number">3</span>); <span class="hljs-comment"># batch_size, out_channels, outHeight]</span>
        <span class="hljs-comment"># print(&apos;c4 here is : &apos;,c.shape)</span>

        <span class="hljs-comment"># RNN </span>
        <span class="hljs-comment"># GRU input shape: [seq_len, batch_size, input_size]&#xFF0C;&#x9700;&#x8981;&#x7531; c &#x5148; reshape</span>
        r = c.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).contiguous()
        <span class="hljs-comment"># print(&apos;r here is : &apos;,r.shape)</span>
        _, r = self.GRU1(r)
        r = self.dropout(torch.squeeze(r,<span class="hljs-number">0</span>)) <span class="hljs-comment"># [batch_size, hiddenRnn]</span>
        <span class="hljs-comment"># print(&apos;r here is : &apos;,r.shape)</span>

        <span class="hljs-comment">#skip-rnn</span>

        <span class="hljs-keyword">if</span> (self.skip &gt; <span class="hljs-number">0</span>):
            <span class="hljs-comment"># print(&apos;here is skip!&apos;)</span>
            s = c[:,:, int(-self.pt * self.skip):].contiguous();
            <span class="hljs-comment"># print(&apos;s1 here is : &apos;,s.shape)#5 100 45</span>
            <span class="hljs-comment"># print(&apos;-----------&apos;,batch_size, self.hidC, self.pt, self.skip)</span>
            s = s.view(batch_size, self.hidC, int(self.pt), self.skip) <span class="hljs-comment">#2,250,9,5</span>
            <span class="hljs-comment"># print(&apos;s2 here is : &apos;,s.shape)</span>
            s = s.permute(<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>).contiguous()
            <span class="hljs-comment"># print(&apos;s3 here is : &apos;,s.shape)</span>
            s = s.view(self.pt, batch_size * self.skip, self.hidC)
            <span class="hljs-comment"># print(&apos;s4 here is : &apos;,s.shape)</span>
            _, s = self.GRUskip(s)
            s = s.view(batch_size, self.skip * self.hidS)
            <span class="hljs-comment"># print(&apos;s5 here is : &apos;,s.shape)</span>
            s = self.dropout(s); <span class="hljs-comment"># [batch_size, hiddenSkip]</span>
            <span class="hljs-comment"># print(&apos;s6 here is : &apos;,s.shape)</span>
            <span class="hljs-comment"># &#x628A;(batch_size, hiddenRnn)&#x548C;(batch_size, hiddenSkip)&#x62FC;&#x63A5;&#x5728;&#x4E00;&#x8D77;&#xFF0C;</span>
            <span class="hljs-comment"># &#x7136;&#x540E;&#x901A;&#x8FC7;&#x5168;&#x8FDE;&#x63A5;&#xFF0C;&#x5F97;&#x5230;(batch_size, data_dim)&#x7684;&#x975E;&#x7EBF;&#x6027;&#x8F93;&#x51FA;</span>
            r = torch.cat((r,s),<span class="hljs-number">1</span>)
            <span class="hljs-comment"># print(&apos;r here is : &apos;,r.shape)</span>

        res = self.linear1(r) <span class="hljs-comment"># [batch_size, data_dim(&#x5373;self.m)] &#x8FD9;&#x4E2A;&#x7684;&#x8F93;&#x51FA;&#x548C;&#x8F93;&#x5165;&#x662F;&#x4E00;&#x6837;&#x5927;&#x7684;&#xFF0C;&#x4E0D;&#x5BF9;</span>
        <span class="hljs-comment"># print(&apos;res here is : &apos;,res.shape)</span>

        <span class="hljs-comment">#highway</span>
        <span class="hljs-keyword">if</span> (self.hw &gt; <span class="hljs-number">0</span>):
            <span class="hljs-comment"># print(&apos;here is hw&apos;)</span>
            z = x[:, -self.hw:, :]
            <span class="hljs-comment"># print(&apos;z here is : &apos;,z.shape)</span>
            z = z.permute(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>).contiguous().view(<span class="hljs-number">-1</span>, self.hw)
            <span class="hljs-comment"># print(&apos;z here is : &apos;,z.shape)#4,1500</span>
            z = self.highway(z) <span class="hljs-comment"># &#x8FC7;&#x7EBF;&#x6027;&#x5C42;</span>
            <span class="hljs-comment"># print(&apos;z here is : &apos;,z.shape)#2,1</span>
            <span class="hljs-comment"># z = z.view(-1,self.m)#30</span>
            <span class="hljs-comment"># print(&apos;z here is : &apos;,z.shape)</span>
            res = res + z<span class="hljs-comment"># &#x76F8;&#x52A0;  2,12</span>
            <span class="hljs-comment"># print(&apos;res here is : &apos;,res.shape)</span>

        <span class="hljs-keyword">if</span> (self.output):
            res = self.output(res)<span class="hljs-comment"># &#x8FC7;&#x4E00;&#x5C42;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x8BBA;&#x6587;&#x91CC;&#x8868;&#x793A;relu&#x6548;&#x679C;&#x6BD4;tanh&#x66F4;&#x597D;</span>
        <span class="hljs-keyword">return</span> res
</code></pre>
<h2 id="data-processing"><a name="data-processing" class="anchor-navigation-ex-anchor" href="#data-processing"><i class="fa fa-link" aria-hidden="true"></i></a><a name="data-processing" class="plugin-anchor" href="#data-processing"><i class="fa fa-link" aria-hidden="true"></i></a>Data Processing</h2>
<h3 id="from-pcap-to-pickle"><a name="from-pcap-to-pickle" class="anchor-navigation-ex-anchor" href="#from-pcap-to-pickle"><i class="fa fa-link" aria-hidden="true"></i></a><a name="from-pcap-to-pickle" class="plugin-anchor" href="#from-pcap-to-pickle"><i class="fa fa-link" aria-hidden="true"></i></a>from pcap to pickle</h3>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> scapy.all <span class="hljs-keyword">import</span> *
<span class="hljs-comment">#from pcapng.scanner import FileScanner</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> multiprocessing <span class="hljs-keyword">as</span> mp
<span class="hljs-keyword">import</span> pickle <span class="hljs-keyword">as</span> pk


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pkts2X</span><span class="hljs-params">(pkts)</span>:</span>
    X = []
    <span class="hljs-comment">#lens = []</span>
    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pkts:
        <span class="hljs-comment">#===================================</span>
        <span class="hljs-comment"># step 1 : remove Ether Header</span>
        <span class="hljs-comment">#===================================</span>
        r = raw(p)[<span class="hljs-number">14</span>:]
        r = np.frombuffer(r, dtype = np.uint8)
        <span class="hljs-comment">#p.show()</span>
        <span class="hljs-comment">#===================================</span>
        <span class="hljs-comment"># step 2 : pad 0 to UDP Header</span>
        <span class="hljs-comment"># it seems that we need to do nothing this step</span>
        <span class="hljs-comment"># I found some length of raw data is larger than 1500</span>
        <span class="hljs-comment"># remove them.</span>
        <span class="hljs-comment">#===================================</span>
        <span class="hljs-keyword">if</span> (TCP <span class="hljs-keyword">in</span> p <span class="hljs-keyword">or</span> UDP <span class="hljs-keyword">in</span> p):
            <span class="hljs-string">&quot;&quot;&quot;
            if UDP in p:
                # todo : padding 0 to 
                print (&apos;UDP&apos;, r[:20])
                print(p[IP].src, p[IP].dst)
            else :
                print(&apos;TCP&apos;, r[:20])
                print(p[IP].src, p[IP].dst)
            &quot;&quot;&quot;</span>
            <span class="hljs-keyword">if</span> (len(r) &gt; <span class="hljs-number">1500</span>):
                <span class="hljs-keyword">pass</span>
            <span class="hljs-keyword">else</span>:
                X.append(r)
                <span class="hljs-comment">#lens.append(len(r))</span>
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">pass</span>
    <span class="hljs-keyword">return</span> X<span class="hljs-comment">#, lens</span>


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_data_by_file</span><span class="hljs-params">(filename)</span>:</span>
    pkts = rdpcap(filename)
    X = pkts2X(pkts)
    <span class="hljs-comment"># save X to npy and delete the original pcap (it&apos;s too large).</span>
    <span class="hljs-keyword">return</span> X


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task</span><span class="hljs-params">(filename)</span>:</span>
    <span class="hljs-keyword">global</span> dict_name2label
    <span class="hljs-keyword">global</span> counter
    head, tail = os.path.split(filename)
    cond1 = os.path.isfile(os.path.join(<span class="hljs-string">&apos;data&apos;</span>, tail+<span class="hljs-string">&apos;.pickle&apos;</span>))
    cond2 = os.path.isfile(os.path.join(<span class="hljs-string">&apos;data&apos;</span>, tail+<span class="hljs-string">&apos;_class.pickle&apos;</span>))
    <span class="hljs-keyword">if</span> (cond1 <span class="hljs-keyword">and</span> cond2):
        <span class="hljs-keyword">with</span> lock:
            counter.value += <span class="hljs-number">1</span>        
        print(<span class="hljs-string">&apos;[{}] {}&apos;</span>.format(counter, filename))
        <span class="hljs-keyword">return</span> <span class="hljs-string">&apos;#ALREADY#&apos;</span>
    X = get_data_by_file(filename)
    <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> cond1):
        y = [dict_name2label[tail]] * len(X)
        <span class="hljs-keyword">with</span> open(os.path.join(<span class="hljs-string">&apos;data&apos;</span>, tail+<span class="hljs-string">&apos;.pickle&apos;</span>), <span class="hljs-string">&apos;wb&apos;</span>) <span class="hljs-keyword">as</span> f:
            pk.dump((X, y), f)
    <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> cond2):
        y2 = [dict_name2class[tail]] * len(X)
        <span class="hljs-keyword">with</span> open(os.path.join(<span class="hljs-string">&apos;data&apos;</span>, tail+<span class="hljs-string">&apos;_class.pickle&apos;</span>), <span class="hljs-string">&apos;wb&apos;</span>) <span class="hljs-keyword">as</span> f:
            pk.dump(y2, f)
    <span class="hljs-keyword">with</span> lock:
        counter.value += <span class="hljs-number">1</span>
    print(<span class="hljs-string">&apos;[{}] {}&apos;</span>.format(counter, filename))
    <span class="hljs-keyword">return</span> <span class="hljs-string">&apos;Done&apos;</span>


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_todo_list</span><span class="hljs-params">(directory, check = None)</span>:</span>
    files = os.listdir(directory)
    todo_list = []
    <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> files:
        fullpath = os.path.join(directory, f)
        <span class="hljs-keyword">if</span> os.path.isfile(fullpath):
            <span class="hljs-keyword">if</span> check <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
                <span class="hljs-keyword">if</span> check(f):
                    todo_list.append(fullpath)
            <span class="hljs-keyword">else</span>:
                todo_list.append(fullpath)
    <span class="hljs-keyword">return</span> todo_list


<span class="hljs-comment">#=========================================</span>
<span class="hljs-comment"># mp init</span>
<span class="hljs-comment">#=========================================</span>

<span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;fileName2Application.pickle&apos;</span>, <span class="hljs-string">&apos;rb&apos;</span>) <span class="hljs-keyword">as</span> f:
    dict_name2label = pk.load(f)

<span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;fileName2Characterization.pickle&apos;</span>, <span class="hljs-string">&apos;rb&apos;</span>) <span class="hljs-keyword">as</span> f:
    dict_name2class = pk.load(f)
lock = mp.Lock()
counter = mp.Value(<span class="hljs-string">&apos;i&apos;</span>, <span class="hljs-number">0</span>)
cpus = mp.cpu_count()//<span class="hljs-number">2</span>
pool = mp.Pool(processes=cpus)

todo_list = gen_todo_list(<span class="hljs-string">&apos;../pcap&apos;</span>)

<span class="hljs-comment">#todo_list = todo_list[:3]</span>

total_number = len(todo_list)

done_list = []

res = pool.map(task, todo_list)

print(len(res))
</code></pre>
<h4 id="links-to-two-files-needed"><a name="links-to-two-files-needed" class="anchor-navigation-ex-anchor" href="#links-to-two-files-needed"><i class="fa fa-link" aria-hidden="true"></i></a><a name="links-to-two-files-needed" class="plugin-anchor" href="#links-to-two-files-needed"><i class="fa fa-link" aria-hidden="true"></i></a>Links to two files needed</h4>
<p><a href="../../Source/traffic_prepro_objs/fileName2Application.pickle">fileName2Application.pickle</a>
<a href="../../Source/traffic_prepro_objs/fileName2Characterization.pickle">fileName2Characterization.pickle</a></p>
<h3 id="from-pickle-to-npytxt"><a name="from-pickle-to-npytxt" class="anchor-navigation-ex-anchor" href="#from-pickle-to-npytxt"><i class="fa fa-link" aria-hidden="true"></i></a><a name="from-pickle-to-npytxt" class="plugin-anchor" href="#from-pickle-to-npytxt"><i class="fa fa-link" aria-hidden="true"></i></a>from pickle to npy/txt</h3>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> time

<span class="hljs-comment"># &#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;</span>
<span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader

<span class="hljs-keyword">import</span> pickle <span class="hljs-keyword">as</span> pk
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelBinarizer
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> os

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
        &#x4E0B;&#x8F7D;&#x6570;&#x636E;&#x3001;&#x521D;&#x59CB;&#x5316;&#x6570;&#x636E;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x5728;&#x8FD9;&#x91CC;&#x5B8C;&#x6210;
    &quot;&quot;&quot;</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,data_path)</span>:</span>        
        self.data_path = data_path
        self.data = self.data(task_type = <span class="hljs-string">&apos;class&apos;</span>)
        self.X_train = torch.from_numpy(np.array(self.data[<span class="hljs-number">0</span>])).to(torch.float32)
        self.X_val = torch.from_numpy(np.array(self.data[<span class="hljs-number">1</span>])).to(torch.float32)
        self.X_test = torch.from_numpy(np.array(self.data[<span class="hljs-number">2</span>])).to(torch.float32)
        self.y_train_onehot = torch.from_numpy(np.array(self.data[<span class="hljs-number">3</span>]))
        self.y_val_onehot = torch.from_numpy(np.array(self.data[<span class="hljs-number">4</span>]))
        self.y_test_onehot = torch.from_numpy(np.array(self.data[<span class="hljs-number">5</span>]))


    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data</span><span class="hljs-params">(self, task_type)</span>:</span>
        <span class="hljs-comment"># load &#x8CC7;&#x6599;</span>
        data_time = time.time()
        X_train, y_train, X_val, y_val, X_test, y_test = self.load_data(task_type)
        print(<span class="hljs-string">&apos;The time consumption of loading data is : {}&apos;</span>.format(time.time()-data_time))
        <span class="hljs-comment"># print(&apos;yyyyyyyyyyyyyyyy&apos;, y_train[1])</span>

        <span class="hljs-comment"># normalize X</span>
        <span class="hljs-comment"># X_train , X_val, X_test = np.array(X_train) / 255, np.array(X_val) / 255, np.array(X_test) / 255</span>

        <span class="hljs-comment"># &#x628A; y &#x7684; string &#x505A;&#x6210; one hot encoding &#x5F62;&#x5F0F;</span>
        coding_time = time.time()
        label_encoder = LabelBinarizer()
        y_train_onehot = label_encoder.fit_transform(y_train)
        y_val_onehot = label_encoder.transform(y_val)
        y_test_onehot = label_encoder.transform(y_test)
        print(<span class="hljs-string">&apos;The time consumption of coding in one-hot is : {}&apos;</span>.format(time.time()-coding_time))
        data = [X_train , X_val, X_test, y_train_onehot, y_val_onehot, y_test_onehot]
        <span class="hljs-keyword">return</span> data

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dump</span><span class="hljs-params">(self, data, filename)</span>:</span>
        <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">&apos;wb&apos;</span>) <span class="hljs-keyword">as</span> f:
            pk.dump(data, f)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load</span><span class="hljs-params">(self, filename)</span>:</span>
        <span class="hljs-keyword">with</span> open(filename, <span class="hljs-string">&apos;rb&apos;</span>) <span class="hljs-keyword">as</span> f:
            data = pk.load(f)
        <span class="hljs-keyword">return</span> data

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_todo_list</span><span class="hljs-params">(self, check = None)</span>:</span>
        files = os.listdir(self.data_path)
        todo_list = []
        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> files:
            fullpath = os.path.join(self.data_path, f)
            <span class="hljs-keyword">if</span> os.path.isfile(fullpath):
                <span class="hljs-keyword">if</span> check <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
                    <span class="hljs-keyword">if</span> check(f):
                        todo_list.append(fullpath)
                <span class="hljs-keyword">else</span>:
                    todo_list.append(fullpath)
        <span class="hljs-keyword">return</span> todo_list

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">check</span><span class="hljs-params">(self, filename)</span>:</span>
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> <span class="hljs-string">&apos;_class&apos;</span> <span class="hljs-keyword">in</span> filename

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_data</span><span class="hljs-params">(self, task_type)</span>:</span>
        max_data_nb = <span class="hljs-number">10000</span>

        todo_list = self.gen_todo_list(check = self.check)

        train_rate = <span class="hljs-number">0.64</span>
        val_rate = <span class="hljs-number">0.16</span>
        X_train = []
        y_train = []
        X_val = []
        y_val = []
        X_test = []
        y_test = []

        <span class="hljs-keyword">for</span> counter, filename <span class="hljs-keyword">in</span> enumerate(todo_list):
            (tmpX, tmpy) = self.load(filename)
            <span class="hljs-keyword">if</span> task_type == <span class="hljs-string">&apos;class&apos;</span>:
                tmpy = self.load(<span class="hljs-string">&apos;.&apos;</span>.join(filename.split(<span class="hljs-string">&apos;.&apos;</span>)[:<span class="hljs-number">-1</span>]) + <span class="hljs-string">&apos;_class.pickle&apos;</span>)
            tmpX , tmpy = tmpX[:max_data_nb], tmpy[:max_data_nb]
            <span class="hljs-keyword">assert</span>(len(tmpX) == len(tmpy))
            tmpX = self.processX(tmpX)
            train_num = int(len(tmpX) * train_rate)
            val_num = int(len(tmpX) * val_rate)
            X_train.extend(tmpX[:train_num])
            y_train.extend(tmpy[:train_num])
            X_val.extend(tmpX[train_num: train_num + val_num])
            y_val.extend(tmpy[train_num: train_num + val_num])
            X_test.extend(tmpX[train_num + val_num:])
            y_test.extend(tmpy[train_num + val_num:])
            print(<span class="hljs-string">&apos;\rLoading... {}/{}&apos;</span>.format(counter+<span class="hljs-number">1</span>,len(todo_list)), end = <span class="hljs-string">&apos;&apos;</span>)
        print(<span class="hljs-string">&apos;\r{} Data loaded.               &apos;</span>.format(len(todo_list)))
        <span class="hljs-keyword">return</span> X_train, y_train, X_val, y_val, X_test, y_test

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processX</span><span class="hljs-params">(self, X)</span>:</span>

        X = np.array(X)
        lens = [len(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X] 
        maxlen = <span class="hljs-number">1500</span>
        tmpX = np.zeros((len(X), maxlen))
        mask = np.arange(maxlen) &lt; np.array(lens)[:,<span class="hljs-keyword">None</span>]
        tmpX[mask] = np.concatenate(X)
        <span class="hljs-keyword">return</span> tmpX

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__next__</span><span class="hljs-params">(self)</span>:</span>
        self.pos += <span class="hljs-number">1</span>
        <span class="hljs-keyword">if</span> self.pos &gt;= len(self.index_list):
            <span class="hljs-keyword">raise</span> StopIteration

        <span class="hljs-keyword">return</span> self.index_list[self.pos]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__iter__</span><span class="hljs-params">(self)</span>:</span>
        self.pos = <span class="hljs-number">-1</span>
        <span class="hljs-keyword">return</span> self

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.index_list)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do</span><span class="hljs-params">(data_path = <span class="hljs-string">&apos;../data&apos;</span>)</span>:</span>

    print(<span class="hljs-string">&apos;preparing dataset...&apos;</span>)    
    trainset = MyDataset(data_path=data_path)


    <span class="hljs-comment"># &#x83B7;&#x5F97;&#x6570;&#x636E;&#x96C6;&#x7684;&#x957F;&#x5EA6; len(), &#x5373;length</span>
    train_data_size = len(trainset.X_train)

    <span class="hljs-comment"># &#x683C;&#x5F0F;&#x5316;&#x5B57;&#x7B26;&#x4E32;, format() &#x4E2D;&#x7684;&#x6570;&#x636E;&#x4F1A;&#x66FF;&#x6362; {}</span>
    print(<span class="hljs-string">&quot;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x96C6;&#x7684;&#x957F;&#x5EA6;&#x4E3A;: {}&quot;</span>.format(train_data_size))

    <span class="hljs-comment"># &#x5728;GPU&#x4E0A;&#x52A0;&#x8F7D;&#x6570;&#x636E;</span>
    print(<span class="hljs-string">&apos;loading X_train...&apos;</span>)
    X_train = trainset.X_train
    print(len(X_train))
    print(<span class="hljs-string">&apos;loading y_train_onehot...&apos;</span>)
    y_train_onehot = trainset.y_train_onehot
    print(len(y_train_onehot))
    print(<span class="hljs-string">&apos;loading X_val...&apos;</span>)
    X_val = trainset.X_val
    print(len(X_val))
    print(<span class="hljs-string">&apos;loading y_val_onehot...&apos;</span>)
    y_val_onehot = trainset.y_val_onehot
    print(len(y_val_onehot))
    print(<span class="hljs-string">&apos;loading X_test...&apos;</span>)
    X_test = trainset.X_test
    print(len(X_test))
    print(<span class="hljs-string">&apos;loading y_test_onehot...&apos;</span>)
    y_test_onehot = trainset.y_test_onehot
    print(len(y_test_onehot))
    print(<span class="hljs-string">&apos;loading is done.&apos;</span>)

    print(<span class="hljs-string">&apos;saving x_train...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/x_train&apos;</span>, X_train)
    print(<span class="hljs-string">&apos;saving x_val...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/x_val&apos;</span>, X_val)
    print(<span class="hljs-string">&apos;saving x_test...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/x_test&apos;</span>, X_test)
    print(<span class="hljs-string">&apos;saving y_train...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/y_train_onehot&apos;</span>, y_train_onehot)
    print(<span class="hljs-string">&apos;saving y_val...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/y_val_onehot&apos;</span>, y_val_onehot)
    print(<span class="hljs-string">&apos;saving y_test...&apos;</span>)
    np.save(<span class="hljs-string">&apos;../data2/y_test_onehot&apos;</span>, y_test_onehot)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do2</span><span class="hljs-params">()</span>:</span>
    print(<span class="hljs-string">&apos;saving x_train...&apos;</span>)
    X_train = np.load(<span class="hljs-string">&apos;../data2/x_train.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/x_train.txt&apos;</span>, X_train)

    print(<span class="hljs-string">&apos;saving x_val...&apos;</span>)
    X_val = np.load(<span class="hljs-string">&apos;../data2/x_val.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/x_val.txt&apos;</span>, X_val)

    print(<span class="hljs-string">&apos;saving x_test...&apos;</span>)
    X_test = np.load(<span class="hljs-string">&apos;../data2/x_test.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/x_test.txt&apos;</span>, X_test)

    print(<span class="hljs-string">&apos;saving y_train...&apos;</span>)
    y_train_onehot = np.load(<span class="hljs-string">&apos;../data2/y_train_onehot.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/y_train_onehot.txt&apos;</span>, y_train_onehot)

    print(<span class="hljs-string">&apos;saving y_val...&apos;</span>)
    y_val_onehot = np.load(<span class="hljs-string">&apos;../data2/y_val_onehot.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/y_val_onehot.txt&apos;</span>, y_val_onehot)

    print(<span class="hljs-string">&apos;saving y_test...&apos;</span>)
    y_test_onehot = np.load(<span class="hljs-string">&apos;../data2/y_test_onehot.npy&apos;</span>)
    np.savetxt(<span class="hljs-string">&apos;../data2/y_test_onehot.txt&apos;</span>, y_test_onehot)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    do2()
</code></pre>
<footer class="page-footer-ex"> <span class="page-footer-ex-copyright"> <a href="https://github.com/Dante-Su" target="_blank">DanteSU</a> </span> &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0; <span class="page-footer-ex-footer-update"> <i>updated</i> 2022-05-29 10:55:27 </span> </footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="./" class="navigation navigation-prev " aria-label="Previous page: 流量分类">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="2.html" class="navigation navigation-next " aria-label="Next page: Related Papers">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Open Source","level":"1.5.1.1","depth":3,"next":{"title":"Related Papers","level":"1.5.1.2","depth":3,"path":"DP/TrafficClassification/2.md","ref":"DP/TrafficClassification/2.md","articles":[]},"previous":{"title":"流量分类","level":"1.5.1","depth":2,"path":"DP/TrafficClassification/README.md","ref":"DP/TrafficClassification/README.md","articles":[{"title":"Open Source","level":"1.5.1.1","depth":3,"path":"DP/TrafficClassification/1.md","ref":"DP/TrafficClassification/1.md","articles":[]},{"title":"Related Papers","level":"1.5.1.2","depth":3,"path":"DP/TrafficClassification/2.md","ref":"DP/TrafficClassification/2.md","articles":[]},{"title":"Related Links","level":"1.5.1.3","depth":3,"path":"DP/TrafficClassification/3.md","ref":"DP/TrafficClassification/3.md","articles":[]}]},"dir":"ltr"},"config":{"plugins":["-sharing","-lunr","-search","search-pro","splitter","expandable-chapters-small","anchors","github","github-buttons","sharing-plus","anchor-navigation-ex","favicon","copy-code-button","page-footer-ex"],"styles":{"website":"./styles/website.css"},"pluginsConfig":{"github":{"url":"https://github.com/Dante-Su"},"page-footer-ex":{"copyright":"[DanteSU](https://github.com/Dante-Su)","markdown":true,"update_format":"2022-05-29 HH:mm:ss","update_label":"<i>updated</i>"},"splitter":{},"search-pro":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"anchor-navigation-ex":{"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"mode":"float","multipleH1":true,"pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"printLog":false,"showGoTop":true,"showLevel":false},"favicon":{"shortcut":"./source/images/favicon.ico","bookmark":"./source/images/favicon.ico","appleTouch":"./source/images/favicon.ico","appleTouchMore":{"120x120":"./source/images/favicon.ico","180x180":"./source/images/favicon.ico"}},"github-buttons":{},"expandable-chapters-small":{},"copy-code-button":{},"sharing":{"qq":false,"all":["google","facebook","weibo","twitter","qq","qzone","linkedin","pocket"],"douban":false,"facebook":false,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":false,"messenger":false,"line":false,"vk":false,"pocket":false,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","author":"DanteSU","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"DanteSU's House","language":"zh-hans","links":{"sidebar":{"但丁世界（在建）":"https://dante-su.github.io/","猪猪之家":"https://github.com/hyffun"}},"gitbook":"3.2.3","description":"All I know is here"},"file":{"path":"DP/TrafficClassification/1.md","mtime":"2022-05-29T02:55:27.116Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2022-05-29T07:26:19.431Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

